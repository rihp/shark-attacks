{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Questions: \n",
    "- how to add the dataset to gitignore?\n",
    "- how can i create a separate module that holds my functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Shark attacks, a project by Roberto Henr√≠quez Perozo. Data Analytics Bootcamp at IronHack](shark-attacks.png)\n",
    "\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "<center>\n",
    "    <h1> PART I: Data cleaning and exploration</h1>\n",
    "</center>\n",
    "\n",
    "\n",
    "## üé£Ô∏è Step 0 - Basic knowledge\n",
    "To begin the development of this project, it would be good to hold a minimum understanding of `Shark Attacks`.\n",
    "\n",
    "As I did not know much about this topic at the day the project started, I have recurred to the shark-attack wiki: https://en.wikipedia.org/wiki/Shark_attack\n",
    "\n",
    "With this information in mind, below is the process of data exploration, cleaning, and wrangling.\n",
    "\n",
    "\n",
    "## üé£Ô∏è Step 1 - Defining the dataset path, and importing it to begin basic dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To follow along and access the DataSet, download it from KAGGLE using this link\n",
    "# https://www.kaggle.com/teajay/global-shark-attacks\n",
    "\n",
    "# Once you have downloaded the DataSet, change the following `dataset` variable to match the \n",
    "# path where you have saved the 'attacks.csv' file.\n",
    "\n",
    "dataset = 'attacks.csv' \n",
    "df = pd.read_csv(dataset, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will check some basic information about the dataset, in order to formulate a more educated hypothesis which we could actually put to test with the data available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I notice that the shape of the `df` with no duplicates is very small when compared to the whole `df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåäÔ∏è  FUNCT\n",
    "This comparison could be turned into its own function, as it will be executed quite often"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before (25723, 24)\n",
      "after (6312, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Name', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time',\n",
       "       'Species ', 'Investigator or Source', 'pdf', 'href formula', 'href',\n",
       "       'Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22',\n",
       "       'Unnamed: 23'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'll delete de duplicated rows\n",
    "print('before', df.shape)\n",
    "df = df.drop_duplicates()\n",
    "print('after', df.shape)\n",
    "\n",
    "# And also take a look at the columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        25-Jun-2018\n",
       "1        18-Jun-2018\n",
       "2        09-Jun-2018\n",
       "3        08-Jun-2018\n",
       "4        04-Jun-2018\n",
       "            ...     \n",
       "6307             NaN\n",
       "6308             NaN\n",
       "6309             NaN\n",
       "8702             NaN\n",
       "25722            NaN\n",
       "Name: Date, Length: 6312, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I want to take a look at the time structures\n",
    "df.Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>6303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>6302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>6299.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6309.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6310.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8702</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25722</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6312 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Case Number.1 Case Number.2  original order Unnamed: 22 Unnamed: 23\n",
       "0        2018.06.25    2018.06.25          6303.0         NaN         NaN\n",
       "1        2018.06.18    2018.06.18          6302.0         NaN         NaN\n",
       "2        2018.06.09    2018.06.09          6301.0         NaN         NaN\n",
       "3        2018.06.08    2018.06.08          6300.0         NaN         NaN\n",
       "4        2018.06.04    2018.06.04          6299.0         NaN         NaN\n",
       "...             ...           ...             ...         ...         ...\n",
       "6307            NaN           NaN          6309.0         NaN         NaN\n",
       "6308            NaN           NaN          6310.0         NaN         NaN\n",
       "6309            NaN           NaN             NaN         NaN         NaN\n",
       "8702            NaN           NaN             NaN         NaN         NaN\n",
       "25722           NaN           NaN             NaN         NaN         NaN\n",
       "\n",
       "[6312 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I want to see what is the data on the last couple\n",
    "# of columns which have unexplicit labels\n",
    "df[['Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22', 'Unnamed: 23']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6312, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Case Number.1       10\n",
       "Case Number.2       10\n",
       "original order       3\n",
       "Unnamed: 22       6311\n",
       "Unnamed: 23       6310\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Too many null values on the last two columns... let's count them\n",
    "print(df.shape)\n",
    "df[['Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22', 'Unnamed: 23']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there is only 1 value in the 'Unnamed: 22' column, and 2 values in the\n",
    "# 'Unnamed: 22' column, I'll not consider this data for my analysis.\n",
    "df = df.drop(columns=['Unnamed: 22', 'Unnamed: 23'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Name', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time',\n",
       "       'Species ', 'Investigator or Source', 'pdf', 'href formula', 'href',\n",
       "       'Case Number.1', 'Case Number.2', 'original order'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we'll look at the columns again\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2003.04.20.c    1\n",
       "1861.02.12.R    1\n",
       "1966.07.14      1\n",
       "1979.03.00      1\n",
       "2015.06.14.a    1\n",
       "               ..\n",
       "2006.09.02      2\n",
       "2005.04.06      2\n",
       "2009.12.18      2\n",
       "1966.12.26      2\n",
       "1923.00.00.a    2\n",
       "Name: Case Number.1, Length: 6285, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following columns seemed a little bit rare, so i do a value count to find out what they are about\n",
    "df['Case Number.1'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1983.07.05      1\n",
       "1861.02.12.R    1\n",
       "1966.07.14      1\n",
       "1979.03.00      1\n",
       "2015.06.14.a    1\n",
       "               ..\n",
       "2013.10.05      2\n",
       "1923.00.00.a    2\n",
       "2005.04.06      2\n",
       "1990.05.10      2\n",
       "1980.07.00      2\n",
       "Name: Case Number.2, Length: 6286, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Case Number.2'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåäÔ∏è Creating a Function\n",
    "\n",
    "After some thought and googling, it seems like these are some sort of notation used to categorize and order the shark attacks.\n",
    "\n",
    "They also use the a notation that includes dates. \n",
    "## Is it the same as the Date on the Date column?\n",
    "\n",
    "To find out, I wantet to pick random samples of the dataframe, but python's built-in `random` module kept giving me trouble when I tried to use it alongside pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nOLDER VERSION OF SAMPLER FUNCTION:\\ndef sampler(df, column, sample_size):\\n    # This function generates an iterator out of random rows from a pandas dataframe\\'s specific column\\n    \\n    # Defining how many samples to fetch (this is the df index)\\n    for i in range(sample_size):\\n        \\n        # The 1000 value can be changed in future versions to match the size of the population\\n        e = random.choice(range(1000))\\n        yield f\"index: {e}, sample: {df.iloc[e][column]}\"\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It's easier to make it into a function\n",
    "\"\"\" \n",
    "OLDER VERSION OF SAMPLER FUNCTION:\n",
    "def sampler(df, column, sample_size):\n",
    "    # This function generates an iterator out of random rows from a pandas dataframe's specific column\n",
    "    \n",
    "    # Defining how many samples to fetch (this is the df index)\n",
    "    for i in range(sample_size):\n",
    "        \n",
    "        # The 1000 value can be changed in future versions to match the size of the population\n",
    "        e = random.choice(range(1000))\n",
    "        yield f\"index: {e}, sample: {df.iloc[e][column]}\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nVER 02\\ndef sampler(df, column, sample_size):\\n# This function generates an iterator out of random rows from a pandas dataframe\\'s specific column\\n    \\n    # Defining how many samples to fetch from the df\\n    for i in range(sample_size):\\n        \\n        # Now a random index is generated out of the total length of the column...\\n        i = random.choice(range(len(df[column])))\\n        # ... to return the data values in that index as an iterator:\\n        yield f\"index: {i}, sample: {df.iloc[i][column]}\"\\n        \\n        # For future versions, it would be good to look at how I can return the\\n        # data as a tupple with just the data, and not have it return a formatted string\\n        # or even better, a pandas dataframe with the results\\n\\n# Now let\\'s try it out\\nsampler(df, [\\'Date\\', \\'Case Number.1\\', \\'Case Number.2\\'], 10)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It's easier to make it into a function\n",
    "\"\"\"\n",
    "VER 02\n",
    "def sampler(df, column, sample_size):\n",
    "# This function generates an iterator out of random rows from a pandas dataframe's specific column\n",
    "    \n",
    "    # Defining how many samples to fetch from the df\n",
    "    for i in range(sample_size):\n",
    "        \n",
    "        # Now a random index is generated out of the total length of the column...\n",
    "        i = random.choice(range(len(df[column])))\n",
    "        # ... to return the data values in that index as an iterator:\n",
    "        yield f\"index: {i}, sample: {df.iloc[i][column]}\"\n",
    "        \n",
    "        # For future versions, it would be good to look at how I can return the\n",
    "        # data as a tupple with just the data, and not have it return a formatted string\n",
    "        # or even better, a pandas dataframe with the results\n",
    "\n",
    "# Now let's try it out\n",
    "sampler(df, ['Date', 'Case Number.1', 'Case Number.2'], 10)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object sampler at 0x7fcbb5a7faf0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It's easier to make it into a function\n",
    "\n",
    "#VER 03\n",
    "def sampler(df, column, sample_size):\n",
    "# This function generates an iterator out of random rows from a pandas dataframe's specific column\n",
    "    \n",
    "    # Defining how many samples to fetch from the df\n",
    "    for i in range(sample_size):\n",
    "        \n",
    "        # Now a random index is generated out of the total length of the column...\n",
    "        i = random.choice(range(len(df[column])))\n",
    "        # ... to return the data values in that index as an iterator:\n",
    "        yield df.iloc[i][column]\n",
    "        \n",
    "        # For future versions, it would be good to look at how I can return the\n",
    "        # data as a tupple with just the data, and not have it return a formatted string\n",
    "        # or even better, a pandas dataframe with the results\n",
    "\n",
    "\n",
    "# Now let's try it out\n",
    "sampler(df, ['Date', 'Case Number.1', 'Case Number.2'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "\n",
    "# list(sampler(df, ['href', 'href formula'],10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Date             08-Jan-2015\n",
       " Case Number.1     2015.01.08\n",
       " Case Number.2     2015.01.08\n",
       " Name: 459, dtype: object,\n",
       " Date              15-Aug-1959\n",
       " Case Number.1    1959.08.15.b\n",
       " Case Number.2    1959.08.15.b\n",
       " Name: 4069, dtype: object,\n",
       " Date              21-Sep-1931\n",
       " Case Number.1    1931.09.21.b\n",
       " Case Number.2    1931.09.21.b\n",
       " Name: 5003, dtype: object,\n",
       " Date             28-Apr-2001\n",
       " Case Number.1     2001.04.28\n",
       " Case Number.2     2001.04.28\n",
       " Name: 1952, dtype: object,\n",
       " Date             14-Oct-1969\n",
       " Case Number.1     1969.10.14\n",
       " Case Number.2     1969.10.14\n",
       " Name: 3419, dtype: object,\n",
       " Date             Before 2004\n",
       " Case Number.1        ND-0107\n",
       " Case Number.2        ND-0107\n",
       " Name: 6212, dtype: object,\n",
       " Date             10-Sep-1992\n",
       " Case Number.1     1992.09.10\n",
       " Case Number.2     1992.09.10\n",
       " Name: 2535, dtype: object,\n",
       " Date              22-Jan-2010\n",
       " Case Number.1    2010.01.22.b\n",
       " Case Number.2    2010.01.22.b\n",
       " Name: 1049, dtype: object,\n",
       " Date             16-Nov-1942\n",
       " Case Number.1     1942.11.16\n",
       " Case Number.2     1942.11.16\n",
       " Name: 4693, dtype: object,\n",
       " Date             30-Nov-1999\n",
       " Case Number.1     1999.11.30\n",
       " Case Number.2     1999.11.30\n",
       " Name: 2086, dtype: object]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since sampler generates iterators, list() must be used to see its contents\n",
    "list(sampler(df, ['Date', 'Case Number.1', 'Case Number.2'], 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è\n",
    "From this output, we can see that the `Case Number` Columnns are actually replicating the info that we already have on the `Date` column. Therefore, we will drop both `Case Number` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>original order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>No injury to occupant, outrigger canoe and pad...</td>\n",
       "      <td>N</td>\n",
       "      <td>18h00</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6303.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson¬†McNeely</td>\n",
       "      <td>F</td>\n",
       "      <td>11</td>\n",
       "      <td>Minor injury to left thigh</td>\n",
       "      <td>N</td>\n",
       "      <td>14h00  -15h00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>M</td>\n",
       "      <td>48</td>\n",
       "      <td>Injury to left lower leg from surfboard skeg</td>\n",
       "      <td>N</td>\n",
       "      <td>07h45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6301.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>08-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Arrawarra Headland</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minor injury to lower leg</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 m shark</td>\n",
       "      <td>B. Myatt, GSAF</td>\n",
       "      <td>2018.06.08-Arrawarra.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>04-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>Colima</td>\n",
       "      <td>La Ticla</td>\n",
       "      <td>Free diving</td>\n",
       "      <td>Gustavo Ramos</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lacerations to leg &amp; hand shark PROVOKED INCIDENT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tiger shark, 3m</td>\n",
       "      <td>A .Kipper</td>\n",
       "      <td>2018.06.04-Ramos.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8702</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25722</th>\n",
       "      <td>xx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6312 rows √ó 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Case Number         Date    Year        Type    Country  \\\n",
       "0      2018.06.25  25-Jun-2018  2018.0     Boating        USA   \n",
       "1      2018.06.18  18-Jun-2018  2018.0  Unprovoked        USA   \n",
       "2      2018.06.09  09-Jun-2018  2018.0     Invalid        USA   \n",
       "3      2018.06.08  08-Jun-2018  2018.0  Unprovoked  AUSTRALIA   \n",
       "4      2018.06.04  04-Jun-2018  2018.0    Provoked     MEXICO   \n",
       "...           ...          ...     ...         ...        ...   \n",
       "6307            0          NaN     NaN         NaN        NaN   \n",
       "6308            0          NaN     NaN         NaN        NaN   \n",
       "6309            0          NaN     NaN         NaN        NaN   \n",
       "8702          NaN          NaN     NaN         NaN        NaN   \n",
       "25722          xx          NaN     NaN         NaN        NaN   \n",
       "\n",
       "                  Area                        Location     Activity  \\\n",
       "0           California     Oceanside, San Diego County     Paddling   \n",
       "1              Georgia  St. Simon Island, Glynn County     Standing   \n",
       "2               Hawaii                    Habush, Oahu      Surfing   \n",
       "3      New South Wales              Arrawarra Headland      Surfing   \n",
       "4               Colima                        La Ticla  Free diving   \n",
       "...                ...                             ...          ...   \n",
       "6307               NaN                             NaN          NaN   \n",
       "6308               NaN                             NaN          NaN   \n",
       "6309               NaN                             NaN          NaN   \n",
       "8702               NaN                             NaN          NaN   \n",
       "25722              NaN                             NaN          NaN   \n",
       "\n",
       "                  Name Sex   Age  \\\n",
       "0          Julie Wolfe    F   57   \n",
       "1      Adyson¬†McNeely     F   11   \n",
       "2          John Denges    M   48   \n",
       "3                 male    M  NaN   \n",
       "4       Gustavo Ramos     M  NaN   \n",
       "...                ...  ...  ...   \n",
       "6307               NaN  NaN  NaN   \n",
       "6308               NaN  NaN  NaN   \n",
       "6309               NaN  NaN  NaN   \n",
       "8702               NaN  NaN  NaN   \n",
       "25722              NaN  NaN  NaN   \n",
       "\n",
       "                                                  Injury Fatal (Y/N)  \\\n",
       "0      No injury to occupant, outrigger canoe and pad...           N   \n",
       "1                             Minor injury to left thigh           N   \n",
       "2           Injury to left lower leg from surfboard skeg           N   \n",
       "3                              Minor injury to lower leg           N   \n",
       "4      Lacerations to leg & hand shark PROVOKED INCIDENT           N   \n",
       "...                                                  ...         ...   \n",
       "6307                                                 NaN         NaN   \n",
       "6308                                                 NaN         NaN   \n",
       "6309                                                 NaN         NaN   \n",
       "8702                                                 NaN         NaN   \n",
       "25722                                                NaN         NaN   \n",
       "\n",
       "                Time         Species           Investigator or Source  \\\n",
       "0              18h00      White shark                R. Collier, GSAF   \n",
       "1      14h00  -15h00              NaN  K.McMurray, TrackingSharks.com   \n",
       "2              07h45              NaN  K.McMurray, TrackingSharks.com   \n",
       "3                NaN        2 m shark                  B. Myatt, GSAF   \n",
       "4                NaN  Tiger shark, 3m                       A .Kipper   \n",
       "...              ...              ...                             ...   \n",
       "6307             NaN              NaN                             NaN   \n",
       "6308             NaN              NaN                             NaN   \n",
       "6309             NaN              NaN                             NaN   \n",
       "8702             NaN              NaN                             NaN   \n",
       "25722            NaN              NaN                             NaN   \n",
       "\n",
       "                            pdf  \\\n",
       "0          2018.06.25-Wolfe.pdf   \n",
       "1        2018.06.18-McNeely.pdf   \n",
       "2         2018.06.09-Denges.pdf   \n",
       "3      2018.06.08-Arrawarra.pdf   \n",
       "4          2018.06.04-Ramos.pdf   \n",
       "...                         ...   \n",
       "6307                        NaN   \n",
       "6308                        NaN   \n",
       "6309                        NaN   \n",
       "8702                        NaN   \n",
       "25722                       NaN   \n",
       "\n",
       "                                            href formula  \\\n",
       "0      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "3      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "4      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "...                                                  ...   \n",
       "6307                                                 NaN   \n",
       "6308                                                 NaN   \n",
       "6309                                                 NaN   \n",
       "8702                                                 NaN   \n",
       "25722                                                NaN   \n",
       "\n",
       "                                                    href  original order  \n",
       "0      http://sharkattackfile.net/spreadsheets/pdf_di...          6303.0  \n",
       "1      http://sharkattackfile.net/spreadsheets/pdf_di...          6302.0  \n",
       "2      http://sharkattackfile.net/spreadsheets/pdf_di...          6301.0  \n",
       "3      http://sharkattackfile.net/spreadsheets/pdf_di...          6300.0  \n",
       "4      http://sharkattackfile.net/spreadsheets/pdf_di...          6299.0  \n",
       "...                                                  ...             ...  \n",
       "6307                                                 NaN          6309.0  \n",
       "6308                                                 NaN          6310.0  \n",
       "6309                                                 NaN             NaN  \n",
       "8702                                                 NaN             NaN  \n",
       "25722                                                NaN             NaN  \n",
       "\n",
       "[6312 rows x 20 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['Case Number.1', 'Case Number.2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this output, we notice that the last couple of rows are still holding many null values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>original order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6297</th>\n",
       "      <td>ND.0005</td>\n",
       "      <td>Before 1903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>Roebuck Bay</td>\n",
       "      <td>Diving</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H. Taunton; N. Bartlett,  p. 234</td>\n",
       "      <td>ND-0005-RoebuckBay.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6298</th>\n",
       "      <td>ND.0004</td>\n",
       "      <td>Before 1903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl diving</td>\n",
       "      <td>Ahmun</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H. Taunton; N. Bartlett,  pp. 233-234</td>\n",
       "      <td>ND-0004-Ahmun.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6299</th>\n",
       "      <td>ND.0003</td>\n",
       "      <td>1900-1905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Ocracoke Inlet</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Coast Guard personnel</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F. Schwartz, p.23; C. Creswell, GSAF</td>\n",
       "      <td>ND-0003-Ocracoke_1900-1905.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6300</th>\n",
       "      <td>ND.0002</td>\n",
       "      <td>1883-1889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>PANAMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Panama Bay 8¬∫N, 79¬∫W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jules Patterson</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Sun, 10/20/1938</td>\n",
       "      <td>ND-0002-JulesPatterson.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6301</th>\n",
       "      <td>ND.0001</td>\n",
       "      <td>1845-1853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>CEYLON (SRI LANKA)</td>\n",
       "      <td>Eastern Province</td>\n",
       "      <td>Below the English fort, Trincomalee</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>FATAL. \"Shark bit him in half, carrying away t...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S.W. Baker</td>\n",
       "      <td>ND-0001-Ceylon.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6302</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6303</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6305.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6304</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6305</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6306</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6308.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8702</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25722</th>\n",
       "      <td>xx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Case Number         Date  Year        Type             Country  \\\n",
       "6297      ND.0005  Before 1903   0.0  Unprovoked           AUSTRALIA   \n",
       "6298      ND.0004  Before 1903   0.0  Unprovoked           AUSTRALIA   \n",
       "6299      ND.0003    1900-1905   0.0  Unprovoked                 USA   \n",
       "6300      ND.0002    1883-1889   0.0  Unprovoked              PANAMA   \n",
       "6301      ND.0001    1845-1853   0.0  Unprovoked  CEYLON (SRI LANKA)   \n",
       "6302            0          NaN   NaN         NaN                 NaN   \n",
       "6303            0          NaN   NaN         NaN                 NaN   \n",
       "6304            0          NaN   NaN         NaN                 NaN   \n",
       "6305            0          NaN   NaN         NaN                 NaN   \n",
       "6306            0          NaN   NaN         NaN                 NaN   \n",
       "6307            0          NaN   NaN         NaN                 NaN   \n",
       "6308            0          NaN   NaN         NaN                 NaN   \n",
       "6309            0          NaN   NaN         NaN                 NaN   \n",
       "8702          NaN          NaN   NaN         NaN                 NaN   \n",
       "25722          xx          NaN   NaN         NaN                 NaN   \n",
       "\n",
       "                    Area                             Location      Activity  \\\n",
       "6297   Western Australia                          Roebuck Bay        Diving   \n",
       "6298   Western Australia                                  NaN  Pearl diving   \n",
       "6299      North Carolina                       Ocracoke Inlet      Swimming   \n",
       "6300                 NaN                 Panama Bay 8¬∫N, 79¬∫W           NaN   \n",
       "6301    Eastern Province  Below the English fort, Trincomalee      Swimming   \n",
       "6302                 NaN                                  NaN           NaN   \n",
       "6303                 NaN                                  NaN           NaN   \n",
       "6304                 NaN                                  NaN           NaN   \n",
       "6305                 NaN                                  NaN           NaN   \n",
       "6306                 NaN                                  NaN           NaN   \n",
       "6307                 NaN                                  NaN           NaN   \n",
       "6308                 NaN                                  NaN           NaN   \n",
       "6309                 NaN                                  NaN           NaN   \n",
       "8702                 NaN                                  NaN           NaN   \n",
       "25722                NaN                                  NaN           NaN   \n",
       "\n",
       "                        Name Sex   Age  \\\n",
       "6297                    male    M  NaN   \n",
       "6298                   Ahmun    M  NaN   \n",
       "6299   Coast Guard personnel    M  NaN   \n",
       "6300         Jules Patterson    M  NaN   \n",
       "6301                    male    M   15   \n",
       "6302                     NaN  NaN  NaN   \n",
       "6303                     NaN  NaN  NaN   \n",
       "6304                     NaN  NaN  NaN   \n",
       "6305                     NaN  NaN  NaN   \n",
       "6306                     NaN  NaN  NaN   \n",
       "6307                     NaN  NaN  NaN   \n",
       "6308                     NaN  NaN  NaN   \n",
       "6309                     NaN  NaN  NaN   \n",
       "8702                     NaN  NaN  NaN   \n",
       "25722                    NaN  NaN  NaN   \n",
       "\n",
       "                                                  Injury Fatal (Y/N) Time  \\\n",
       "6297                                               FATAL           Y  NaN   \n",
       "6298                                               FATAL           Y  NaN   \n",
       "6299                                               FATAL           Y  NaN   \n",
       "6300                                               FATAL           Y  NaN   \n",
       "6301   FATAL. \"Shark bit him in half, carrying away t...           Y  NaN   \n",
       "6302                                                 NaN         NaN  NaN   \n",
       "6303                                                 NaN         NaN  NaN   \n",
       "6304                                                 NaN         NaN  NaN   \n",
       "6305                                                 NaN         NaN  NaN   \n",
       "6306                                                 NaN         NaN  NaN   \n",
       "6307                                                 NaN         NaN  NaN   \n",
       "6308                                                 NaN         NaN  NaN   \n",
       "6309                                                 NaN         NaN  NaN   \n",
       "8702                                                 NaN         NaN  NaN   \n",
       "25722                                                NaN         NaN  NaN   \n",
       "\n",
       "      Species                  Investigator or Source  \\\n",
       "6297       NaN       H. Taunton; N. Bartlett,  p. 234   \n",
       "6298       NaN  H. Taunton; N. Bartlett,  pp. 233-234   \n",
       "6299       NaN   F. Schwartz, p.23; C. Creswell, GSAF   \n",
       "6300       NaN                    The Sun, 10/20/1938   \n",
       "6301       NaN                             S.W. Baker   \n",
       "6302       NaN                                    NaN   \n",
       "6303       NaN                                    NaN   \n",
       "6304       NaN                                    NaN   \n",
       "6305       NaN                                    NaN   \n",
       "6306       NaN                                    NaN   \n",
       "6307       NaN                                    NaN   \n",
       "6308       NaN                                    NaN   \n",
       "6309       NaN                                    NaN   \n",
       "8702       NaN                                    NaN   \n",
       "25722      NaN                                    NaN   \n",
       "\n",
       "                                  pdf  \\\n",
       "6297           ND-0005-RoebuckBay.pdf   \n",
       "6298                ND-0004-Ahmun.pdf   \n",
       "6299   ND-0003-Ocracoke_1900-1905.pdf   \n",
       "6300       ND-0002-JulesPatterson.pdf   \n",
       "6301               ND-0001-Ceylon.pdf   \n",
       "6302                              NaN   \n",
       "6303                              NaN   \n",
       "6304                              NaN   \n",
       "6305                              NaN   \n",
       "6306                              NaN   \n",
       "6307                              NaN   \n",
       "6308                              NaN   \n",
       "6309                              NaN   \n",
       "8702                              NaN   \n",
       "25722                             NaN   \n",
       "\n",
       "                                            href formula  \\\n",
       "6297   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6298   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6299   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6300   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6301   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6302                                                 NaN   \n",
       "6303                                                 NaN   \n",
       "6304                                                 NaN   \n",
       "6305                                                 NaN   \n",
       "6306                                                 NaN   \n",
       "6307                                                 NaN   \n",
       "6308                                                 NaN   \n",
       "6309                                                 NaN   \n",
       "8702                                                 NaN   \n",
       "25722                                                NaN   \n",
       "\n",
       "                                                    href  original order  \n",
       "6297   http://sharkattackfile.net/spreadsheets/pdf_di...             6.0  \n",
       "6298   http://sharkattackfile.net/spreadsheets/pdf_di...             5.0  \n",
       "6299   http://sharkattackfile.net/spreadsheets/pdf_di...             4.0  \n",
       "6300   http://sharkattackfile.net/spreadsheets/pdf_di...             3.0  \n",
       "6301   http://sharkattackfile.net/spreadsheets/pdf_di...             2.0  \n",
       "6302                                                 NaN          6304.0  \n",
       "6303                                                 NaN          6305.0  \n",
       "6304                                                 NaN          6306.0  \n",
       "6305                                                 NaN          6307.0  \n",
       "6306                                                 NaN          6308.0  \n",
       "6307                                                 NaN          6309.0  \n",
       "6308                                                 NaN          6310.0  \n",
       "6309                                                 NaN             NaN  \n",
       "8702                                                 NaN             NaN  \n",
       "25722                                                NaN             NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but if we look closely, it's only the last 10 columns which have the nulls.\n",
    "df.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>original order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6297</th>\n",
       "      <td>ND.0005</td>\n",
       "      <td>Before 1903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>Roebuck Bay</td>\n",
       "      <td>Diving</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H. Taunton; N. Bartlett,  p. 234</td>\n",
       "      <td>ND-0005-RoebuckBay.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6298</th>\n",
       "      <td>ND.0004</td>\n",
       "      <td>Before 1903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl diving</td>\n",
       "      <td>Ahmun</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H. Taunton; N. Bartlett,  pp. 233-234</td>\n",
       "      <td>ND-0004-Ahmun.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6299</th>\n",
       "      <td>ND.0003</td>\n",
       "      <td>1900-1905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Ocracoke Inlet</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Coast Guard personnel</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F. Schwartz, p.23; C. Creswell, GSAF</td>\n",
       "      <td>ND-0003-Ocracoke_1900-1905.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6300</th>\n",
       "      <td>ND.0002</td>\n",
       "      <td>1883-1889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>PANAMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Panama Bay 8¬∫N, 79¬∫W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jules Patterson</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Sun, 10/20/1938</td>\n",
       "      <td>ND-0002-JulesPatterson.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6301</th>\n",
       "      <td>ND.0001</td>\n",
       "      <td>1845-1853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>CEYLON (SRI LANKA)</td>\n",
       "      <td>Eastern Province</td>\n",
       "      <td>Below the English fort, Trincomalee</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>FATAL. \"Shark bit him in half, carrying away t...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S.W. Baker</td>\n",
       "      <td>ND-0001-Ceylon.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Case Number         Date  Year        Type             Country  \\\n",
       "6297     ND.0005  Before 1903   0.0  Unprovoked           AUSTRALIA   \n",
       "6298     ND.0004  Before 1903   0.0  Unprovoked           AUSTRALIA   \n",
       "6299     ND.0003    1900-1905   0.0  Unprovoked                 USA   \n",
       "6300     ND.0002    1883-1889   0.0  Unprovoked              PANAMA   \n",
       "6301     ND.0001    1845-1853   0.0  Unprovoked  CEYLON (SRI LANKA)   \n",
       "\n",
       "                   Area                             Location      Activity  \\\n",
       "6297  Western Australia                          Roebuck Bay        Diving   \n",
       "6298  Western Australia                                  NaN  Pearl diving   \n",
       "6299     North Carolina                       Ocracoke Inlet      Swimming   \n",
       "6300                NaN                 Panama Bay 8¬∫N, 79¬∫W           NaN   \n",
       "6301   Eastern Province  Below the English fort, Trincomalee      Swimming   \n",
       "\n",
       "                       Name Sex   Age  \\\n",
       "6297                   male    M  NaN   \n",
       "6298                  Ahmun    M  NaN   \n",
       "6299  Coast Guard personnel    M  NaN   \n",
       "6300        Jules Patterson    M  NaN   \n",
       "6301                   male    M   15   \n",
       "\n",
       "                                                 Injury Fatal (Y/N) Time  \\\n",
       "6297                                              FATAL           Y  NaN   \n",
       "6298                                              FATAL           Y  NaN   \n",
       "6299                                              FATAL           Y  NaN   \n",
       "6300                                              FATAL           Y  NaN   \n",
       "6301  FATAL. \"Shark bit him in half, carrying away t...           Y  NaN   \n",
       "\n",
       "     Species                  Investigator or Source  \\\n",
       "6297      NaN       H. Taunton; N. Bartlett,  p. 234   \n",
       "6298      NaN  H. Taunton; N. Bartlett,  pp. 233-234   \n",
       "6299      NaN   F. Schwartz, p.23; C. Creswell, GSAF   \n",
       "6300      NaN                    The Sun, 10/20/1938   \n",
       "6301      NaN                             S.W. Baker   \n",
       "\n",
       "                                 pdf  \\\n",
       "6297          ND-0005-RoebuckBay.pdf   \n",
       "6298               ND-0004-Ahmun.pdf   \n",
       "6299  ND-0003-Ocracoke_1900-1905.pdf   \n",
       "6300      ND-0002-JulesPatterson.pdf   \n",
       "6301              ND-0001-Ceylon.pdf   \n",
       "\n",
       "                                           href formula  \\\n",
       "6297  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6298  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6299  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6300  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6301  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                   href  original order  \n",
       "6297  http://sharkattackfile.net/spreadsheets/pdf_di...             6.0  \n",
       "6298  http://sharkattackfile.net/spreadsheets/pdf_di...             5.0  \n",
       "6299  http://sharkattackfile.net/spreadsheets/pdf_di...             4.0  \n",
       "6300  http://sharkattackfile.net/spreadsheets/pdf_di...             3.0  \n",
       "6301  http://sharkattackfile.net/spreadsheets/pdf_di...             2.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#since they are only 10 instances, we can drop them manually:\n",
    "df = df.drop([6302, 6303,6304,6305,6306,6307,6308,6309,8702,25722])\n",
    "\n",
    "#results\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü¶àÔ∏è\n",
    "Whith this cleaned dataframe, we can look deeper into the actual data.\n",
    "\n",
    "Notice that we still have additional columns that are not giving us any **'meaty information'** !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After checking, these are just old indexes\n",
    "# df['original order'].value_counts()\n",
    "\n",
    "# And these are only the titles of the pdfs\n",
    "# df['pdf'].value_counts()\n",
    "\n",
    "df = df.drop(columns = ['pdf', 'original order'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü¶àÔ∏è\n",
    "The `href` and `href formula` columsn look very similar, but since they can't be read on the DataFrame that pandas provides, we'll try to use our `sampler()` function again to compare them both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[href            http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " href formula    http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " Name: 352, dtype: object,\n",
       " href            http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " href formula    http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " Name: 4965, dtype: object]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sampler(df, ['href', 'href formula'],2))\n",
    "# This however, returns invalid links which are not accurately represented.\n",
    "# example: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü¶àÔ∏è\n",
    "To actually see the contents, I've resorted to two separate methods, `random.sample` and a `for` loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://sharkattackfile.net/spreadsheets/pdf_directory/1934.01.07-Grant.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/2009.12.06-Large.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1959.01.17.a-Neil.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1830.07.26-JosephBlaney.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1987.08.15-Rogers_Collier.pdf']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['http://sharkattackfile.net/spreadsheets/pdf_directory/ND-0064-Shatt-al-Arab.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1958.04.30-Bowers.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1946.11.20-EsronaJohnson.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1972.12.26-Pfosse.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/2006.06.15-Milea.pdf']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# With Random sample\n",
    "display(random.sample(list(df['href']), 5))\n",
    "display(random.sample(list(df['href formula']), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 274, href:         http://sharkattackfile.net/spreadsheets/pdf_directory/2016.05.22-Marcus.pdf\n",
      "index: 274, href formula: http://sharkattackfile.net/spreadsheets/pdf_directory/2016.05.22-Marcus.pdf\n",
      "index: 408, href:         http://sharkattackfile.net/spreadsheets/pdf_directory/2015.06.24.a-Kumpe.pdf\n",
      "index: 408, href formula: http://sharkattackfile.net/spreadsheets/pdf_directory/2015.06.24.a-Kumpe.pdf\n",
      "index: 30, href:         http://sharkattackfile.net/spreadsheets/pdf_directory/2018.04.14-Rowan.pff\n",
      "index: 30, href formula: http://sharkattackfile.net/spreadsheets/pdf_directory/2018.04.14-Rowan.pff\n",
      "index: 572, href:         http://sharkattackfile.net/spreadsheets/pdf_directory/2014.03.22.a-Hoffman.pdf\n",
      "index: 572, href formula: http://sharkattackfile.net/spreadsheets/pdf_directory/2014.03.22.a-Hoffman.pdf\n",
      "index: 708, href:         http://sharkattackfile.net/spreadsheets/pdf_directory/2013.01.21.R-Marshallsea.pdf\n",
      "index: 708, href formula: http://sharkattackfile.net/spreadsheets/pdf_directory/2013.01.21.R-Marshallsea.pdf\n"
     ]
    }
   ],
   "source": [
    "# With a FOR loop\n",
    "for i in range(5):\n",
    "    e = random.choice(range(1000))\n",
    "    print(f\"index: {e}, href:         {df.iloc[e]['href']}\")\n",
    "    print(f\"index: {e}, href formula: {df.iloc[e]['href formula']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è\n",
    "The links on both columns seem to match, most of the times anyways.\n",
    "\n",
    "In some cases, the `href` seems to have an duplication on its links which corrupted them and made them innaccessible.\n",
    "\n",
    "However, the `href formula` actually saved the correct URL format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://sharkattackfile.net/spreadsheets/pdf_directory/http://sharkattackfile.net/spreadsheets/pdf_directory/2015.11.15.a-Engelman.pdf\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/2015.11.15.a-Engelman.pdf\n",
      "\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/http://sharkattackfile.net/spreadsheets/pdf_directory/2015.12.21.a-Brazil.pdf\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/2015.12.21.a-Brazil.pdf\n",
      "\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/http://sharkattackfile.net/spreadsheets/pdf_directory/2014.00.00.b-OceanicWhitetip.pdf\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/2014.00.00.b-OceanicWhitetip.pdf\n",
      "\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/http://sharkattackfile.net/spreadsheets/pdf_directory/2014.04.03-Armstrong.pdf\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/2014.04.03-Armstrong.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.iloc[332]['href']), print(df.iloc[332]['href formula'])\n",
    "print()\n",
    "print(df.iloc[324]['href']), print(df.iloc[324]['href formula'])\n",
    "print()\n",
    "print(df.iloc[588]['href']), print(df.iloc[588]['href formula'])\n",
    "print()\n",
    "print(df.iloc[569]['href']), print(df.iloc[569]['href formula'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the sake of simplicity, we will drop the `href` column, and replace it with the `href formula`\n",
    "df = df.drop(columns='href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time', 'Species ',\n",
       "       'Investigator or Source', 'href formula'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The column with the name of the victims also does not bring much relevant information to our study\n",
    "df = df.drop(columns='Name')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèäÔ∏è IDEAS:\n",
    "- The pdfs presented on the links seem quite structured\n",
    " \n",
    " - It could be possible to parse them later down the road and use a **REGEX** to find more data\n",
    " \n",
    " - Like, adding a column that lists the **'Moon Phase'** described on some of the pdfs\n",
    "\n",
    "- I also have ran query a few times to notice that all pdfs have actually been uploaded to the same website and have the same naming structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è\n",
    "\n",
    "Some column names can be simplified, and some have unnecesary white spaces.\n",
    " \n",
    " Let's fix that right away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time', 'Species ',\n",
       "       'Investigator or Source', 'href formula'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CaseNum', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Sex', 'Age', 'Injury', 'Fatal', 'Time', 'Species',\n",
       "       'Source', 'href'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df\n",
    "df.columns = ['CaseNum', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
    "       'Activity', 'Sex', 'Age', 'Injury', 'Fatal', 'Time',\n",
    "       'Species', 'Source', 'href']\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèäÔ∏è SPECIES IDEAS: \n",
    "- create a standardized column for species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è\n",
    "Many of the values from the Species column are `nulls`. We'll fill them with the same `Invalid` value that other cells already have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "White shark                                           163\n",
       "Shark involvement prior to death was not confirmed    105\n",
       "Invalid                                               102\n",
       "Shark involvement not confirmed                        88\n",
       "Tiger shark                                            73\n",
       "                                                     ... \n",
       "136-kg [300-lb] shark                                   1\n",
       "9-foot shark                                            1\n",
       "Tiger shark, 3.5 m                                      1\n",
       "Spinner shark, 1.2 m to 1.5 m [4' to 5']                1\n",
       "1.8 m [6'] shark, species identity questionable         1\n",
       "Name: Species, Length: 1549, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BEFORE\n",
    "df.Species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Invalid                                               2940\n",
       "White shark                                            163\n",
       "Shark involvement prior to death was not confirmed     105\n",
       "Shark involvement not confirmed                         88\n",
       "Tiger shark                                             73\n",
       "                                                      ... \n",
       "136-kg [300-lb] shark                                    1\n",
       "9-foot shark                                             1\n",
       "Tiger shark, 3.5 m                                       1\n",
       "Spinner shark, 1.2 m to 1.5 m [4' to 5']                 1\n",
       "1.8 m [6'] shark, species identity questionable          1\n",
       "Name: Species, Length: 1549, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Species = df.Species.fillna('Invalid')\n",
    "\n",
    "#AFTER\n",
    "df.Species.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        6302\n",
       "unique       1549\n",
       "top       Invalid\n",
       "freq         2940\n",
       "Name: Species, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With the .describe() method, we can see that there are 1549 unique values in this column\n",
    "# It would be interesting to create a new column which narrows this down to less unique values.\n",
    "df.Species.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è \n",
    "\n",
    "[Can you guess the Pok√©mon?](https://i.ytimg.com/vi/mg1A94zBWBw/hqdefault.jpg)\n",
    "\n",
    "There are more than 400 species of sharks, and while lurking around the `Species` column you can find all sort of weird animals. Did you know there's even one species of shark known as the *'Cookie Cutter shark'* ?\n",
    "\n",
    "I certainly had no clue. \n",
    "\n",
    "Here I tried to sort a bit of the data, by creating a secondary column which filtered the different species, while also taking out possible confusions. The scrutiny for this categorization is quite laxed, as this is not a research paper, but more an exercise with data...\n",
    "\n",
    "Below is the process of creating such a secondary table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Invalid                                               2940\n",
       "White shark                                            163\n",
       "Shark involvement prior to death was not confirmed     105\n",
       "Shark involvement not confirmed                         88\n",
       "Tiger shark                                             73\n",
       "                                                      ... \n",
       "136-kg [300-lb] shark                                    1\n",
       "9-foot shark                                             1\n",
       "Tiger shark, 3.5 m                                       1\n",
       "Spinner shark, 1.2 m to 1.5 m [4' to 5']                 1\n",
       "1.8 m [6'] shark, species identity questionable          1\n",
       "Name: Species2, Length: 1549, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping the Species column to decrease the amount of unique values\n",
    "df2 = df.copy()\n",
    "\n",
    "df2['Species2'] = df2['Species']  # .map(lambda x: 'White shark' if 'White shark' in x else x)\n",
    "df2.Species2.value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèäÔ∏è "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shark_identifier(x):\n",
    "    \n",
    "    #THERE ARE SO MANY ERRORS, let's filter them\n",
    "    \n",
    "    if 'not confirmed' in x.lower():\n",
    "        return \"NOT CONFIRMED\"\n",
    "    if 'unidentified' in x.lower():\n",
    "        return 'NOT CONFIRMED'\n",
    "    if ' or ' in x.lower():\n",
    "        return 'NOT CONFIRMED'\n",
    "    \n",
    "    if 'no shark involvement' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    if 'invalid' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    if 'questionable' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    if 'doubtful' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    \n",
    "        \n",
    "    if 'hoax' in x.lower():\n",
    "        return 'HOAX'\n",
    "    if 'drown' in x.lower():\n",
    "        return 'DROWNED'\n",
    "    if 'stingray' in x.lower():\n",
    "        return 'STINGRAY'\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    #  --- WHO'S THAT POKEMON?---\n",
    "    \n",
    "    if 'white shark' in x.lower():\n",
    "        return \"White shark\"\n",
    "    if 'tiger shark' in x.lower():\n",
    "        return \"Tiger shark\"\n",
    "    if 'bull shark' in x.lower():\n",
    "        return \"Bull shark\"\n",
    "    if 'nurse shark' in x.lower():\n",
    "        return 'Nurse shark'\n",
    "    if 'brown shark' in x.lower():\n",
    "        return 'Brown shark'\n",
    "    if 'mako shark' in x.lower():\n",
    "        return 'Mako Shark'\n",
    "    if 'blue shark' in x.lower():\n",
    "        return 'Blue shark'\n",
    "    if 'bronze whaler shark' in x.lower():\n",
    "        return 'Bronze whaler shark'\n",
    "    if 'blacktip shark' in x.lower():\n",
    "        return 'Blacktip shark'\n",
    "    if 'whitetip shark' in x.lower():\n",
    "        return 'Whitetip shark'\n",
    "    if 'sandbar shark' in x.lower():\n",
    "        return 'Sandbar shark'\n",
    "    if 'lemon shark' in x.lower():\n",
    "        return 'Lemon shark'\n",
    "    if 'hammerhead shark' in x.lower():\n",
    "        return 'Hammerhead shark'\n",
    "    if 'raggedtooth shark' in x.lower():\n",
    "        return 'Raggedtooth shark'\n",
    "    if 'thresher shark' in x.lower():\n",
    "        return 'Thresher shark'\n",
    "    if 'dusky shark' in x.lower():\n",
    "        return 'Dusky shark'\n",
    "    if 'wobbegong shark' in x.lower():\n",
    "        return 'Wobbegong shark'\n",
    "    if 'dusky shark' in x.lower():\n",
    "        return 'Dusky shark'\n",
    "    if 'spinner shark' in x.lower():\n",
    "        return 'Spinner shark'\n",
    "    if 'blue nose shark' in x.lower():\n",
    "        return 'Blue nose shark'\n",
    "    if 'leopard shark' in x.lower():\n",
    "        return 'Leopard shark'\n",
    "    if 'silvertip shark' in x.lower():\n",
    "        return 'Silvertip shark'\n",
    "    if 'gray shark' in x.lower():\n",
    "        return 'Gray shark'\n",
    "    if 'grey shark' in x.lower():\n",
    "        return 'Gray shark'\n",
    "    if 'reef shark' in x.lower():\n",
    "        return 'Reef shark'\n",
    "    if 'carpet shark' in x.lower():\n",
    "        return 'Carpet shark'\n",
    "    if 'whaler shark' in x.lower():\n",
    "        return 'Whaler shark'\n",
    "    \n",
    "    # -- trying to filter sizes --\n",
    "    \n",
    "    if \"\"\"10'\"\"\" in x.lower():\n",
    "        return \"\"\"10' shark\"\"\"\n",
    "    if \"\"\"11'\"\"\" in x.lower():\n",
    "        return \"\"\"11' shark\"\"\"\n",
    "    if \"\"\"12'\"\"\" in x.lower():\n",
    "        return \"\"\"12' shark\"\"\"\n",
    "    if \"\"\"13'\"\"\" in x.lower():\n",
    "        return \"\"\"13' shark\"\"\"\n",
    "    if \"\"\"14'\"\"\" in x.lower():\n",
    "        return \"\"\"14' shark\"\"\"\n",
    "    if \"\"\"15'\"\"\" in x.lower():\n",
    "        return \"\"\"15' shark\"\"\"\n",
    "    if \"\"\"16'\"\"\" in x.lower():\n",
    "        return \"\"\"16' shark\"\"\"\n",
    "    if \"\"\"17'\"\"\" in x.lower():\n",
    "        return \"\"\"17' shark\"\"\"\n",
    "    if \"\"\"18'\"\"\" in x.lower():\n",
    "        return \"\"\"18' shark\"\"\"\n",
    "    if \"\"\"19'\"\"\" in x.lower():\n",
    "        return \"\"\"19' shark\"\"\"\n",
    "    if \"\"\"20'\"\"\" in x.lower():\n",
    "        return \"\"\"20' shark\"\"\"\n",
    "    if \"\"\"21'\"\"\" in x.lower():\n",
    "        return \"\"\"21' shark\"\"\"\n",
    "    \n",
    "    if \"\"\"1'\"\"\" in x.lower():\n",
    "        return \"\"\"1' shark\"\"\"\n",
    "    if \"\"\"2'\"\"\" in x.lower():\n",
    "        return \"\"\"2' shark\"\"\"\n",
    "    if \"\"\"3'\"\"\" in x.lower():\n",
    "        return \"\"\"3' shark\"\"\"\n",
    "    if \"\"\"4'\"\"\" in x.lower():\n",
    "        return \"\"\"4' shark\"\"\"\n",
    "    if \"\"\"5'\"\"\" in x.lower():\n",
    "        return \"\"\"5' shark\"\"\"\n",
    "    if \"\"\"6'\"\"\" in x.lower():\n",
    "        return \"\"\"6' shark\"\"\"\n",
    "    if \"\"\"7'\"\"\" in x.lower():\n",
    "        return \"\"\"7' shark\"\"\"    \n",
    "    if \"\"\"8'\"\"\" in x.lower():\n",
    "        return \"\"\"8' shark\"\"\"\n",
    "    if \"\"\"9'\"\"\" in x.lower():\n",
    "        return \"\"\"9' shark\"\"\"\n",
    "\n",
    "    if 'small shark' in x.lower():\n",
    "        return 'Small shark'\n",
    "    \n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "df2['Species2'] = df2['Species'].map(shark_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INVALID ENTRY                                   3052\n",
      "White shark                                      625\n",
      "NOT CONFIRMED                                    305\n",
      "Tiger shark                                      275\n",
      "Bull shark                                       171\n",
      "4' shark                                         131\n",
      "5' shark                                         127\n",
      "6' shark                                         124\n",
      "Nurse shark                                       94\n",
      "Shark involvement prior to death unconfirmed      68\n",
      "3' shark                                          67\n",
      "Reef shark                                        65\n",
      "Bronze whaler shark                               60\n",
      "Blacktip shark                                    56\n",
      "Small shark                                       55\n",
      "10' shark                                         54\n",
      "Mako Shark                                        53\n",
      "12' shark                                         47\n",
      "Wobbegong shark                                   46\n",
      "Hammerhead shark                                  44\n",
      "Raggedtooth shark                                 43\n",
      "Blue shark                                        38\n",
      "7' shark                                          35\n",
      "Lemon shark                                       34\n",
      "8' shark                                          32\n",
      "2 m shark                                         25\n",
      "2' shark                                          23\n",
      "Whitetip shark                                    23\n",
      "9' shark                                          21\n",
      "Spinner shark                                     20\n",
      "14' shark                                         19\n",
      "3 m shark                                         17\n",
      "13' shark                                         15\n",
      "1.5 m shark                                       13\n",
      "Dusky shark                                       12\n",
      "20' shark                                         12\n",
      "Zambesi shark                                     11\n",
      "15' shark                                         11\n",
      "16' shark                                          9\n",
      "1 m shark                                          9\n",
      "Carpet shark                                       8\n",
      "2.5 m shark                                        7\n",
      "18' shark                                          7\n",
      "1.8 m shark                                        7\n",
      "Basking shark                                      7\n",
      "                                                   6\n",
      "Thought to involve a Zambesi shark                 6\n",
      "Whaler shark                                       6\n",
      "\"sand shark\"                                       5\n",
      "Angel shark                                        5\n",
      "Name: Species2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df2.Species2.value_counts().head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No axis named Fatal for object type <class 'pandas.core.frame.DataFrame'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-89c56d764f3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Species2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Fatal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed)\u001b[0m\n\u001b[1;32m   5797\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mby\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5798\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to supply one of 'by' and 'level'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5799\u001b[0;31m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5801\u001b[0m         return groupby_generic.DataFrameGroupBy(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_axis_number\u001b[0;34m(cls, axis)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No axis named {axis} for object type {cls}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No axis named Fatal for object type <class 'pandas.core.frame.DataFrame'>"
     ]
    }
   ],
   "source": [
    "df2.groupby('Species2', 'Fatal').filter(lambda x : x > 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèäÔ∏è TYPE OF ATTACK\n",
    "- On the Type column, dont count sea disasters, questionable and boatomg\n",
    "- Stardarize\n",
    "- Size of the shark according to Species column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Type.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Type = df.Type.fillna('Invalid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It looks still like some of these pdfs are duplicates, even after dropping duplicates :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# how many times each pdf on the dataframe\n",
    "df3 = df[\"href\"]\n",
    "df3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop dupes and compare lengths\n",
    "df_pdf_nodupes = df.drop_duplicates()\n",
    "\n",
    "len(df) - len(df_pdf_nodupes), 'duped values'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.Country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fatal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since the lengths are not the same, I will check if those duplicated entries are only in this column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I'll look at the rest of the data now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "remove_spaces = lambda x:  x.remove(' ') if ' ' in x else x\n",
    "\"\"\"\n",
    "\n",
    "df_label['Fatal'] = list(\n",
    "                            map(remove_spaces(\n",
    "                            df_label['Fatal']),\n",
    "                            ))\n",
    "\"\"\"\n",
    "    \n",
    "df_label['Fatal'].value_counts()\n",
    "\n",
    "\n",
    "# I want to see the indexes which have a duplicated pdf row\n",
    "\"\"\"\n",
    "\n",
    "dupes = []\n",
    "for a,b in list(df_label['pdf'].duplicated().items()):\n",
    "    if b:\n",
    "        dupes.append(a)\n",
    "dupes \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df_label.loc[dupes]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfx = df_nodupes[\"pdf\"].value_counts() if "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform this to sort the shark species\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_label['Species'].value_counts().items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Use this to fill null values: \n",
    "# df_clean[\"drive\"] = df_clean.drive.fillna(\"NoTransmision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Injuries and types of attack\n",
    "The GSAF categorizes scavenging bites on humans as \"questionable incidents.\"\n",
    "\n",
    "## PROVOKED\n",
    "Provoked attacks occur when a human touches, hooks, nets, or otherwise aggravates the animal. Incidents that occur outside of a shark's natural habitat, such as aquariums and research holding-pens, are considered provoked, as are all incidents involving captured sharks. Sometimes humans inadvertently provoke an attack, such as when a surfer accidentally hits a shark with a surf board.\n",
    "\n",
    "## UNPROVOKED\n",
    "- Hit-and-run attack\n",
    "- Sneak Attack\n",
    "- Bump-and-bite attack \n",
    "\n",
    "For more information on how to differentiate PROVOKED vs UNPROVOKED attacks :\n",
    "https://en.wikipedia.org/wiki/Shark_attack#Types_of_attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there is no column that states if the attack was provoked or not,\n",
    "# I want to analyze the injury column to distinguish between the cases that were provoked\n",
    "# and those that were unprovoked.\n",
    "\n",
    "random.sample(list(df_label.Injury.value_counts().items()),20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorizing  Provoked and  Unprovoked attacks\n",
    "#df_clean.loc[df_clean[\"trany\"].str.startswith(\"M\"),\"trany\"] = \"Manual\"\n",
    "\n",
    "provoked = ['PROVOKED', 'hook', 'shot']\n",
    "#map(lambda words, x : words in x, provoked, df_nodupes.loc[df_nodupes['Injury'].str])\n",
    "df_nodupes.loc[df_nodupes['Injury'].str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodupes.loc[df_nodupes['Injury'].str]\n",
    "\n",
    "# df_provoked = np.where(df_nodupes.Injury.isin(provoked), True, False) \n",
    "\n",
    "# Passing that categorization to a new PROVOKED COLUMN\n",
    "df_nodupes['Provoked'] = df_provoked\n",
    "df_nodupes['Provoked'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.columns) # To know which are the columns in the DF\n",
    "display(df.count()) # To know how much data are we missin on each column\n",
    "display(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label[['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
    "       'Activity', 'Name', 'Sex', 'Age', 'Injury', 'Fatal', 'Time', 'Species',\n",
    "       'Investigator or Source', 'pdf', 'href',\n",
    "       'Case Number.1', 'Case Number.2']].head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
