{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# TO-DO: \n",
    "- how to add the dataset to gitignore?\n",
    "- how can i create a separate module that holds my functions?\n",
    "- change the functions so that they use dictionaries and not "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Shark attacks, a project by Roberto Henr√≠quez Perozo. Data Analytics Bootcamp at IronHack](shark-attacks.png)\n",
    "\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "<center>\n",
    "    <h1> PART I: Data cleaning and exploration</h1>\n",
    "</center>\n",
    "\n",
    "\n",
    "## üé£Ô∏è Step 0 - Basic knowledge\n",
    "To begin the development of this project, it would be good to hold a minimum understanding of `Shark Attacks`.\n",
    "\n",
    "As I did not know much about this topic at the day the project started, I have recurred to the shark-attack wiki: https://en.wikipedia.org/wiki/Shark_attack\n",
    "\n",
    "With this information in mind, below is the process of data exploration, cleaning, and wrangling.\n",
    "\n",
    "\n",
    "## üé£Ô∏è Step 1 - Defining the dataset path, and importing it to begin basic dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To follow along and access the DataSet, download it from KAGGLE using this link\n",
    "# https://www.kaggle.com/teajay/global-shark-attacks\n",
    "\n",
    "# Once you have downloaded the DataSet, change the following `dataset` variable to match the \n",
    "# path where you have saved the 'attacks.csv' file.\n",
    "dataset = 'attacks.csv' \n",
    "\n",
    "\n",
    "df = pd.read_csv(dataset, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will check some basic information about the dataset, in order to formulate a more educated hypothesis which we could actually put to test with the data available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I notice that the shape of the `df` with no duplicates is very small when compared to the whole `df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåäÔ∏è  FUNCT\n",
    "This comparison could be turned into its own function, as it will be executed quite often"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before (25723, 24)\n",
      "after (6312, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Name', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time',\n",
       "       'Species ', 'Investigator or Source', 'pdf', 'href formula', 'href',\n",
       "       'Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22',\n",
       "       'Unnamed: 23'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'll delete de duplicated rows\n",
    "print('before', df.shape)\n",
    "df = df.drop_duplicates()\n",
    "print('after', df.shape)\n",
    "\n",
    "# And also take a look at the columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        25-Jun-2018\n",
       "1        18-Jun-2018\n",
       "2        09-Jun-2018\n",
       "3        08-Jun-2018\n",
       "4        04-Jun-2018\n",
       "            ...     \n",
       "6307             NaN\n",
       "6308             NaN\n",
       "6309             NaN\n",
       "8702             NaN\n",
       "25722            NaN\n",
       "Name: Date, Length: 6312, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I want to take a look at the time structures\n",
    "df.Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>6303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>6302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>6299.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6309.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6310.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8702</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25722</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6312 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Case Number.1 Case Number.2  original order Unnamed: 22 Unnamed: 23\n",
       "0        2018.06.25    2018.06.25          6303.0         NaN         NaN\n",
       "1        2018.06.18    2018.06.18          6302.0         NaN         NaN\n",
       "2        2018.06.09    2018.06.09          6301.0         NaN         NaN\n",
       "3        2018.06.08    2018.06.08          6300.0         NaN         NaN\n",
       "4        2018.06.04    2018.06.04          6299.0         NaN         NaN\n",
       "...             ...           ...             ...         ...         ...\n",
       "6307            NaN           NaN          6309.0         NaN         NaN\n",
       "6308            NaN           NaN          6310.0         NaN         NaN\n",
       "6309            NaN           NaN             NaN         NaN         NaN\n",
       "8702            NaN           NaN             NaN         NaN         NaN\n",
       "25722           NaN           NaN             NaN         NaN         NaN\n",
       "\n",
       "[6312 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I want to see what is the data on the last couple\n",
    "# of columns which have unexplicit labels\n",
    "df[['Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22', 'Unnamed: 23']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6312, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Case Number.1       10\n",
       "Case Number.2       10\n",
       "original order       3\n",
       "Unnamed: 22       6311\n",
       "Unnamed: 23       6310\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Too many null values on the last two columns... let's count them\n",
    "print(df.shape)\n",
    "df[['Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22', 'Unnamed: 23']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there is only 1 value in the 'Unnamed: 22' column, and 2 values in the\n",
    "# 'Unnamed: 22' column, I'll not consider this data for my analysis.\n",
    "df = df.drop(columns=['Unnamed: 22', 'Unnamed: 23'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2007.10.13      1\n",
       "1962.12.09      1\n",
       "1993.02.18      1\n",
       "1872.00.00      1\n",
       "1920.00.00.a    1\n",
       "               ..\n",
       "1913.08.27.R    2\n",
       "2009.12.18      2\n",
       "2006.09.02      2\n",
       "2013.10.05      2\n",
       "1962.06.11.b    2\n",
       "Name: Case Number.1, Length: 6285, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following columns seemed a little bit rare, so i do a value count to find out what they are about\n",
    "df['Case Number.1'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1956.06.20      1\n",
       "1962.12.09      1\n",
       "1993.02.18      1\n",
       "1872.00.00      1\n",
       "1920.00.00.a    1\n",
       "               ..\n",
       "1990.05.10      2\n",
       "1962.06.11.b    2\n",
       "2005.04.06      2\n",
       "2012.09.02.b    2\n",
       "1920.00.00.b    2\n",
       "Name: Case Number.2, Length: 6286, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Case Number.2'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåäÔ∏è Creating a Function\n",
    "\n",
    "After some thought and googling, it seems like these are some sort of notation used to categorize and order the shark attacks.\n",
    "\n",
    "They also use the a notation that includes dates. \n",
    "## Is it the same as the Date on the Date column?\n",
    "\n",
    "To find out, I wanted to pick random samples of the dataframe, but python's built-in `random` module kept giving me trouble when I tried to use it alongside pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object sampler at 0x7f10b1181570>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It was better to make it into a function\n",
    "#VER 03\n",
    "def sampler(df, column, sample_size):\n",
    "# This function generates an iterator out of random rows from a pandas dataframe's specific column\n",
    "    \n",
    "    # Defining how many samples to fetch from the df\n",
    "    for i in range(sample_size):\n",
    "        \n",
    "        # Now a random index is generated out of the total length of the column...\n",
    "        i = random.choice(range(len(df[column])))\n",
    "        # ... to return the data values in that index as an iterator:\n",
    "        yield df.iloc[i][column]\n",
    "        \n",
    "        # For future versions, it would be good to look at how I can return the\n",
    "        # data as a tupple with just the data, and not have it return a formatted string\n",
    "        # or even better, a pandas dataframe with the results\n",
    "\n",
    "\n",
    "# Now let's try it out\n",
    "sampler(df, ['Date', 'Case Number.1', 'Case Number.2'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Date             6-Aug-2005\n",
       " Case Number.1    2005.08.06\n",
       " Case Number.2    2005.08.06\n",
       " Name: 1562, dtype: object,\n",
       " Date               Mar-1948\n",
       " Case Number.1    1948.03.00\n",
       " Case Number.2    1948.03.00\n",
       " Name: 4551, dtype: object,\n",
       " Date             Reported 29-Nov-2005\n",
       " Case Number.1            2005.11.29.R\n",
       " Case Number.2            2005.11.29.R\n",
       " Name: 1520, dtype: object,\n",
       " Date             18-May-2004\n",
       " Case Number.1     2004.05.18\n",
       " Case Number.2     2004.05.18\n",
       " Name: 1673, dtype: object,\n",
       " Date             11-Sep-1992\n",
       " Case Number.1     1992.09.11\n",
       " Case Number.2     1992.09.11\n",
       " Name: 2534, dtype: object,\n",
       " Date                     1954\n",
       " Case Number.1    1954.00.00.e\n",
       " Case Number.2    1954.00.00.e\n",
       " Name: 4351, dtype: object,\n",
       " Date             31-Jul-2011\n",
       " Case Number.1     2011.07.31\n",
       " Case Number.2     2011.07.31\n",
       " Name: 890, dtype: object,\n",
       " Date             23-May-2012\n",
       " Case Number.1     2012.05.23\n",
       " Case Number.2     2012.05.23\n",
       " Name: 792, dtype: object,\n",
       " Date             Reported 07-Aug-1872\n",
       " Case Number.1            1872.08.07.R\n",
       " Case Number.2            1872.08.07.R\n",
       " Name: 5897, dtype: object,\n",
       " Date             04-Mar-1989\n",
       " Case Number.1     1989.03.04\n",
       " Case Number.2     1989.03.04\n",
       " Name: 2691, dtype: object]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since sampler generates iterators, list() must be used to see its contents\n",
    "list(sampler(df, ['Date', 'Case Number.1', 'Case Number.2'], 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è\n",
    "From this output, we can see that the `Case Number` Columnns are actually replicating the info that we already have on the `Date` column. Therefore, we will drop both `Case Number` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>original order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>No injury to occupant, outrigger canoe and pad...</td>\n",
       "      <td>N</td>\n",
       "      <td>18h00</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6303.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson¬†McNeely</td>\n",
       "      <td>F</td>\n",
       "      <td>11</td>\n",
       "      <td>Minor injury to left thigh</td>\n",
       "      <td>N</td>\n",
       "      <td>14h00  -15h00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>M</td>\n",
       "      <td>48</td>\n",
       "      <td>Injury to left lower leg from surfboard skeg</td>\n",
       "      <td>N</td>\n",
       "      <td>07h45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6301.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>08-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Arrawarra Headland</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minor injury to lower leg</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 m shark</td>\n",
       "      <td>B. Myatt, GSAF</td>\n",
       "      <td>2018.06.08-Arrawarra.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>04-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>Colima</td>\n",
       "      <td>La Ticla</td>\n",
       "      <td>Free diving</td>\n",
       "      <td>Gustavo Ramos</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lacerations to leg &amp; hand shark PROVOKED INCIDENT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tiger shark, 3m</td>\n",
       "      <td>A .Kipper</td>\n",
       "      <td>2018.06.04-Ramos.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8702</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25722</th>\n",
       "      <td>xx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6312 rows √ó 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Case Number         Date    Year        Type    Country  \\\n",
       "0      2018.06.25  25-Jun-2018  2018.0     Boating        USA   \n",
       "1      2018.06.18  18-Jun-2018  2018.0  Unprovoked        USA   \n",
       "2      2018.06.09  09-Jun-2018  2018.0     Invalid        USA   \n",
       "3      2018.06.08  08-Jun-2018  2018.0  Unprovoked  AUSTRALIA   \n",
       "4      2018.06.04  04-Jun-2018  2018.0    Provoked     MEXICO   \n",
       "...           ...          ...     ...         ...        ...   \n",
       "6307            0          NaN     NaN         NaN        NaN   \n",
       "6308            0          NaN     NaN         NaN        NaN   \n",
       "6309            0          NaN     NaN         NaN        NaN   \n",
       "8702          NaN          NaN     NaN         NaN        NaN   \n",
       "25722          xx          NaN     NaN         NaN        NaN   \n",
       "\n",
       "                  Area                        Location     Activity  \\\n",
       "0           California     Oceanside, San Diego County     Paddling   \n",
       "1              Georgia  St. Simon Island, Glynn County     Standing   \n",
       "2               Hawaii                    Habush, Oahu      Surfing   \n",
       "3      New South Wales              Arrawarra Headland      Surfing   \n",
       "4               Colima                        La Ticla  Free diving   \n",
       "...                ...                             ...          ...   \n",
       "6307               NaN                             NaN          NaN   \n",
       "6308               NaN                             NaN          NaN   \n",
       "6309               NaN                             NaN          NaN   \n",
       "8702               NaN                             NaN          NaN   \n",
       "25722              NaN                             NaN          NaN   \n",
       "\n",
       "                  Name Sex   Age  \\\n",
       "0          Julie Wolfe    F   57   \n",
       "1      Adyson¬†McNeely     F   11   \n",
       "2          John Denges    M   48   \n",
       "3                 male    M  NaN   \n",
       "4       Gustavo Ramos     M  NaN   \n",
       "...                ...  ...  ...   \n",
       "6307               NaN  NaN  NaN   \n",
       "6308               NaN  NaN  NaN   \n",
       "6309               NaN  NaN  NaN   \n",
       "8702               NaN  NaN  NaN   \n",
       "25722              NaN  NaN  NaN   \n",
       "\n",
       "                                                  Injury Fatal (Y/N)  \\\n",
       "0      No injury to occupant, outrigger canoe and pad...           N   \n",
       "1                             Minor injury to left thigh           N   \n",
       "2           Injury to left lower leg from surfboard skeg           N   \n",
       "3                              Minor injury to lower leg           N   \n",
       "4      Lacerations to leg & hand shark PROVOKED INCIDENT           N   \n",
       "...                                                  ...         ...   \n",
       "6307                                                 NaN         NaN   \n",
       "6308                                                 NaN         NaN   \n",
       "6309                                                 NaN         NaN   \n",
       "8702                                                 NaN         NaN   \n",
       "25722                                                NaN         NaN   \n",
       "\n",
       "                Time         Species           Investigator or Source  \\\n",
       "0              18h00      White shark                R. Collier, GSAF   \n",
       "1      14h00  -15h00              NaN  K.McMurray, TrackingSharks.com   \n",
       "2              07h45              NaN  K.McMurray, TrackingSharks.com   \n",
       "3                NaN        2 m shark                  B. Myatt, GSAF   \n",
       "4                NaN  Tiger shark, 3m                       A .Kipper   \n",
       "...              ...              ...                             ...   \n",
       "6307             NaN              NaN                             NaN   \n",
       "6308             NaN              NaN                             NaN   \n",
       "6309             NaN              NaN                             NaN   \n",
       "8702             NaN              NaN                             NaN   \n",
       "25722            NaN              NaN                             NaN   \n",
       "\n",
       "                            pdf  \\\n",
       "0          2018.06.25-Wolfe.pdf   \n",
       "1        2018.06.18-McNeely.pdf   \n",
       "2         2018.06.09-Denges.pdf   \n",
       "3      2018.06.08-Arrawarra.pdf   \n",
       "4          2018.06.04-Ramos.pdf   \n",
       "...                         ...   \n",
       "6307                        NaN   \n",
       "6308                        NaN   \n",
       "6309                        NaN   \n",
       "8702                        NaN   \n",
       "25722                       NaN   \n",
       "\n",
       "                                            href formula  \\\n",
       "0      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "3      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "4      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "...                                                  ...   \n",
       "6307                                                 NaN   \n",
       "6308                                                 NaN   \n",
       "6309                                                 NaN   \n",
       "8702                                                 NaN   \n",
       "25722                                                NaN   \n",
       "\n",
       "                                                    href  original order  \n",
       "0      http://sharkattackfile.net/spreadsheets/pdf_di...          6303.0  \n",
       "1      http://sharkattackfile.net/spreadsheets/pdf_di...          6302.0  \n",
       "2      http://sharkattackfile.net/spreadsheets/pdf_di...          6301.0  \n",
       "3      http://sharkattackfile.net/spreadsheets/pdf_di...          6300.0  \n",
       "4      http://sharkattackfile.net/spreadsheets/pdf_di...          6299.0  \n",
       "...                                                  ...             ...  \n",
       "6307                                                 NaN          6309.0  \n",
       "6308                                                 NaN          6310.0  \n",
       "6309                                                 NaN             NaN  \n",
       "8702                                                 NaN             NaN  \n",
       "25722                                                NaN             NaN  \n",
       "\n",
       "[6312 rows x 20 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['Case Number.1', 'Case Number.2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a closer look at the tail of the df, we notice that the last couple of rows are still holding many null values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>original order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6297</th>\n",
       "      <td>ND.0005</td>\n",
       "      <td>Before 1903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>Roebuck Bay</td>\n",
       "      <td>Diving</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H. Taunton; N. Bartlett,  p. 234</td>\n",
       "      <td>ND-0005-RoebuckBay.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6298</th>\n",
       "      <td>ND.0004</td>\n",
       "      <td>Before 1903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl diving</td>\n",
       "      <td>Ahmun</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H. Taunton; N. Bartlett,  pp. 233-234</td>\n",
       "      <td>ND-0004-Ahmun.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6299</th>\n",
       "      <td>ND.0003</td>\n",
       "      <td>1900-1905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Ocracoke Inlet</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Coast Guard personnel</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F. Schwartz, p.23; C. Creswell, GSAF</td>\n",
       "      <td>ND-0003-Ocracoke_1900-1905.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6300</th>\n",
       "      <td>ND.0002</td>\n",
       "      <td>1883-1889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>PANAMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Panama Bay 8¬∫N, 79¬∫W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jules Patterson</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Sun, 10/20/1938</td>\n",
       "      <td>ND-0002-JulesPatterson.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6301</th>\n",
       "      <td>ND.0001</td>\n",
       "      <td>1845-1853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>CEYLON (SRI LANKA)</td>\n",
       "      <td>Eastern Province</td>\n",
       "      <td>Below the English fort, Trincomalee</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>FATAL. \"Shark bit him in half, carrying away t...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S.W. Baker</td>\n",
       "      <td>ND-0001-Ceylon.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6302</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6303</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6305.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6304</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6305</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6306</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6308.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8702</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25722</th>\n",
       "      <td>xx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Case Number         Date  Year        Type             Country  \\\n",
       "6297      ND.0005  Before 1903   0.0  Unprovoked           AUSTRALIA   \n",
       "6298      ND.0004  Before 1903   0.0  Unprovoked           AUSTRALIA   \n",
       "6299      ND.0003    1900-1905   0.0  Unprovoked                 USA   \n",
       "6300      ND.0002    1883-1889   0.0  Unprovoked              PANAMA   \n",
       "6301      ND.0001    1845-1853   0.0  Unprovoked  CEYLON (SRI LANKA)   \n",
       "6302            0          NaN   NaN         NaN                 NaN   \n",
       "6303            0          NaN   NaN         NaN                 NaN   \n",
       "6304            0          NaN   NaN         NaN                 NaN   \n",
       "6305            0          NaN   NaN         NaN                 NaN   \n",
       "6306            0          NaN   NaN         NaN                 NaN   \n",
       "6307            0          NaN   NaN         NaN                 NaN   \n",
       "6308            0          NaN   NaN         NaN                 NaN   \n",
       "6309            0          NaN   NaN         NaN                 NaN   \n",
       "8702          NaN          NaN   NaN         NaN                 NaN   \n",
       "25722          xx          NaN   NaN         NaN                 NaN   \n",
       "\n",
       "                    Area                             Location      Activity  \\\n",
       "6297   Western Australia                          Roebuck Bay        Diving   \n",
       "6298   Western Australia                                  NaN  Pearl diving   \n",
       "6299      North Carolina                       Ocracoke Inlet      Swimming   \n",
       "6300                 NaN                 Panama Bay 8¬∫N, 79¬∫W           NaN   \n",
       "6301    Eastern Province  Below the English fort, Trincomalee      Swimming   \n",
       "6302                 NaN                                  NaN           NaN   \n",
       "6303                 NaN                                  NaN           NaN   \n",
       "6304                 NaN                                  NaN           NaN   \n",
       "6305                 NaN                                  NaN           NaN   \n",
       "6306                 NaN                                  NaN           NaN   \n",
       "6307                 NaN                                  NaN           NaN   \n",
       "6308                 NaN                                  NaN           NaN   \n",
       "6309                 NaN                                  NaN           NaN   \n",
       "8702                 NaN                                  NaN           NaN   \n",
       "25722                NaN                                  NaN           NaN   \n",
       "\n",
       "                        Name Sex   Age  \\\n",
       "6297                    male    M  NaN   \n",
       "6298                   Ahmun    M  NaN   \n",
       "6299   Coast Guard personnel    M  NaN   \n",
       "6300         Jules Patterson    M  NaN   \n",
       "6301                    male    M   15   \n",
       "6302                     NaN  NaN  NaN   \n",
       "6303                     NaN  NaN  NaN   \n",
       "6304                     NaN  NaN  NaN   \n",
       "6305                     NaN  NaN  NaN   \n",
       "6306                     NaN  NaN  NaN   \n",
       "6307                     NaN  NaN  NaN   \n",
       "6308                     NaN  NaN  NaN   \n",
       "6309                     NaN  NaN  NaN   \n",
       "8702                     NaN  NaN  NaN   \n",
       "25722                    NaN  NaN  NaN   \n",
       "\n",
       "                                                  Injury Fatal (Y/N) Time  \\\n",
       "6297                                               FATAL           Y  NaN   \n",
       "6298                                               FATAL           Y  NaN   \n",
       "6299                                               FATAL           Y  NaN   \n",
       "6300                                               FATAL           Y  NaN   \n",
       "6301   FATAL. \"Shark bit him in half, carrying away t...           Y  NaN   \n",
       "6302                                                 NaN         NaN  NaN   \n",
       "6303                                                 NaN         NaN  NaN   \n",
       "6304                                                 NaN         NaN  NaN   \n",
       "6305                                                 NaN         NaN  NaN   \n",
       "6306                                                 NaN         NaN  NaN   \n",
       "6307                                                 NaN         NaN  NaN   \n",
       "6308                                                 NaN         NaN  NaN   \n",
       "6309                                                 NaN         NaN  NaN   \n",
       "8702                                                 NaN         NaN  NaN   \n",
       "25722                                                NaN         NaN  NaN   \n",
       "\n",
       "      Species                  Investigator or Source  \\\n",
       "6297       NaN       H. Taunton; N. Bartlett,  p. 234   \n",
       "6298       NaN  H. Taunton; N. Bartlett,  pp. 233-234   \n",
       "6299       NaN   F. Schwartz, p.23; C. Creswell, GSAF   \n",
       "6300       NaN                    The Sun, 10/20/1938   \n",
       "6301       NaN                             S.W. Baker   \n",
       "6302       NaN                                    NaN   \n",
       "6303       NaN                                    NaN   \n",
       "6304       NaN                                    NaN   \n",
       "6305       NaN                                    NaN   \n",
       "6306       NaN                                    NaN   \n",
       "6307       NaN                                    NaN   \n",
       "6308       NaN                                    NaN   \n",
       "6309       NaN                                    NaN   \n",
       "8702       NaN                                    NaN   \n",
       "25722      NaN                                    NaN   \n",
       "\n",
       "                                  pdf  \\\n",
       "6297           ND-0005-RoebuckBay.pdf   \n",
       "6298                ND-0004-Ahmun.pdf   \n",
       "6299   ND-0003-Ocracoke_1900-1905.pdf   \n",
       "6300       ND-0002-JulesPatterson.pdf   \n",
       "6301               ND-0001-Ceylon.pdf   \n",
       "6302                              NaN   \n",
       "6303                              NaN   \n",
       "6304                              NaN   \n",
       "6305                              NaN   \n",
       "6306                              NaN   \n",
       "6307                              NaN   \n",
       "6308                              NaN   \n",
       "6309                              NaN   \n",
       "8702                              NaN   \n",
       "25722                             NaN   \n",
       "\n",
       "                                            href formula  \\\n",
       "6297   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6298   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6299   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6300   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6301   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6302                                                 NaN   \n",
       "6303                                                 NaN   \n",
       "6304                                                 NaN   \n",
       "6305                                                 NaN   \n",
       "6306                                                 NaN   \n",
       "6307                                                 NaN   \n",
       "6308                                                 NaN   \n",
       "6309                                                 NaN   \n",
       "8702                                                 NaN   \n",
       "25722                                                NaN   \n",
       "\n",
       "                                                    href  original order  \n",
       "6297   http://sharkattackfile.net/spreadsheets/pdf_di...             6.0  \n",
       "6298   http://sharkattackfile.net/spreadsheets/pdf_di...             5.0  \n",
       "6299   http://sharkattackfile.net/spreadsheets/pdf_di...             4.0  \n",
       "6300   http://sharkattackfile.net/spreadsheets/pdf_di...             3.0  \n",
       "6301   http://sharkattackfile.net/spreadsheets/pdf_di...             2.0  \n",
       "6302                                                 NaN          6304.0  \n",
       "6303                                                 NaN          6305.0  \n",
       "6304                                                 NaN          6306.0  \n",
       "6305                                                 NaN          6307.0  \n",
       "6306                                                 NaN          6308.0  \n",
       "6307                                                 NaN          6309.0  \n",
       "6308                                                 NaN          6310.0  \n",
       "6309                                                 NaN             NaN  \n",
       "8702                                                 NaN             NaN  \n",
       "25722                                                NaN             NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it's only the last 10 columns which have the nulls.\n",
    "df.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#since they are only 10 instances, we can drop them manually using their index:\n",
    "df = df.drop([6302, 6303,6304,6305,6306,6307,6308,6309,8702,25722])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>original order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6297</th>\n",
       "      <td>ND.0005</td>\n",
       "      <td>Before 1903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>Roebuck Bay</td>\n",
       "      <td>Diving</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H. Taunton; N. Bartlett,  p. 234</td>\n",
       "      <td>ND-0005-RoebuckBay.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6298</th>\n",
       "      <td>ND.0004</td>\n",
       "      <td>Before 1903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl diving</td>\n",
       "      <td>Ahmun</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H. Taunton; N. Bartlett,  pp. 233-234</td>\n",
       "      <td>ND-0004-Ahmun.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6299</th>\n",
       "      <td>ND.0003</td>\n",
       "      <td>1900-1905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Ocracoke Inlet</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Coast Guard personnel</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F. Schwartz, p.23; C. Creswell, GSAF</td>\n",
       "      <td>ND-0003-Ocracoke_1900-1905.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6300</th>\n",
       "      <td>ND.0002</td>\n",
       "      <td>1883-1889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>PANAMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Panama Bay 8¬∫N, 79¬∫W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jules Patterson</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Sun, 10/20/1938</td>\n",
       "      <td>ND-0002-JulesPatterson.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6301</th>\n",
       "      <td>ND.0001</td>\n",
       "      <td>1845-1853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>CEYLON (SRI LANKA)</td>\n",
       "      <td>Eastern Province</td>\n",
       "      <td>Below the English fort, Trincomalee</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>FATAL. \"Shark bit him in half, carrying away t...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S.W. Baker</td>\n",
       "      <td>ND-0001-Ceylon.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Case Number         Date  Year        Type             Country  \\\n",
       "6297     ND.0005  Before 1903   0.0  Unprovoked           AUSTRALIA   \n",
       "6298     ND.0004  Before 1903   0.0  Unprovoked           AUSTRALIA   \n",
       "6299     ND.0003    1900-1905   0.0  Unprovoked                 USA   \n",
       "6300     ND.0002    1883-1889   0.0  Unprovoked              PANAMA   \n",
       "6301     ND.0001    1845-1853   0.0  Unprovoked  CEYLON (SRI LANKA)   \n",
       "\n",
       "                   Area                             Location      Activity  \\\n",
       "6297  Western Australia                          Roebuck Bay        Diving   \n",
       "6298  Western Australia                                  NaN  Pearl diving   \n",
       "6299     North Carolina                       Ocracoke Inlet      Swimming   \n",
       "6300                NaN                 Panama Bay 8¬∫N, 79¬∫W           NaN   \n",
       "6301   Eastern Province  Below the English fort, Trincomalee      Swimming   \n",
       "\n",
       "                       Name Sex   Age  \\\n",
       "6297                   male    M  NaN   \n",
       "6298                  Ahmun    M  NaN   \n",
       "6299  Coast Guard personnel    M  NaN   \n",
       "6300        Jules Patterson    M  NaN   \n",
       "6301                   male    M   15   \n",
       "\n",
       "                                                 Injury Fatal (Y/N) Time  \\\n",
       "6297                                              FATAL           Y  NaN   \n",
       "6298                                              FATAL           Y  NaN   \n",
       "6299                                              FATAL           Y  NaN   \n",
       "6300                                              FATAL           Y  NaN   \n",
       "6301  FATAL. \"Shark bit him in half, carrying away t...           Y  NaN   \n",
       "\n",
       "     Species                  Investigator or Source  \\\n",
       "6297      NaN       H. Taunton; N. Bartlett,  p. 234   \n",
       "6298      NaN  H. Taunton; N. Bartlett,  pp. 233-234   \n",
       "6299      NaN   F. Schwartz, p.23; C. Creswell, GSAF   \n",
       "6300      NaN                    The Sun, 10/20/1938   \n",
       "6301      NaN                             S.W. Baker   \n",
       "\n",
       "                                 pdf  \\\n",
       "6297          ND-0005-RoebuckBay.pdf   \n",
       "6298               ND-0004-Ahmun.pdf   \n",
       "6299  ND-0003-Ocracoke_1900-1905.pdf   \n",
       "6300      ND-0002-JulesPatterson.pdf   \n",
       "6301              ND-0001-Ceylon.pdf   \n",
       "\n",
       "                                           href formula  \\\n",
       "6297  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6298  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6299  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6300  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6301  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                   href  original order  \n",
       "6297  http://sharkattackfile.net/spreadsheets/pdf_di...             6.0  \n",
       "6298  http://sharkattackfile.net/spreadsheets/pdf_di...             5.0  \n",
       "6299  http://sharkattackfile.net/spreadsheets/pdf_di...             4.0  \n",
       "6300  http://sharkattackfile.net/spreadsheets/pdf_di...             3.0  \n",
       "6301  http://sharkattackfile.net/spreadsheets/pdf_di...             2.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü¶àÔ∏è\n",
    "Whith this cleaned dataframe, we can look deeper into the actual data.\n",
    "\n",
    "Notice that we still have additional columns that are not giving us any **'meaty information'** !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are just old indexes\n",
    "# df['original order'].value_counts()\n",
    "\n",
    "# And these are only the titles of the pdfs\n",
    "# df['pdf'].value_counts()\n",
    "\n",
    "# let's get rid of them\n",
    "df = df.drop(columns = ['pdf', 'original order'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü¶àÔ∏è\n",
    "The `href` and `href formula` columns look very similar, but since they can't be read on the DataFrame that pandas provides, we'll try to use our `sampler()` function again to compare them both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[href            http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " href formula    http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " Name: 545, dtype: object,\n",
       " href            http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " href formula    http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " Name: 1433, dtype: object]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sampler(df, ['href', 'href formula'],2))\n",
    "# This however, returns invalid links which are not accurately represented.\n",
    "# example: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü¶àÔ∏è\n",
    "Well.. Oops?\n",
    "To actually see the contents, I've resorted to two separate methods, `random.sample` and a `for` loop.\n",
    "\n",
    "These cells can be re-run a couple of times to make sure the data in the columns is homogeneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://sharkattackfile.net/spreadsheets/pdf_directory/1894.06.15.a-R-Rover.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1863.00.00.R2-Ceylon.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1984.11.11-Stetson.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/2010.02.06.a-RivieraBeach.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1858.01.09.R-Tonga.pdf']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['http://sharkattackfile.net/spreadsheets/pdf_directory/2014.10.18-Roberson.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/2005.03.05-SolomonIslands.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/2002.05.31.b-Fontan.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1986.11.04-Lund.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1959.08.12-Tomaz.pdf']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# With Random sample\n",
    "display(random.sample(list(df['href']), 5))\n",
    "display(random.sample(list(df['href formula']), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 724, href:         http://sharkattackfile.net/spreadsheets/pdf_directory/2012.11.04.b-Riglos.pdf\n",
      "index: 724, href formula: http://sharkattackfile.net/spreadsheets/pdf_directory/2012.11.04.b-Riglos.pdf\n",
      "index: 706, href:         http://sharkattackfile.net/spreadsheets/pdf_directory/2013.01.26-boat.pdf\n",
      "index: 706, href formula: http://sharkattackfile.net/spreadsheets/pdf_directory/2013.01.26-boat.pdf\n",
      "index: 111, href:         http://sharkattackfile.net/spreadsheets/pdf_directory/2017.07.24-Matsu.pdf\n",
      "index: 111, href formula: http://sharkattackfile.net/spreadsheets/pdf_directory/2017.07.24-Matsu.pdf\n",
      "index: 104, href:         http://sharkattackfile.net/spreadsheets/pdf_directory/2017.08.03-Massachusetts.pdf\n",
      "index: 104, href formula: http://sharkattackfile.net/spreadsheets/pdf_directory/2017.08.03-Massachusetts.pdf\n",
      "index: 287, href:         http://sharkattackfile.net/spreadsheets/pdf_directory/2016.04.13-Senkowicz.pdf\n",
      "index: 287, href formula: http://sharkattackfile.net/spreadsheets/pdf_directory/2016.04.13-Senkowicz.pdf\n"
     ]
    }
   ],
   "source": [
    "# With a FOR loop\n",
    "for i in range(5):\n",
    "    e = random.choice(range(1000))\n",
    "    print(f\"index: {e}, href:         {df.iloc[e]['href']}\")\n",
    "    print(f\"index: {e}, href formula: {df.iloc[e]['href formula']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è\n",
    "The links on both columns seem to match, most of the times anyways.\n",
    "\n",
    "In some cases, the `href` seems to have an duplication on its links which corrupted them and made them innaccessible.\n",
    "\n",
    "However, the `href formula` actually saved the correct URL format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://sharkattackfile.net/spreadsheets/pdf_directory/http://sharkattackfile.net/spreadsheets/pdf_directory/2015.11.15.a-Engelman.pdf\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/2015.11.15.a-Engelman.pdf\n",
      "\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/http://sharkattackfile.net/spreadsheets/pdf_directory/2015.12.21.a-Brazil.pdf\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/2015.12.21.a-Brazil.pdf\n",
      "\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/http://sharkattackfile.net/spreadsheets/pdf_directory/2014.00.00.b-OceanicWhitetip.pdf\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/2014.00.00.b-OceanicWhitetip.pdf\n",
      "\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/http://sharkattackfile.net/spreadsheets/pdf_directory/2014.04.03-Armstrong.pdf\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/2014.04.03-Armstrong.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examples of the corrupted link versus their working counterpart\n",
    "print(df.iloc[332]['href']), print(df.iloc[332]['href formula'])\n",
    "print()\n",
    "print(df.iloc[324]['href']), print(df.iloc[324]['href formula'])\n",
    "print()\n",
    "print(df.iloc[588]['href']), print(df.iloc[588]['href formula'])\n",
    "print()\n",
    "print(df.iloc[569]['href']), print(df.iloc[569]['href formula'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the sake of simplicity, we will drop the `href` column, and replace it with the `href formula`\n",
    "df = df.drop(columns='href')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèäÔ∏è IDEAS:\n",
    "- The pdfs presented on the links seem quite structured\n",
    " \n",
    " - It could be possible to parse them later down the road and use a **REGEX** to find more data\n",
    " \n",
    " - Like, adding a column that lists the **'Moon Phase'** described on some of the pdfs\n",
    "\n",
    "- I also have ran query a few times to notice that all pdfs have actually been uploaded to the same website and have the same naming structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è\n",
    "\n",
    "Some column names can be simplified, and some have unnecesary white spaces.\n",
    " \n",
    " Let's fix that right away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Name', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time',\n",
       "       'Species ', 'Investigator or Source', 'href formula'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The column with the name of the victims does not bring much relevant information to our study\n",
    "df = df.drop(columns='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CaseNum', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Sex', 'Age', 'Injury', 'Fatal', 'Time', 'Species',\n",
       "       'Source', 'href'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df\n",
    "df.columns = ['CaseNum', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
    "       'Activity', 'Sex', 'Age', 'Injury', 'Fatal', 'Time',\n",
    "       'Species', 'Source', 'href']\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèäÔ∏è SPECIES IDEAS: \n",
    "- create a standardized column for species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è\n",
    "Many of the values from the Species column are `nulls`. We'll fill them with the same `Invalid` value that other cells already have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "White shark                                           163\n",
       "Shark involvement prior to death was not confirmed    105\n",
       "Invalid                                               102\n",
       "Shark involvement not confirmed                        88\n",
       "Tiger shark                                            73\n",
       "                                                     ... \n",
       "Oceanic whitetip sharks were in the vicinity            1\n",
       "15'                                                     1\n",
       "2.4 m shark                                             1\n",
       "White shark, 2 m to 4 m [6'9\" to 13']                   1\n",
       "1.4 m [4'6\"] blacktip shark                             1\n",
       "Name: Species, Length: 1549, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BEFORE\n",
    "df.Species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Invalid                                               2940\n",
       "White shark                                            163\n",
       "Shark involvement prior to death was not confirmed     105\n",
       "Shark involvement not confirmed                         88\n",
       "Tiger shark                                             73\n",
       "                                                      ... \n",
       "Oceanic whitetip sharks were in the vicinity             1\n",
       "15'                                                      1\n",
       "2.4 m shark                                              1\n",
       "White shark, 2 m to 4 m [6'9\" to 13']                    1\n",
       "1.4 m [4'6\"] blacktip shark                              1\n",
       "Name: Species, Length: 1549, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Species = df.Species.fillna('Invalid')\n",
    "\n",
    "#AFTER\n",
    "df.Species.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        6302\n",
       "unique       1549\n",
       "top       Invalid\n",
       "freq         2940\n",
       "Name: Species, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With the .describe() method, we can see that there are 1549 unique values in this column\n",
    "# It would be interesting to create a new column which narrows this down to less unique values.\n",
    "df.Species.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è \n",
    "\n",
    "[Can you guess the Pok√©mon?](https://i.ytimg.com/vi/mg1A94zBWBw/hqdefault.jpg)\n",
    "\n",
    "There are more than 400 species of sharks, and while lurking around the `Species` column you can find all sort of weird animals. Did you know there's even one species of shark known as the *'Cookie Cutter shark'* ?\n",
    "\n",
    "I certainly had no clue. \n",
    "\n",
    "Here I tried to sort a bit of the data, by creating a secondary column which *mapped* the different species, while also taking out possible confusions. \n",
    "\n",
    "- *note: the scrutiny for this categorization is quite laxed, as this project is more an exercise with data and less a research paper. The data, however, can be processed even further by forking this github repo.*\n",
    "\n",
    "Below is the process of creating such a secondary table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Invalid                                               2940\n",
       "White shark                                            163\n",
       "Shark involvement prior to death was not confirmed     105\n",
       "Shark involvement not confirmed                         88\n",
       "Tiger shark                                             73\n",
       "                                                      ... \n",
       "Oceanic whitetip sharks were in the vicinity             1\n",
       "15'                                                      1\n",
       "2.4 m shark                                              1\n",
       "White shark, 2 m to 4 m [6'9\" to 13']                    1\n",
       "1.4 m [4'6\"] blacktip shark                              1\n",
       "Name: Species2, Length: 1549, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping the Species column to decrease the amount of unique values\n",
    "df['Species2'] = df['Species']  # .map(lambda x: 'White shark' if 'White shark' in x else x)\n",
    "df.Species2.value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèäÔ∏è "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shark_identifier2(x):\n",
    "    \n",
    "    #THERE ARE SO MANY ERRORS IN THIS COLUMN, let's filter them\n",
    "    # NOT CONFIRMED\n",
    "    if 'not confirmed' in x.lower():\n",
    "        return \"OTHER / NOT KNOWN\"\n",
    "    if 'unidentified' in x.lower():\n",
    "        return 'OTHER / NOT KNOWN'\n",
    "    if ' or ' in x.lower():\n",
    "        return 'OTHER / NOT KNOWN'\n",
    "    #INVALIDS\n",
    "    if 'no shark involvement' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    if 'invalid' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    if 'questionable' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    if 'doubtful' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    #OTHER INVALIDS\n",
    "    if 'hoax' in x.lower():\n",
    "        return 'HOAX'\n",
    "    if 'drown' in x.lower():\n",
    "        return 'DROWNED'\n",
    "    if 'stingray' in x.lower():\n",
    "        return 'STINGRAY'\n",
    "    \n",
    "    \n",
    "    #  --- WHO'S THAT POKEMON?---\n",
    "    \n",
    "    if 'white shark' in x.lower():\n",
    "        return \"White shark\"\n",
    "    if 'tiger shark' in x.lower():\n",
    "        return \"Tiger shark\"\n",
    "    if 'bull shark' in x.lower():\n",
    "        return \"Bull shark\"\n",
    "    if 'nurse shark' in x.lower():\n",
    "        return 'Nurse shark'\n",
    "    if 'brown shark' in x.lower():\n",
    "        return 'Brown shark'\n",
    "    if 'mako shark' in x.lower():\n",
    "        return 'Mako Shark'\n",
    "    if 'blue shark' in x.lower():\n",
    "        return 'Blue shark'\n",
    "    if 'bronze whaler shark' in x.lower():\n",
    "        return 'Bronze whaler shark'\n",
    "    if 'blacktip shark' in x.lower():\n",
    "        return 'Blacktip shark'\n",
    "    if 'whitetip shark' in x.lower():\n",
    "        return 'Whitetip shark'\n",
    "    if 'sandbar shark' in x.lower():\n",
    "        return 'Sandbar shark'\n",
    "    if 'lemon shark' in x.lower():\n",
    "        return 'Lemon shark'\n",
    "    if 'hammerhead shark' in x.lower():\n",
    "        return 'Hammerhead shark'\n",
    "    if 'raggedtooth shark' in x.lower():\n",
    "        return 'Raggedtooth shark'\n",
    "    if 'thresher shark' in x.lower():\n",
    "        return 'Thresher shark'\n",
    "    if 'dusky shark' in x.lower():\n",
    "        return 'Dusky shark'\n",
    "    if 'wobbegong shark' in x.lower():\n",
    "        return 'Wobbegong shark'\n",
    "    if 'dusky shark' in x.lower():\n",
    "        return 'Dusky shark'\n",
    "    if 'spinner shark' in x.lower():\n",
    "        return 'Spinner shark'\n",
    "    if 'blue nose shark' in x.lower():\n",
    "        return 'Blue nose shark'\n",
    "    if 'leopard shark' in x.lower():\n",
    "        return 'Leopard shark'\n",
    "    if 'silvertip shark' in x.lower():\n",
    "        return 'Silvertip shark'\n",
    "    if 'gray shark' in x.lower():\n",
    "        return 'Gray shark'\n",
    "    if 'grey shark' in x.lower():\n",
    "        return 'Gray shark'\n",
    "    if 'reef shark' in x.lower():\n",
    "        return 'Reef shark'\n",
    "    if 'carpet shark' in x.lower():\n",
    "        return 'Carpet shark'\n",
    "    if 'whaler shark' in x.lower():\n",
    "        return 'Whaler shark'\n",
    "    if 'zambesi shark' in x.lower():\n",
    "        return 'Zambesi shark'\n",
    "    \n",
    "    # -- trying to filter sizes --\n",
    "\n",
    "    if 'small shark' in x.lower():\n",
    "        return 'Small shark'\n",
    "    \n",
    "    else:\n",
    "        return 'OTHER / NOT KNOWN'\n",
    "    \n",
    "df['Species2'] = df['Species'].map(shark_identifier2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INVALID ENTRY          3052\n",
      "OTHER / NOT KNOWN      1467\n",
      "White shark             625\n",
      "Tiger shark             275\n",
      "Bull shark              171\n",
      "Nurse shark              94\n",
      "Reef shark               65\n",
      "Bronze whaler shark      60\n",
      "Blacktip shark           56\n",
      "Small shark              55\n",
      "Mako Shark               53\n",
      "Wobbegong shark          46\n",
      "Hammerhead shark         44\n",
      "Raggedtooth shark        43\n",
      "Blue shark               38\n",
      "Lemon shark              34\n",
      "Zambesi shark            29\n",
      "Whitetip shark           23\n",
      "Spinner shark            20\n",
      "Dusky shark              12\n",
      "Carpet shark              8\n",
      "Whaler shark              6\n",
      "Sandbar shark             5\n",
      "Thresher shark            4\n",
      "Brown shark               3\n",
      "Gray shark                3\n",
      "DROWNED                   2\n",
      "HOAX                      2\n",
      "Blue nose shark           2\n",
      "Silvertip shark           2\n",
      "Leopard shark             2\n",
      "STINGRAY                  1\n",
      "Name: Species2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.Species2.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which species generate the most fatalities\n",
    "# df2.groupby('Species2', 'Fatal').filter(lambda x : x > 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è Injuries and types of attack\n",
    "The GSAF categorizes scavenging bites on humans as \"questionable incidents.\"\n",
    "\n",
    "## PROVOKED\n",
    "Provoked attacks occur when a human touches, hooks, nets, or otherwise aggravates the animal. Incidents that occur outside of a shark's natural habitat, such as aquariums and research holding-pens, are considered provoked, as are all incidents involving captured sharks. Sometimes humans inadvertently provoke an attack, such as when a surfer accidentally hits a shark with a surf board.\n",
    "\n",
    "## UNPROVOKED\n",
    "- Hit-and-run attack\n",
    "- Sneak Attack\n",
    "- Bump-and-bite attack \n",
    "\n",
    "For more information on how to differentiate PROVOKED vs UNPROVOKED attacks :\n",
    "https://en.wikipedia.org/wiki/Shark_attack#Types_of_attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèäÔ∏è TYPE OF ATTACK\n",
    "- On the Type column, dont count sea disasters, questionable and boatomg\n",
    "- Stardarize\n",
    "- Size of the shark according to Species column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Type.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unprovoked      4595\n",
       "Provoked         574\n",
       "Invalid          551\n",
       "Sea Disaster     239\n",
       "Boating          203\n",
       "Boat             137\n",
       "Questionable       2\n",
       "Boatomg            1\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Type = df.Type.fillna('Invalid')\n",
    "df.Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unprovoked      4595\n",
       "Provoked         574\n",
       "Invalid          553\n",
       "Boat             341\n",
       "Sea Disaster     239\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boat, Boating and Boatomg to 1 category\n",
    "filt = lambda x: 'Boat' if 'Boat' in x else x\n",
    "df.Type = df.Type.map(filt)\n",
    "\n",
    "# Questionable to Invalid\n",
    "filt = lambda x : 'Invalid' if 'Questionable' in x else x\n",
    "df.Type = df.Type.map(filt)\n",
    "\n",
    "df.Type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Surfing                                              971\n",
       "Swimming                                             869\n",
       "Fishing                                              431\n",
       "Spearfishing                                         333\n",
       "Bathing                                              162\n",
       "                                                    ... \n",
       "Floating face-down in knee-deep water                  1\n",
       "Abalone diving using Hookah (near calving whales)      1\n",
       "Standing, watching seine netters                       1\n",
       "Boogie boarding / wading                               1\n",
       "Swimming near breakwater                               1\n",
       "Name: Activity, Length: 1532, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Activity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Swimming                                                 1274\n",
       "Surfing                                                  1203\n",
       "Fishing                                                  1119\n",
       "Diving                                                    600\n",
       "Wading                                                    163\n",
       "                                                         ... \n",
       "Hunting turtle                                              1\n",
       "Crouching in the water                                      1\n",
       "Jumping in swells                                           1\n",
       "Dismantling cable buoys of the cable ship All America       1\n",
       "Stuffing a shark into an automobile                         1\n",
       "Name: Activity2, Length: 370, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filt(x):\n",
    "    if type(x) is str:\n",
    "        if 'floating' in x.lower():\n",
    "            return 'Floating'\n",
    "        if 'diving' in x.lower():\n",
    "            return 'Diving'\n",
    "        if 'dive' in x.lower():\n",
    "            return 'Diving'\n",
    "        if 'skiing' in x.lower():\n",
    "            return 'Skiing'\n",
    "        if 'ski ' in x.lower():\n",
    "            return 'Skiing'\n",
    "        if 'surf' in x.lower():\n",
    "            return 'Surfing'\n",
    "        if 'snorkel' in x.lower():\n",
    "            return 'Snorkeling'\n",
    "        if 'fishing' in x.lower():\n",
    "            return 'Fishing'\n",
    "        if 'drift' in x.lower():\n",
    "            return 'Drifting'\n",
    "        if 'swim' in x.lower():\n",
    "            return 'Swimming'\n",
    "        if 'bathing' in x.lower():\n",
    "            return 'Swimming'\n",
    "        if 'paddle' in x.lower():\n",
    "            return 'Paddleboarding'\n",
    "        \n",
    "        if 'raft' in x.lower():\n",
    "            return 'Rafting'\n",
    "        if 'playing' in x.lower():\n",
    "            return 'Playing'\n",
    "        \n",
    "        if 'wading' in x.lower():\n",
    "            return 'Wading'\n",
    "        if 'research' in x.lower():\n",
    "            return 'Research'\n",
    "        if 'rescue' in x.lower():\n",
    "            return 'Rescuing someone / somthing'\n",
    "        if 'rescuing' in x.lower():\n",
    "            return 'Rescuing someone / somthing'\n",
    "        if 'overboard' in x.lower():\n",
    "            return 'Fell from boat into water'        \n",
    "        if 'fell' in x.lower():\n",
    "            return 'Fell to the water'\n",
    "        \n",
    "        if 'boat' in x.lower():\n",
    "            return 'Boating'\n",
    "        if 'yatch' in x.lower():\n",
    "            return 'Boating'\n",
    "        if 'disaster' in x.lower():\n",
    "            return 'Sea Disaster'\n",
    "        if 'wreck' in x.lower():\n",
    "            return 'Shipwreck'\n",
    "        if 'capsize' in x.lower():\n",
    "            return 'Shipwreck'\n",
    "        if 'sank' in x.lower():\n",
    "            return 'Shipwreck'\n",
    "        if 'torpedo' in x.lower():\n",
    "            return 'War (Torpedo)'\n",
    "        if 'warship' in x.lower():\n",
    "            return 'War (Warship)'\n",
    "        if ('plane' and 'crash') in x.lower():\n",
    "            return 'Airplane crash'\n",
    "        if 'airliner' in x.lower():\n",
    "            return 'Airplane crash'\n",
    "        \n",
    "        \n",
    "        if 'filming' in x.lower():\n",
    "            return 'Filming / Photoshoot'\n",
    "        if 'sailing' in x.lower():\n",
    "            return 'Sailing'\n",
    "        if 'net ' in x.lower():\n",
    "            return 'Fishing'\n",
    "        if ' net' in x.lower():\n",
    "            \n",
    "            return 'Fishing'\n",
    "        if 'photo' in x.lower():\n",
    "            return 'Filming / Photoshoot'\n",
    "        if 'sinking' in x.lower():\n",
    "            return 'Sea Disaster'\n",
    "        \n",
    "        if 'board' in x.lower():\n",
    "            return 'Other types of Boarding sports'\n",
    "        else:\n",
    "            return x\n",
    "df['Activity2'] = df.Activity.map(filt)\n",
    "df.Activity2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill the empty values too\n",
    "df.Activity.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Activity2 = df.Activity2.fillna('NOT SPECIFIED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Activity2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fatalities\n",
    "Sort them out and map them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "539"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Fatal.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Fatal = df.Fatal.fillna('UNKNOWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N          4301\n",
       "Y          1389\n",
       "UNKNOWN     612\n",
       "Name: Fatal, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filt(x):\n",
    "    if 'UNKNOWN' in x.upper():\n",
    "        return x\n",
    "    if 'N' in x.upper():\n",
    "        return 'N'\n",
    "    if 'Y' in x.upper():\n",
    "        return 'Y'\n",
    "    else:\n",
    "        return 'UNKNOWN'\n",
    "\n",
    "df['Fatal'] = df.Fatal.map(filt)\n",
    "df.Fatal.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FATAL                                                                                                       802\n",
       "Survived                                                                                                     97\n",
       "Foot bitten                                                                                                  87\n",
       "No injury                                                                                                    82\n",
       "Leg bitten                                                                                                   72\n",
       "                                                                                                           ... \n",
       "Right elbow bitten                                                                                            1\n",
       "Left inner thigh                                                                                              1\n",
       "Minor cuts above his right eye                                                                                1\n",
       "Left hand injured: gash on back of hand, toothmarks on palm                                                   1\n",
       "His remains were recovered from a shark 3 years after his disappearance - Probable drowning / scavenging      1\n",
       "Name: Injury, Length: 3737, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Injury.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CaseNum      False\n",
      "Date         False\n",
      "Year         False\n",
      "Type         False\n",
      "Country      False\n",
      "Area         False\n",
      "Location     False\n",
      "Activity     False\n",
      "Sex          False\n",
      "Age           True\n",
      "Injury       False\n",
      "Fatal        False\n",
      "Time          True\n",
      "Species      False\n",
      "Source       False\n",
      "href         False\n",
      "Species2     False\n",
      "Activity2    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(df.count() < 5000) # To know how much data are we missin on each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è\n",
    "The `Age` and `Time` column have many null values and is not going to be uses to test our hypothesis, so we will drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CaseNum       object\n",
       "Date          object\n",
       "Year         float64\n",
       "Type          object\n",
       "Country       object\n",
       "Area          object\n",
       "Location      object\n",
       "Activity      object\n",
       "Sex           object\n",
       "Injury        object\n",
       "Fatal         object\n",
       "Species       object\n",
       "Source        object\n",
       "href          object\n",
       "Species2      object\n",
       "Activity2     object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.drop(columns=['Age', 'Time'])\n",
    "df.columns\n",
    "display(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 'duped values')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop dupes and compare lengths\n",
    "df_pdf_nodupes = df.drop_duplicates()\n",
    "\n",
    "len(df) - len(df_pdf_nodupes), 'duped values'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "<br><br><br>\n",
    "\n",
    "<h1><center> üèÑÔ∏è Exporting the cleaned Dataset </center></h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phew... \n",
    "#\n",
    "# That was a long haul right there.\n",
    "# It might not be perfect, but we have\n",
    "# some cleaner data with which we can \n",
    "# make a more educated guess abour \n",
    "# this topic.\n",
    "#\n",
    "# Now, we can take this dataframe and\n",
    "# export it. This will be one of the\n",
    "# products of this project and \n",
    "# hopefully benefit the future of\n",
    "# sharing the planet with sharks.\n",
    "#\n",
    "#\n",
    "#\n",
    "# Oh, I almos forgot... \n",
    "#\n",
    "# Exporting as '.csv':\n",
    "#\n",
    "# It cannot get any simpler than this:\n",
    "df.to_csv('exported.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_measurments(x):\n",
    "    \n",
    "    #THERE ARE SO MANY ERRORS IN THIS COLUMN, let's filter them\n",
    "    # NOT CONFIRMED\n",
    "    \n",
    "    # -- trying to filter sizes --\n",
    "    \n",
    "    if \"\"\"10'\"\"\" in x.lower():\n",
    "        return \"\"\"10' shark\"\"\"\n",
    "    if \"\"\"11'\"\"\" in x.lower():\n",
    "        return \"\"\"11' shark\"\"\"\n",
    "    if \"\"\"12'\"\"\" in x.lower():\n",
    "        return \"\"\"12' shark\"\"\"\n",
    "    if \"\"\"13'\"\"\" in x.lower():\n",
    "        return \"\"\"13' shark\"\"\"\n",
    "    if \"\"\"14'\"\"\" in x.lower():\n",
    "        return \"\"\"14' shark\"\"\"\n",
    "    if \"\"\"15'\"\"\" in x.lower():\n",
    "        return \"\"\"15' shark\"\"\"\n",
    "    if \"\"\"16'\"\"\" in x.lower():\n",
    "        return \"\"\"16' shark\"\"\"\n",
    "    if \"\"\"17'\"\"\" in x.lower():\n",
    "        return \"\"\"17' shark\"\"\"\n",
    "    if \"\"\"18'\"\"\" in x.lower():\n",
    "        return \"\"\"18' shark\"\"\"\n",
    "    if \"\"\"19'\"\"\" in x.lower():\n",
    "        return \"\"\"19' shark\"\"\"\n",
    "    if \"\"\"20'\"\"\" in x.lower():\n",
    "        return \"\"\"20' shark\"\"\"\n",
    "    if \"\"\"21'\"\"\" in x.lower():\n",
    "        return \"\"\"21' shark\"\"\"\n",
    "    \n",
    "    if \"\"\"1'\"\"\" in x.lower():\n",
    "        return \"\"\"1' shark\"\"\"\n",
    "    if \"\"\"2'\"\"\" in x.lower():\n",
    "        return \"\"\"2' shark\"\"\"\n",
    "    if \"\"\"3'\"\"\" in x.lower():\n",
    "        return \"\"\"3' shark\"\"\"\n",
    "    if \"\"\"4'\"\"\" in x.lower():\n",
    "        return \"\"\"4' shark\"\"\"\n",
    "    if \"\"\"5'\"\"\" in x.lower():\n",
    "        return \"\"\"5' shark\"\"\"\n",
    "    if \"\"\"6'\"\"\" in x.lower():\n",
    "        return \"\"\"6' shark\"\"\"\n",
    "    if \"\"\"7'\"\"\" in x.lower():\n",
    "        return \"\"\"7' shark\"\"\"    \n",
    "    if \"\"\"8'\"\"\" in x.lower():\n",
    "        return \"\"\"8' shark\"\"\"\n",
    "    if \"\"\"9'\"\"\" in x.lower():\n",
    "        return \"\"\"9' shark\"\"\"\n",
    "\n",
    "    if 'small shark' in x.lower():\n",
    "        return 'Small shark'\n",
    "    \n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "# df['Species2'] = df['Species'].map(shark_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('FATAL, disappeared, body not recovered', 1),\n",
       " ('Injured by sharks, but managed to swim ashore 6.5 hours later', 1),\n",
       " ('Minor cuts to dorsum & sole of left foot when he stepped on shark PROVOKED INCIDENT',\n",
       "  1),\n",
       " ('Lacerations to face and right leg', 1),\n",
       " ('No injury, shark bit rudder', 1),\n",
       " ('No injury to occupant; shark leapt into boat', 1),\n",
       " ('No injury, kayak bitten', 11),\n",
       " ('Shark involvement prior to death unconfirmed', 5),\n",
       " ('Severe injury to forearm near elbow', 1),\n",
       " ('Cut to arm while roping shark PROVOKED INCIDENT', 1),\n",
       " ('Thigh bitten, shark teeth embedded in canoe', 1),\n",
       " ('No injury to occupant, netted shark rammed & bit boat PROVOKED INCIDENT',\n",
       "  1),\n",
       " ('Dr. A.R. Hernandez of ship Cabo Hornos treated passenger whose leg was severed by a shark',\n",
       "  1),\n",
       " ('FATAL, other human remains bitten by sharks, 13 people missing', 1),\n",
       " ('No injury to occupants, sharks bit chunks from boat', 1),\n",
       " ('Foot severely bitten, surgically amputated', 1),\n",
       " ('Arm severed, but survived. Note: Some weeks later he was swimming at the same spot when a shark severed his right foot.',\n",
       "  1),\n",
       " ('Wounds to upper thigh and lower leg', 1),\n",
       " ('Abdomen & chest abraded', 1),\n",
       " ('No injury to occupants, shark hit boat, lifting it from the water, bit & dented propeller',\n",
       "  1)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since there is no column that states if the attack was provoked or not,\n",
    "# I want to analyze the injury column to distinguish between the cases that were provoked\n",
    "# and those that were unprovoked.\n",
    "\n",
    "random.sample(list(df.Injury.value_counts().items()),20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6252                                                FATAL\n",
       "6253                                  FATAL, leg severed \n",
       "6254                                             PROVOKED\n",
       "6255                                      Buttocks bitten\n",
       "6256                                            No injury\n",
       "6257                                             Survived\n",
       "6258                                                FATAL\n",
       "6259    FATAL, shark leapt into raft and bit the man w...\n",
       "6260                                       Buttock bitten\n",
       "6261                                          Head bitten\n",
       "6262                    FATAL, foot lacerated & crushed  \n",
       "6263    FATAL, femoral artery severed, died 12 days la...\n",
       "6264    FATAL, fell into water when shark seized his r...\n",
       "6265        FATAL, left leg bitten with severe blood loss\n",
       "6266                                FATAL, died of sepsis\n",
       "6267                                      Buttocks bitten\n",
       "6268                 Foot lacerated, surgically amputated\n",
       "6269                                                FATAL\n",
       "6270                                             PROVOKED\n",
       "6271    No injury, but shark removed the heel & part o...\n",
       "6272                                     Shark bumped him\n",
       "6273                                            Fatal x 2\n",
       "6274           No injury to occupant; shark capsized boat\n",
       "6275                                          Head bitten\n",
       "6276                                                FATAL\n",
       "6277                                                  NaN\n",
       "6278                                                FATAL\n",
       "6279                                         Ankle bitten\n",
       "6280                                 Lacerations to thigh\n",
       "6281                                  FATAL, leg severed \n",
       "6282                                                FATAL\n",
       "6283                                   2-inch lacerations\n",
       "6284                                          Foot bitten\n",
       "6285                                                FATAL\n",
       "6286                                                FATAL\n",
       "6287    FATAL, 18 people  were killed by sharks, 2 sur...\n",
       "6288                                           \"Lost leg\"\n",
       "6289    FATAL, body not recovered but shark was caught...\n",
       "6290                       FATAL, leg stripped of flesh  \n",
       "6291                                         Foot severed\n",
       "6292                                         Ankle bitten\n",
       "6293    FATAL, knocked overboard by tail of shark & ca...\n",
       "6294                                                FATAL\n",
       "6295                                                FATAL\n",
       "6296                                                FATAL\n",
       "6297                                                FATAL\n",
       "6298                                                FATAL\n",
       "6299                                                FATAL\n",
       "6300                                                FATAL\n",
       "6301    FATAL. \"Shark bit him in half, carrying away t...\n",
       "Name: Provoked, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorizing  Provoked and  Unprovoked attacks\n",
    "# df_provoked = np.where(df_nodupes.Injury.isin(provoked), True, False) \n",
    "\n",
    "# Passing that categorization to a new PROVOKED COLUMN\n",
    "def provoked_attacks(x):\n",
    "    \n",
    "    provoked = ['PROVOKED', 'hook', 'shot']\n",
    "    \n",
    "    for e in provoked:\n",
    "        if e in str(x):\n",
    "            return 'PROVOKED'\n",
    "        else:\n",
    "            return x\n",
    "df['Provoked'] = df.Injury.map(provoked_attacks)\n",
    "df['Provoked'].tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rh/.local/lib/python3.6/site-packages/pandas/core/common.py:222: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "  values = list(values)\n",
      "/home/rh/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py:429: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "  if data and all(isinstance(e, tuple) for e in data):\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Series' objects are mutable, thus they cannot be hashed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-b158f2487466>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprovoked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'PROVOKED'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hook'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#map(lambda words, x : words in x, provoked, df_nodupes.loc[df_nodupes['Injury'].str])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Injury'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1952\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1954\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1593\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m             return self.obj._reindex_with_indexers(\n\u001b[1;32m   1597\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1545\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_for_reindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1547\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1548\u001b[0m             \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer_for\u001b[0;34m(self, target, **kwargs)\u001b[0m\n\u001b[1;32m   4499\u001b[0m         \"\"\"\n\u001b[1;32m   4500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4502\u001b[0m         \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4503\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   2727\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2728\u001b[0m             return this.get_indexer(\n\u001b[0;32m-> 2729\u001b[0;31m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2730\u001b[0m             )\n\u001b[1;32m   2731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   2751\u001b[0m                 )\n\u001b[1;32m   2752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2753\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2755\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mensure_platform_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.lookup\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1798\u001b[0m         raise TypeError(\n\u001b[0;32m-> 1799\u001b[0;31m             \u001b[0;34mf\"{repr(type(self).__name__)} objects are mutable, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1800\u001b[0m             \u001b[0;34mf\"thus they cannot be hashed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Series' objects are mutable, thus they cannot be hashed"
     ]
    }
   ],
   "source": [
    "#df_clean.loc[df_clean[\"trany\"].str.startswith(\"M\"),\"trany\"] = \"Manual\"\n",
    "\n",
    "provoked = ['PROVOKED', 'hook', 'shot']\n",
    "#map(lambda words, x : words in x, provoked, df_nodupes.loc[df_nodupes['Injury'].str])\n",
    "df.loc[df['Injury'].str]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
