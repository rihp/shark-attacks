{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic knowledge: \n",
    "To begin this project, it would be good to hold a minimum understanding of the subject we will be analyzing. As I did not know much about this topic at the day the project started, I have recurred to the shark-attack wiki: https://en.wikipedia.org/wiki/Shark_attack\n",
    "\n",
    "\n",
    "\n",
    "# Defining the dataset path, and importing it to begin basic dataset exploration\n",
    "\n",
    "Questions: \n",
    "- how to add the dataset to gitignore?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To follow along and access the DataSet, download it from KAGGLE using this link\n",
    "# https://www.kaggle.com/teajay/global-shark-attacks\n",
    "\n",
    "# Once you have downloaded the DataSet, change the dataset variable to match the \n",
    "# path where you have saved the 'attacks.csv' file.\n",
    "dataset = 'attacks.csv' \n",
    "df = pd.read_csv(dataset, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will check some basic information about the dataset, in order to formulate a more educated hypothesis which we could actually put to test with the data available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25723, 24)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6312, 24)\n"
     ]
    }
   ],
   "source": [
    "display(df.shape)# To know the shape of the DF\n",
    "print(df.drop_duplicates().shape) # Shape when eliminating duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I notice that the shape of the df with no duplicates is very small when compared to the whole df. This seems weird and since the `drop_duplicates` function ignores time indexes, I'll try to compare both dataframes' time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Name', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time',\n",
       "       'Species ', 'Investigator or Source', 'pdf', 'href formula', 'href',\n",
       "       'Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22',\n",
       "       'Unnamed: 23'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        25-Jun-2018\n",
       "1        18-Jun-2018\n",
       "2        09-Jun-2018\n",
       "3        08-Jun-2018\n",
       "4        04-Jun-2018\n",
       "            ...     \n",
       "25718            NaN\n",
       "25719            NaN\n",
       "25720            NaN\n",
       "25721            NaN\n",
       "25722            NaN\n",
       "Name: Date, Length: 25723, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        25-Jun-2018\n",
       "1        18-Jun-2018\n",
       "2        09-Jun-2018\n",
       "3        08-Jun-2018\n",
       "4        04-Jun-2018\n",
       "            ...     \n",
       "6307             NaN\n",
       "6308             NaN\n",
       "6309             NaN\n",
       "8702             NaN\n",
       "25722            NaN\n",
       "Name: Date, Length: 6312, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodupes = df.drop_duplicates()\n",
    "df_nodupes.Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>6303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>6302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>6299.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6309.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6310.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8702</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25722</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6312 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Case Number.1 Case Number.2  original order Unnamed: 22 Unnamed: 23\n",
       "0        2018.06.25    2018.06.25          6303.0         NaN         NaN\n",
       "1        2018.06.18    2018.06.18          6302.0         NaN         NaN\n",
       "2        2018.06.09    2018.06.09          6301.0         NaN         NaN\n",
       "3        2018.06.08    2018.06.08          6300.0         NaN         NaN\n",
       "4        2018.06.04    2018.06.04          6299.0         NaN         NaN\n",
       "...             ...           ...             ...         ...         ...\n",
       "6307            NaN           NaN          6309.0         NaN         NaN\n",
       "6308            NaN           NaN          6310.0         NaN         NaN\n",
       "6309            NaN           NaN             NaN         NaN         NaN\n",
       "8702            NaN           NaN             NaN         NaN         NaN\n",
       "25722           NaN           NaN             NaN         NaN         NaN\n",
       "\n",
       "[6312 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, with a df smaller in size, I want to see what info is there on the last couple\n",
    "# of columns which have unexplicit\n",
    "df_nodupes[['Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22', 'Unnamed: 23']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6312, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Case Number.1       10\n",
       "Case Number.2       10\n",
       "original order       3\n",
       "Unnamed: 22       6311\n",
       "Unnamed: 23       6310\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Too many null values... let's count them and let\n",
    "print(df_nodupes.shape)\n",
    "df_nodupes[['Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22', 'Unnamed: 23']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If only 1 value in the 'Unnamed: 22' column, and 2 values in the\n",
    "# 'Unnamed: 22' column, I'll not consider this data for my analysis.\n",
    "df_nodupes = df_nodupes.drop(columns=['Unnamed: 22', 'Unnamed: 23'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Name', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time',\n",
       "       'Species ', 'Investigator or Source', 'pdf', 'href formula', 'href',\n",
       "       'Case Number.1', 'Case Number.2', 'original order'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we'll look at the columns again\n",
    "df_nodupes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1920.00.00.b    2\n",
       "2005.04.06      2\n",
       "1913.08.27.R    2\n",
       "2014.08.02      2\n",
       "1923.00.00.a    2\n",
       "               ..\n",
       "2017.08.10      1\n",
       "1955.09.23.b    1\n",
       "1962.07.28      1\n",
       "1966.07.17.b    1\n",
       "1967.04.00      1\n",
       "Name: Case Number.1, Length: 6285, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following columns seemed a little bit rare, so i do a value count to find out what they are about\n",
    "df_nodupes['Case Number.1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013.10.05        2\n",
       "1915.07.06.a.R    2\n",
       "1966.12.26        2\n",
       "1907.10.16.R      2\n",
       "2009.12.18        2\n",
       "                 ..\n",
       "2005.05.15        1\n",
       "1987.04.15        1\n",
       "2017.02.25        1\n",
       "1900.09.05        1\n",
       "1967.04.00        1\n",
       "Name: Case Number.2, Length: 6286, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodupes['Case Number.2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569.0     2\n",
       "4603.0    1\n",
       "4899.0    1\n",
       "810.0     1\n",
       "796.0     1\n",
       "         ..\n",
       "3508.0    1\n",
       "3256.0    1\n",
       "3106.0    1\n",
       "3080.0    1\n",
       "6272.0    1\n",
       "Name: original order, Length: 6308, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodupes['original order'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Name', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time',\n",
       "       'Species ', 'Investigator or Source', 'pdf', 'href formula', 'href',\n",
       "       'Case Number.1', 'Case Number.2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since 'original order seems like arbitrary indexes, i'll drop it\n",
    "df_nodupes = df_nodupes.drop(columns='original order')\n",
    "df_nodupes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdf     10\n",
      "href    10\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf</th>\n",
       "      <th>href</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.06.08-Arrawarra.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.06.04-Ramos.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8702</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25722</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6312 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            pdf  \\\n",
       "0          2018.06.25-Wolfe.pdf   \n",
       "1        2018.06.18-McNeely.pdf   \n",
       "2         2018.06.09-Denges.pdf   \n",
       "3      2018.06.08-Arrawarra.pdf   \n",
       "4          2018.06.04-Ramos.pdf   \n",
       "...                         ...   \n",
       "6307                        NaN   \n",
       "6308                        NaN   \n",
       "6309                        NaN   \n",
       "8702                        NaN   \n",
       "25722                       NaN   \n",
       "\n",
       "                                                    href  \n",
       "0      http://sharkattackfile.net/spreadsheets/pdf_di...  \n",
       "1      http://sharkattackfile.net/spreadsheets/pdf_di...  \n",
       "2      http://sharkattackfile.net/spreadsheets/pdf_di...  \n",
       "3      http://sharkattackfile.net/spreadsheets/pdf_di...  \n",
       "4      http://sharkattackfile.net/spreadsheets/pdf_di...  \n",
       "...                                                  ...  \n",
       "6307                                                 NaN  \n",
       "6308                                                 NaN  \n",
       "6309                                                 NaN  \n",
       "8702                                                 NaN  \n",
       "25722                                                NaN  \n",
       "\n",
       "[6312 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I want to check out some of the pdf and href\n",
    "print(df_nodupes[['pdf', 'href']].isnull().sum())\n",
    "df_nodupes[['pdf', 'href']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 530, link: http://sharkattackfile.net/spreadsheets/pdf_directory/2014.07.16-Maui.pdf\n",
      "index: 144, link: http://sharkattackfile.net/spreadsheets/pdf_directory/2017.05.06-Rozada.pdf\n",
      "index: 940, link: http://sharkattackfile.net/spreadsheets/pdf_directory/2011.03.10.R-Sharm-scavenging.pdf\n",
      "index: 351, link: http://sharkattackfile.net/spreadsheets/pdf_directory/2015.10.05.b-FtPierce.pdf\n",
      "index: 891, link: http://sharkattackfile.net/spreadsheets/pdf_directory/2011.07.30-Malabago.pdf\n",
      "index: 229, link: http://sharkattackfile.net/spreadsheets/pdf_directory/2016.08.27-Chardard.pdf\n",
      "index: 162, link: http://sharkattackfile.net/spreadsheets/pdf_directory/2017.04.10.a-Orr.pdf\n",
      "index: 884, link: http://sharkattackfile.net/spreadsheets/pdf_directory/2011.08.16.c-D'Esposito.pdf\n",
      "index: 316, link: http://sharkattackfile.net/spreadsheets/pdf_directory/2016.01.23-Mason.pdf\n",
      "index: 943, link: http://sharkattackfile.net/spreadsheets/pdf_directory/2011.02.23-Jean-Luc.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['http://sharkattackfile.net/spreadsheets/pdf_directory/2011.06.06.R-James.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1972.12.25-Sockoff.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/2006.04.09.a-Pereira.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1989.07.27-SovietDiver.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1989.04.00-Allen.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1942.11.13.a-Guadalcanal.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1981.07.07-NV-Cannette.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/2005.04.25-deckhand.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1981.07.01-Wilson.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/2001.06.12-Black.pdf']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# I want to check what is on those pdfs\n",
    "# A random sample of the column \n",
    "\n",
    "# With a FOR loop\n",
    "for i in range(10):\n",
    "    e = random.choice(range(1000))\n",
    "    print(f\"index: {e}, link: {df_nodupes.iloc[e]['href']}\")\n",
    "\n",
    "# With Random sample\n",
    "display(random.sample(list(df_nodupes['href']), 10))\n",
    "\n",
    "# Below are a couple of the links, when I open them, I have found that they are seem quite structured\n",
    "# It could be possible to parse them later down the road and use a REGEX to find more data\n",
    "\n",
    "# I also have ran this column a few times to notice that all pdfs have actually been uploaded to\n",
    "# the same website and have the same naming structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After some random sampling, I've noticed that the following indexes have some mistakes.. \n",
    "# a REGEX can be used to fix problems like these \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://sharkattackfile.net/spreadsheets/pdf_directory/http://sharkattackfile.net/spreadsheets/pdf_directory/2015.11.15.a-Engelman.pdf\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/http://sharkattackfile.net/spreadsheets/pdf_directory/2015.12.21.a-Brazil.pdf\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/http://sharkattackfile.net/spreadsheets/pdf_directory/2014.00.00.b-OceanicWhitetip.pdf\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/http://sharkattackfile.net/spreadsheets/pdf_directory/2014.04.03-Armstrong.pdf\n"
     ]
    }
   ],
   "source": [
    "print(df_nodupes.iloc[332]['href'])\n",
    "print(df_nodupes.iloc[324]['href'])\n",
    "print(df_nodupes.iloc[588]['href'])\n",
    "print(df_nodupes.iloc[569]['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It looks still like some of these pdfs are duplicates, even after dropping duplicates :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1906.09.27.R.a&b-Munich-Swede.pdf      2\n",
       "1916.12.08.a-b-German.pdf              2\n",
       "1916.07.12.a-b-Stillwell-Fisher.pdf    2\n",
       "1934.12.23.a-b-Inman.pdf               2\n",
       "1935.06.05.R-SolomonIslands.pdf        2\n",
       "                                      ..\n",
       "1976.03.12.b-GlenWright.pdf            1\n",
       "2010.08.17-Edwards.pdf                 1\n",
       "1960.05.01-Taludig.pdf                 1\n",
       "2012.08.15-GulfShoresSwimmer.pdf       1\n",
       "2008.07.25.a-Fiack.pdf                 1\n",
       "Name: pdf, Length: 6291, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many times each pdf on the dataframe\n",
    "df_pdf = df_nodupes[\"pdf\"]\n",
    "df_pdf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6312, 6292)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop dupes and compare lengths\n",
    "df_pdf_nodupes = df_pdf.drop_duplicates()\n",
    "\n",
    "len(df_pdf), len(df_pdf_nodupes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since the lengths are not the same, I will check if those duplicated entries are only in this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>pdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08-Jun-2018</td>\n",
       "      <td>Arrawarra Headland</td>\n",
       "      <td>2018.06.08-Arrawarra.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04-Jun-2018</td>\n",
       "      <td>La Ticla</td>\n",
       "      <td>2018.06.04-Ramos.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8702</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25722</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6312 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date                        Location                       pdf\n",
       "0      25-Jun-2018     Oceanside, San Diego County      2018.06.25-Wolfe.pdf\n",
       "1      18-Jun-2018  St. Simon Island, Glynn County    2018.06.18-McNeely.pdf\n",
       "2      09-Jun-2018                    Habush, Oahu     2018.06.09-Denges.pdf\n",
       "3      08-Jun-2018              Arrawarra Headland  2018.06.08-Arrawarra.pdf\n",
       "4      04-Jun-2018                        La Ticla      2018.06.04-Ramos.pdf\n",
       "...            ...                             ...                       ...\n",
       "6307           NaN                             NaN                       NaN\n",
       "6308           NaN                             NaN                       NaN\n",
       "6309           NaN                             NaN                       NaN\n",
       "8702           NaN                             NaN                       NaN\n",
       "25722          NaN                             NaN                       NaN\n",
       "\n",
       "[6312 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodupes[[\"Date\", \"Location\", \"pdf\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_nodupes_indexes \n",
    "for e in list(df_nodupes['pdf']):\n",
    "    if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\\n            ...\\n            1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\\n           dtype='int64', length=6291)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-7112e9caa4f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_nodupes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_nodupes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pdf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2806\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m         )\n\u001b[1;32m   1555\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1638\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1640\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1642\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\\n            ...\\n            1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\\n           dtype='int64', length=6291)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "dfx = df_nodupes[\"pdf\"].value_counts() if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.columns) # To know which are the columns in the DF\n",
    "display(df.count()) # To know how much data are we missin on each column\n",
    "display(df.dtypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
