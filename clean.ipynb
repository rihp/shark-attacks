{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Questions: \n",
    "- how to add the dataset to gitignore?\n",
    "- how can i create a separate module that holds my functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Shark attacks, a project by Roberto Henr√≠quez Perozo. Data Analytics Bootcamp at IronHack](shark-attacks.png)\n",
    "\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "<center>\n",
    "    <h1> PART I: Data cleaning and exploration</h1>\n",
    "</center>\n",
    "\n",
    "\n",
    "## üé£Ô∏è Step 0 - Basic knowledge\n",
    "To begin the development of this project, it would be good to hold a minimum understanding of `Shark Attacks`.\n",
    "\n",
    "As I did not know much about this topic at the day the project started, I have recurred to the shark-attack wiki: https://en.wikipedia.org/wiki/Shark_attack\n",
    "\n",
    "With this information in mind, below is the process of data exploration, cleaning, and wrangling.\n",
    "\n",
    "\n",
    "## üé£Ô∏è Step 1 - Defining the dataset path, and importing it to begin basic dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To follow along and access the DataSet, download it from KAGGLE using this link\n",
    "# https://www.kaggle.com/teajay/global-shark-attacks\n",
    "\n",
    "# Once you have downloaded the DataSet, change the following `dataset` variable to match the \n",
    "# path where you have saved the 'attacks.csv' file.\n",
    "dataset = 'attacks.csv' \n",
    "\n",
    "\n",
    "df = pd.read_csv(dataset, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will check some basic information about the dataset, in order to formulate a more educated hypothesis which we could actually put to test with the data available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I notice that the shape of the `df` with no duplicates is very small when compared to the whole `df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåäÔ∏è  FUNCT\n",
    "This comparison could be turned into its own function, as it will be executed quite often"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before (25723, 24)\n",
      "after (6312, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Name', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time',\n",
       "       'Species ', 'Investigator or Source', 'pdf', 'href formula', 'href',\n",
       "       'Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22',\n",
       "       'Unnamed: 23'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'll delete de duplicated rows\n",
    "print('before', df.shape)\n",
    "df = df.drop_duplicates()\n",
    "print('after', df.shape)\n",
    "\n",
    "# And also take a look at the columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        25-Jun-2018\n",
       "1        18-Jun-2018\n",
       "2        09-Jun-2018\n",
       "3        08-Jun-2018\n",
       "4        04-Jun-2018\n",
       "            ...     \n",
       "6307             NaN\n",
       "6308             NaN\n",
       "6309             NaN\n",
       "8702             NaN\n",
       "25722            NaN\n",
       "Name: Date, Length: 6312, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I want to take a look at the time structures\n",
    "df.Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>6303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>6302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>6299.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6309.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6310.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8702</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25722</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6312 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Case Number.1 Case Number.2  original order Unnamed: 22 Unnamed: 23\n",
       "0        2018.06.25    2018.06.25          6303.0         NaN         NaN\n",
       "1        2018.06.18    2018.06.18          6302.0         NaN         NaN\n",
       "2        2018.06.09    2018.06.09          6301.0         NaN         NaN\n",
       "3        2018.06.08    2018.06.08          6300.0         NaN         NaN\n",
       "4        2018.06.04    2018.06.04          6299.0         NaN         NaN\n",
       "...             ...           ...             ...         ...         ...\n",
       "6307            NaN           NaN          6309.0         NaN         NaN\n",
       "6308            NaN           NaN          6310.0         NaN         NaN\n",
       "6309            NaN           NaN             NaN         NaN         NaN\n",
       "8702            NaN           NaN             NaN         NaN         NaN\n",
       "25722           NaN           NaN             NaN         NaN         NaN\n",
       "\n",
       "[6312 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I want to see what is the data on the last couple\n",
    "# of columns which have unexplicit labels\n",
    "df[['Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22', 'Unnamed: 23']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6312, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Case Number.1       10\n",
       "Case Number.2       10\n",
       "original order       3\n",
       "Unnamed: 22       6311\n",
       "Unnamed: 23       6310\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Too many null values on the last two columns... let's count them\n",
    "print(df.shape)\n",
    "df[['Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22', 'Unnamed: 23']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there is only 1 value in the 'Unnamed: 22' column, and 2 values in the\n",
    "# 'Unnamed: 22' column, I'll not consider this data for my analysis.\n",
    "df = df.drop(columns=['Unnamed: 22', 'Unnamed: 23'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1916.12.30        1\n",
       "1955.02.10        1\n",
       "1994.09.26        1\n",
       "1866.07.09.R      1\n",
       "2009.04.06.b      1\n",
       "                 ..\n",
       "1980.07.00        2\n",
       "2012.09.02.b      2\n",
       "1915.07.06.a.R    2\n",
       "1907.10.16.R      2\n",
       "1990.05.10        2\n",
       "Name: Case Number.1, Length: 6285, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following columns seemed a little bit rare, so i do a value count to find out what they are about\n",
    "df['Case Number.1'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2008.08.30.c    1\n",
       "1955.02.10      1\n",
       "1994.09.26      1\n",
       "1866.07.09.R    1\n",
       "2009.04.06.b    1\n",
       "               ..\n",
       "2014.08.02      2\n",
       "2009.12.18      2\n",
       "1983.06.15      2\n",
       "1923.00.00.a    2\n",
       "1966.12.26      2\n",
       "Name: Case Number.2, Length: 6286, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Case Number.2'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåäÔ∏è Creating a Function\n",
    "\n",
    "After some thought and googling, it seems like these are some sort of notation used to categorize and order the shark attacks.\n",
    "\n",
    "They also use the a notation that includes dates. \n",
    "## Is it the same as the Date on the Date column?\n",
    "\n",
    "To find out, I wanted to pick random samples of the dataframe, but python's built-in `random` module kept giving me trouble when I tried to use it alongside pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object sampler at 0x7f88360f7570>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It was better to make it into a function\n",
    "#VER 03\n",
    "def sampler(df, column, sample_size):\n",
    "# This function generates an iterator out of random rows from a pandas dataframe's specific column\n",
    "    \n",
    "    # Defining how many samples to fetch from the df\n",
    "    for i in range(sample_size):\n",
    "        \n",
    "        # Now a random index is generated out of the total length of the column...\n",
    "        i = random.choice(range(len(df[column])))\n",
    "        # ... to return the data values in that index as an iterator:\n",
    "        yield df.iloc[i][column]\n",
    "        \n",
    "        # For future versions, it would be good to look at how I can return the\n",
    "        # data as a tupple with just the data, and not have it return a formatted string\n",
    "        # or even better, a pandas dataframe with the results\n",
    "\n",
    "\n",
    "# Now let's try it out\n",
    "sampler(df, ['Date', 'Case Number.1', 'Case Number.2'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Date              02-Aug-2010\n",
       " Case Number.1    2010.08.02.b\n",
       " Case Number.2    2010.08.02.b\n",
       " Name: 1004, dtype: object,\n",
       " Date             24-Sep-2012\n",
       " Case Number.1     2012.09.24\n",
       " Case Number.2     2012.09.24\n",
       " Name: 737, dtype: object,\n",
       " Date             11-Mar-2015\n",
       " Case Number.1     2015.03.11\n",
       " Case Number.2     2015.03.11\n",
       " Name: 443, dtype: object,\n",
       " Date             24-May 1922\n",
       " Case Number.1     1922.05.24\n",
       " Case Number.2     1922.05.24\n",
       " Name: 5224, dtype: object,\n",
       " Date             17-Mar-1926\n",
       " Case Number.1     1926.03.17\n",
       " Case Number.2     1926.03.17\n",
       " Name: 5153, dtype: object,\n",
       " Date             07-Aug-2007\n",
       " Case Number.1     2007.08.07\n",
       " Case Number.2     2007.08.07\n",
       " Name: 1352, dtype: object,\n",
       " Date             27-Aug-1997\n",
       " Case Number.1     1997.08.27\n",
       " Case Number.2     1997.08.27\n",
       " Name: 2228, dtype: object,\n",
       " Date             05-Sep-1990\n",
       " Case Number.1     1990.09.05\n",
       " Case Number.2     1990.09.05\n",
       " Name: 2624, dtype: object,\n",
       " Date             Reported 02-Jun-2008\n",
       " Case Number.1            2008.06.02.R\n",
       " Case Number.2            2008.06.02.R\n",
       " Name: 1251, dtype: object,\n",
       " Date             30-Jun-1993\n",
       " Case Number.1     1993.06.30\n",
       " Case Number.2     1993.06.30\n",
       " Name: 2488, dtype: object]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since sampler generates iterators, list() must be used to see its contents\n",
    "list(sampler(df, ['Date', 'Case Number.1', 'Case Number.2'], 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è\n",
    "From this output, we can see that the `Case Number` Columnns are actually replicating the info that we already have on the `Date` column. Therefore, we will drop both `Case Number` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>original order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>No injury to occupant, outrigger canoe and pad...</td>\n",
       "      <td>N</td>\n",
       "      <td>18h00</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6303.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson¬†McNeely</td>\n",
       "      <td>F</td>\n",
       "      <td>11</td>\n",
       "      <td>Minor injury to left thigh</td>\n",
       "      <td>N</td>\n",
       "      <td>14h00  -15h00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>M</td>\n",
       "      <td>48</td>\n",
       "      <td>Injury to left lower leg from surfboard skeg</td>\n",
       "      <td>N</td>\n",
       "      <td>07h45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6301.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>08-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Arrawarra Headland</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minor injury to lower leg</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 m shark</td>\n",
       "      <td>B. Myatt, GSAF</td>\n",
       "      <td>2018.06.08-Arrawarra.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>04-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>Colima</td>\n",
       "      <td>La Ticla</td>\n",
       "      <td>Free diving</td>\n",
       "      <td>Gustavo Ramos</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lacerations to leg &amp; hand shark PROVOKED INCIDENT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tiger shark, 3m</td>\n",
       "      <td>A .Kipper</td>\n",
       "      <td>2018.06.04-Ramos.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8702</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25722</th>\n",
       "      <td>xx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6312 rows √ó 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Case Number         Date    Year        Type    Country  \\\n",
       "0      2018.06.25  25-Jun-2018  2018.0     Boating        USA   \n",
       "1      2018.06.18  18-Jun-2018  2018.0  Unprovoked        USA   \n",
       "2      2018.06.09  09-Jun-2018  2018.0     Invalid        USA   \n",
       "3      2018.06.08  08-Jun-2018  2018.0  Unprovoked  AUSTRALIA   \n",
       "4      2018.06.04  04-Jun-2018  2018.0    Provoked     MEXICO   \n",
       "...           ...          ...     ...         ...        ...   \n",
       "6307            0          NaN     NaN         NaN        NaN   \n",
       "6308            0          NaN     NaN         NaN        NaN   \n",
       "6309            0          NaN     NaN         NaN        NaN   \n",
       "8702          NaN          NaN     NaN         NaN        NaN   \n",
       "25722          xx          NaN     NaN         NaN        NaN   \n",
       "\n",
       "                  Area                        Location     Activity  \\\n",
       "0           California     Oceanside, San Diego County     Paddling   \n",
       "1              Georgia  St. Simon Island, Glynn County     Standing   \n",
       "2               Hawaii                    Habush, Oahu      Surfing   \n",
       "3      New South Wales              Arrawarra Headland      Surfing   \n",
       "4               Colima                        La Ticla  Free diving   \n",
       "...                ...                             ...          ...   \n",
       "6307               NaN                             NaN          NaN   \n",
       "6308               NaN                             NaN          NaN   \n",
       "6309               NaN                             NaN          NaN   \n",
       "8702               NaN                             NaN          NaN   \n",
       "25722              NaN                             NaN          NaN   \n",
       "\n",
       "                  Name Sex   Age  \\\n",
       "0          Julie Wolfe    F   57   \n",
       "1      Adyson¬†McNeely     F   11   \n",
       "2          John Denges    M   48   \n",
       "3                 male    M  NaN   \n",
       "4       Gustavo Ramos     M  NaN   \n",
       "...                ...  ...  ...   \n",
       "6307               NaN  NaN  NaN   \n",
       "6308               NaN  NaN  NaN   \n",
       "6309               NaN  NaN  NaN   \n",
       "8702               NaN  NaN  NaN   \n",
       "25722              NaN  NaN  NaN   \n",
       "\n",
       "                                                  Injury Fatal (Y/N)  \\\n",
       "0      No injury to occupant, outrigger canoe and pad...           N   \n",
       "1                             Minor injury to left thigh           N   \n",
       "2           Injury to left lower leg from surfboard skeg           N   \n",
       "3                              Minor injury to lower leg           N   \n",
       "4      Lacerations to leg & hand shark PROVOKED INCIDENT           N   \n",
       "...                                                  ...         ...   \n",
       "6307                                                 NaN         NaN   \n",
       "6308                                                 NaN         NaN   \n",
       "6309                                                 NaN         NaN   \n",
       "8702                                                 NaN         NaN   \n",
       "25722                                                NaN         NaN   \n",
       "\n",
       "                Time         Species           Investigator or Source  \\\n",
       "0              18h00      White shark                R. Collier, GSAF   \n",
       "1      14h00  -15h00              NaN  K.McMurray, TrackingSharks.com   \n",
       "2              07h45              NaN  K.McMurray, TrackingSharks.com   \n",
       "3                NaN        2 m shark                  B. Myatt, GSAF   \n",
       "4                NaN  Tiger shark, 3m                       A .Kipper   \n",
       "...              ...              ...                             ...   \n",
       "6307             NaN              NaN                             NaN   \n",
       "6308             NaN              NaN                             NaN   \n",
       "6309             NaN              NaN                             NaN   \n",
       "8702             NaN              NaN                             NaN   \n",
       "25722            NaN              NaN                             NaN   \n",
       "\n",
       "                            pdf  \\\n",
       "0          2018.06.25-Wolfe.pdf   \n",
       "1        2018.06.18-McNeely.pdf   \n",
       "2         2018.06.09-Denges.pdf   \n",
       "3      2018.06.08-Arrawarra.pdf   \n",
       "4          2018.06.04-Ramos.pdf   \n",
       "...                         ...   \n",
       "6307                        NaN   \n",
       "6308                        NaN   \n",
       "6309                        NaN   \n",
       "8702                        NaN   \n",
       "25722                       NaN   \n",
       "\n",
       "                                            href formula  \\\n",
       "0      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "3      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "4      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "...                                                  ...   \n",
       "6307                                                 NaN   \n",
       "6308                                                 NaN   \n",
       "6309                                                 NaN   \n",
       "8702                                                 NaN   \n",
       "25722                                                NaN   \n",
       "\n",
       "                                                    href  original order  \n",
       "0      http://sharkattackfile.net/spreadsheets/pdf_di...          6303.0  \n",
       "1      http://sharkattackfile.net/spreadsheets/pdf_di...          6302.0  \n",
       "2      http://sharkattackfile.net/spreadsheets/pdf_di...          6301.0  \n",
       "3      http://sharkattackfile.net/spreadsheets/pdf_di...          6300.0  \n",
       "4      http://sharkattackfile.net/spreadsheets/pdf_di...          6299.0  \n",
       "...                                                  ...             ...  \n",
       "6307                                                 NaN          6309.0  \n",
       "6308                                                 NaN          6310.0  \n",
       "6309                                                 NaN             NaN  \n",
       "8702                                                 NaN             NaN  \n",
       "25722                                                NaN             NaN  \n",
       "\n",
       "[6312 rows x 20 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['Case Number.1', 'Case Number.2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a closer look at the tail of the df, we notice that the last couple of rows are still holding many null values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>original order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6297</th>\n",
       "      <td>ND.0005</td>\n",
       "      <td>Before 1903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>Roebuck Bay</td>\n",
       "      <td>Diving</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H. Taunton; N. Bartlett,  p. 234</td>\n",
       "      <td>ND-0005-RoebuckBay.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6298</th>\n",
       "      <td>ND.0004</td>\n",
       "      <td>Before 1903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl diving</td>\n",
       "      <td>Ahmun</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H. Taunton; N. Bartlett,  pp. 233-234</td>\n",
       "      <td>ND-0004-Ahmun.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6299</th>\n",
       "      <td>ND.0003</td>\n",
       "      <td>1900-1905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Ocracoke Inlet</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Coast Guard personnel</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F. Schwartz, p.23; C. Creswell, GSAF</td>\n",
       "      <td>ND-0003-Ocracoke_1900-1905.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6300</th>\n",
       "      <td>ND.0002</td>\n",
       "      <td>1883-1889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>PANAMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Panama Bay 8¬∫N, 79¬∫W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jules Patterson</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Sun, 10/20/1938</td>\n",
       "      <td>ND-0002-JulesPatterson.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6301</th>\n",
       "      <td>ND.0001</td>\n",
       "      <td>1845-1853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>CEYLON (SRI LANKA)</td>\n",
       "      <td>Eastern Province</td>\n",
       "      <td>Below the English fort, Trincomalee</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>FATAL. \"Shark bit him in half, carrying away t...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S.W. Baker</td>\n",
       "      <td>ND-0001-Ceylon.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6302</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6303</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6305.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6304</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6305</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6306</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6308.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8702</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25722</th>\n",
       "      <td>xx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Case Number         Date  Year        Type             Country  \\\n",
       "6297      ND.0005  Before 1903   0.0  Unprovoked           AUSTRALIA   \n",
       "6298      ND.0004  Before 1903   0.0  Unprovoked           AUSTRALIA   \n",
       "6299      ND.0003    1900-1905   0.0  Unprovoked                 USA   \n",
       "6300      ND.0002    1883-1889   0.0  Unprovoked              PANAMA   \n",
       "6301      ND.0001    1845-1853   0.0  Unprovoked  CEYLON (SRI LANKA)   \n",
       "6302            0          NaN   NaN         NaN                 NaN   \n",
       "6303            0          NaN   NaN         NaN                 NaN   \n",
       "6304            0          NaN   NaN         NaN                 NaN   \n",
       "6305            0          NaN   NaN         NaN                 NaN   \n",
       "6306            0          NaN   NaN         NaN                 NaN   \n",
       "6307            0          NaN   NaN         NaN                 NaN   \n",
       "6308            0          NaN   NaN         NaN                 NaN   \n",
       "6309            0          NaN   NaN         NaN                 NaN   \n",
       "8702          NaN          NaN   NaN         NaN                 NaN   \n",
       "25722          xx          NaN   NaN         NaN                 NaN   \n",
       "\n",
       "                    Area                             Location      Activity  \\\n",
       "6297   Western Australia                          Roebuck Bay        Diving   \n",
       "6298   Western Australia                                  NaN  Pearl diving   \n",
       "6299      North Carolina                       Ocracoke Inlet      Swimming   \n",
       "6300                 NaN                 Panama Bay 8¬∫N, 79¬∫W           NaN   \n",
       "6301    Eastern Province  Below the English fort, Trincomalee      Swimming   \n",
       "6302                 NaN                                  NaN           NaN   \n",
       "6303                 NaN                                  NaN           NaN   \n",
       "6304                 NaN                                  NaN           NaN   \n",
       "6305                 NaN                                  NaN           NaN   \n",
       "6306                 NaN                                  NaN           NaN   \n",
       "6307                 NaN                                  NaN           NaN   \n",
       "6308                 NaN                                  NaN           NaN   \n",
       "6309                 NaN                                  NaN           NaN   \n",
       "8702                 NaN                                  NaN           NaN   \n",
       "25722                NaN                                  NaN           NaN   \n",
       "\n",
       "                        Name Sex   Age  \\\n",
       "6297                    male    M  NaN   \n",
       "6298                   Ahmun    M  NaN   \n",
       "6299   Coast Guard personnel    M  NaN   \n",
       "6300         Jules Patterson    M  NaN   \n",
       "6301                    male    M   15   \n",
       "6302                     NaN  NaN  NaN   \n",
       "6303                     NaN  NaN  NaN   \n",
       "6304                     NaN  NaN  NaN   \n",
       "6305                     NaN  NaN  NaN   \n",
       "6306                     NaN  NaN  NaN   \n",
       "6307                     NaN  NaN  NaN   \n",
       "6308                     NaN  NaN  NaN   \n",
       "6309                     NaN  NaN  NaN   \n",
       "8702                     NaN  NaN  NaN   \n",
       "25722                    NaN  NaN  NaN   \n",
       "\n",
       "                                                  Injury Fatal (Y/N) Time  \\\n",
       "6297                                               FATAL           Y  NaN   \n",
       "6298                                               FATAL           Y  NaN   \n",
       "6299                                               FATAL           Y  NaN   \n",
       "6300                                               FATAL           Y  NaN   \n",
       "6301   FATAL. \"Shark bit him in half, carrying away t...           Y  NaN   \n",
       "6302                                                 NaN         NaN  NaN   \n",
       "6303                                                 NaN         NaN  NaN   \n",
       "6304                                                 NaN         NaN  NaN   \n",
       "6305                                                 NaN         NaN  NaN   \n",
       "6306                                                 NaN         NaN  NaN   \n",
       "6307                                                 NaN         NaN  NaN   \n",
       "6308                                                 NaN         NaN  NaN   \n",
       "6309                                                 NaN         NaN  NaN   \n",
       "8702                                                 NaN         NaN  NaN   \n",
       "25722                                                NaN         NaN  NaN   \n",
       "\n",
       "      Species                  Investigator or Source  \\\n",
       "6297       NaN       H. Taunton; N. Bartlett,  p. 234   \n",
       "6298       NaN  H. Taunton; N. Bartlett,  pp. 233-234   \n",
       "6299       NaN   F. Schwartz, p.23; C. Creswell, GSAF   \n",
       "6300       NaN                    The Sun, 10/20/1938   \n",
       "6301       NaN                             S.W. Baker   \n",
       "6302       NaN                                    NaN   \n",
       "6303       NaN                                    NaN   \n",
       "6304       NaN                                    NaN   \n",
       "6305       NaN                                    NaN   \n",
       "6306       NaN                                    NaN   \n",
       "6307       NaN                                    NaN   \n",
       "6308       NaN                                    NaN   \n",
       "6309       NaN                                    NaN   \n",
       "8702       NaN                                    NaN   \n",
       "25722      NaN                                    NaN   \n",
       "\n",
       "                                  pdf  \\\n",
       "6297           ND-0005-RoebuckBay.pdf   \n",
       "6298                ND-0004-Ahmun.pdf   \n",
       "6299   ND-0003-Ocracoke_1900-1905.pdf   \n",
       "6300       ND-0002-JulesPatterson.pdf   \n",
       "6301               ND-0001-Ceylon.pdf   \n",
       "6302                              NaN   \n",
       "6303                              NaN   \n",
       "6304                              NaN   \n",
       "6305                              NaN   \n",
       "6306                              NaN   \n",
       "6307                              NaN   \n",
       "6308                              NaN   \n",
       "6309                              NaN   \n",
       "8702                              NaN   \n",
       "25722                             NaN   \n",
       "\n",
       "                                            href formula  \\\n",
       "6297   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6298   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6299   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6300   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6301   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6302                                                 NaN   \n",
       "6303                                                 NaN   \n",
       "6304                                                 NaN   \n",
       "6305                                                 NaN   \n",
       "6306                                                 NaN   \n",
       "6307                                                 NaN   \n",
       "6308                                                 NaN   \n",
       "6309                                                 NaN   \n",
       "8702                                                 NaN   \n",
       "25722                                                NaN   \n",
       "\n",
       "                                                    href  original order  \n",
       "6297   http://sharkattackfile.net/spreadsheets/pdf_di...             6.0  \n",
       "6298   http://sharkattackfile.net/spreadsheets/pdf_di...             5.0  \n",
       "6299   http://sharkattackfile.net/spreadsheets/pdf_di...             4.0  \n",
       "6300   http://sharkattackfile.net/spreadsheets/pdf_di...             3.0  \n",
       "6301   http://sharkattackfile.net/spreadsheets/pdf_di...             2.0  \n",
       "6302                                                 NaN          6304.0  \n",
       "6303                                                 NaN          6305.0  \n",
       "6304                                                 NaN          6306.0  \n",
       "6305                                                 NaN          6307.0  \n",
       "6306                                                 NaN          6308.0  \n",
       "6307                                                 NaN          6309.0  \n",
       "6308                                                 NaN          6310.0  \n",
       "6309                                                 NaN             NaN  \n",
       "8702                                                 NaN             NaN  \n",
       "25722                                                NaN             NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it's only the last 10 columns which have the nulls.\n",
    "df.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#since they are only 10 instances, we can drop them manually using their index:\n",
    "df = df.drop([6302, 6303,6304,6305,6306,6307,6308,6309,8702,25722])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>original order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6297</th>\n",
       "      <td>ND.0005</td>\n",
       "      <td>Before 1903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>Roebuck Bay</td>\n",
       "      <td>Diving</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H. Taunton; N. Bartlett,  p. 234</td>\n",
       "      <td>ND-0005-RoebuckBay.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6298</th>\n",
       "      <td>ND.0004</td>\n",
       "      <td>Before 1903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl diving</td>\n",
       "      <td>Ahmun</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H. Taunton; N. Bartlett,  pp. 233-234</td>\n",
       "      <td>ND-0004-Ahmun.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6299</th>\n",
       "      <td>ND.0003</td>\n",
       "      <td>1900-1905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Ocracoke Inlet</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Coast Guard personnel</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F. Schwartz, p.23; C. Creswell, GSAF</td>\n",
       "      <td>ND-0003-Ocracoke_1900-1905.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6300</th>\n",
       "      <td>ND.0002</td>\n",
       "      <td>1883-1889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>PANAMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Panama Bay 8¬∫N, 79¬∫W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jules Patterson</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Sun, 10/20/1938</td>\n",
       "      <td>ND-0002-JulesPatterson.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6301</th>\n",
       "      <td>ND.0001</td>\n",
       "      <td>1845-1853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>CEYLON (SRI LANKA)</td>\n",
       "      <td>Eastern Province</td>\n",
       "      <td>Below the English fort, Trincomalee</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>FATAL. \"Shark bit him in half, carrying away t...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S.W. Baker</td>\n",
       "      <td>ND-0001-Ceylon.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Case Number         Date  Year        Type             Country  \\\n",
       "6297     ND.0005  Before 1903   0.0  Unprovoked           AUSTRALIA   \n",
       "6298     ND.0004  Before 1903   0.0  Unprovoked           AUSTRALIA   \n",
       "6299     ND.0003    1900-1905   0.0  Unprovoked                 USA   \n",
       "6300     ND.0002    1883-1889   0.0  Unprovoked              PANAMA   \n",
       "6301     ND.0001    1845-1853   0.0  Unprovoked  CEYLON (SRI LANKA)   \n",
       "\n",
       "                   Area                             Location      Activity  \\\n",
       "6297  Western Australia                          Roebuck Bay        Diving   \n",
       "6298  Western Australia                                  NaN  Pearl diving   \n",
       "6299     North Carolina                       Ocracoke Inlet      Swimming   \n",
       "6300                NaN                 Panama Bay 8¬∫N, 79¬∫W           NaN   \n",
       "6301   Eastern Province  Below the English fort, Trincomalee      Swimming   \n",
       "\n",
       "                       Name Sex   Age  \\\n",
       "6297                   male    M  NaN   \n",
       "6298                  Ahmun    M  NaN   \n",
       "6299  Coast Guard personnel    M  NaN   \n",
       "6300        Jules Patterson    M  NaN   \n",
       "6301                   male    M   15   \n",
       "\n",
       "                                                 Injury Fatal (Y/N) Time  \\\n",
       "6297                                              FATAL           Y  NaN   \n",
       "6298                                              FATAL           Y  NaN   \n",
       "6299                                              FATAL           Y  NaN   \n",
       "6300                                              FATAL           Y  NaN   \n",
       "6301  FATAL. \"Shark bit him in half, carrying away t...           Y  NaN   \n",
       "\n",
       "     Species                  Investigator or Source  \\\n",
       "6297      NaN       H. Taunton; N. Bartlett,  p. 234   \n",
       "6298      NaN  H. Taunton; N. Bartlett,  pp. 233-234   \n",
       "6299      NaN   F. Schwartz, p.23; C. Creswell, GSAF   \n",
       "6300      NaN                    The Sun, 10/20/1938   \n",
       "6301      NaN                             S.W. Baker   \n",
       "\n",
       "                                 pdf  \\\n",
       "6297          ND-0005-RoebuckBay.pdf   \n",
       "6298               ND-0004-Ahmun.pdf   \n",
       "6299  ND-0003-Ocracoke_1900-1905.pdf   \n",
       "6300      ND-0002-JulesPatterson.pdf   \n",
       "6301              ND-0001-Ceylon.pdf   \n",
       "\n",
       "                                           href formula  \\\n",
       "6297  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6298  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6299  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6300  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6301  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                   href  original order  \n",
       "6297  http://sharkattackfile.net/spreadsheets/pdf_di...             6.0  \n",
       "6298  http://sharkattackfile.net/spreadsheets/pdf_di...             5.0  \n",
       "6299  http://sharkattackfile.net/spreadsheets/pdf_di...             4.0  \n",
       "6300  http://sharkattackfile.net/spreadsheets/pdf_di...             3.0  \n",
       "6301  http://sharkattackfile.net/spreadsheets/pdf_di...             2.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü¶àÔ∏è\n",
    "Whith this cleaned dataframe, we can look deeper into the actual data.\n",
    "\n",
    "Notice that we still have additional columns that are not giving us any **'meaty information'** !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are just old indexes\n",
    "# df['original order'].value_counts()\n",
    "\n",
    "# And these are only the titles of the pdfs\n",
    "# df['pdf'].value_counts()\n",
    "\n",
    "# let's get rid of them\n",
    "df = df.drop(columns = ['pdf', 'original order'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü¶àÔ∏è\n",
    "The `href` and `href formula` columns look very similar, but since they can't be read on the DataFrame that pandas provides, we'll try to use our `sampler()` function again to compare them both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[href            http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " href formula    http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " Name: 1123, dtype: object,\n",
       " href            http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " href formula    http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " Name: 6026, dtype: object]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sampler(df, ['href', 'href formula'],2))\n",
    "# This however, returns invalid links which are not accurately represented.\n",
    "# example: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü¶àÔ∏è\n",
    "Well.. Oops?\n",
    "To actually see the contents, I've resorted to two separate methods, `random.sample` and a `for` loop.\n",
    "\n",
    "These cells can be re-run a couple of times to make sure the data in the columns is homogeneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://sharkattackfile.net/spreadsheets/pdf_directory/2014.10.02.b-Vandenberg.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1941.07.23-boatBingo.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1975.06.23.a-Hutson.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1964.02.14.a-Berabi.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1850.10.21-sailor.pdf']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['http://sharkattackfile.net/spreadsheets/pdf_directory/1978.03.05-GuluDeep.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/2003.04.20.b-Albright.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1956.08.00.e-Kirby.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1939.11.11-boat-Maroubra.pdf',\n",
       " 'http://sharkattackfile.net/spreadsheets/pdf_directory/1902.08.28.R-Nicotera.pdf']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# With Random sample\n",
    "display(random.sample(list(df['href']), 5))\n",
    "display(random.sample(list(df['href formula']), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 470, href:         http://sharkattackfile.net/spreadsheets/pdf_directory/2014.12.15-DanielSmith.pdf\n",
      "index: 470, href formula: http://sharkattackfile.net/spreadsheets/pdf_directory/2014.12.15-DanielSmith.pdf\n",
      "index: 725, href:         http://sharkattackfile.net/spreadsheets/pdf_directory/2012.11.04.a-Kekaha.pdf\n",
      "index: 725, href formula: http://sharkattackfile.net/spreadsheets/pdf_directory/2012.11.04.a-Kekaha.pdf\n",
      "index: 939, href:         http://sharkattackfile.net/spreadsheets/pdf_directory/2011.03.16-Mondy.pdf\n",
      "index: 939, href formula: http://sharkattackfile.net/spreadsheets/pdf_directory/2011.03.16-Mondy.pdf\n",
      "index: 623, href:         http://sharkattackfile.net/spreadsheets/pdf_directory/2013.09.12-Portman.pdf\n",
      "index: 623, href formula: http://sharkattackfile.net/spreadsheets/pdf_directory/2013.09.12-Portman.pdf\n",
      "index: 302, href:         http://sharkattackfile.net/spreadsheets/pdf_directory/2016.03.02-Thomas.pdf\n",
      "index: 302, href formula: http://sharkattackfile.net/spreadsheets/pdf_directory/2016.03.02-Thomas.pdf\n"
     ]
    }
   ],
   "source": [
    "# With a FOR loop\n",
    "for i in range(5):\n",
    "    e = random.choice(range(1000))\n",
    "    print(f\"index: {e}, href:         {df.iloc[e]['href']}\")\n",
    "    print(f\"index: {e}, href formula: {df.iloc[e]['href formula']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è\n",
    "The links on both columns seem to match, most of the times anyways.\n",
    "\n",
    "In some cases, the `href` seems to have an duplication on its links which corrupted them and made them innaccessible.\n",
    "\n",
    "However, the `href formula` actually saved the correct URL format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://sharkattackfile.net/spreadsheets/pdf_directory/http://sharkattackfile.net/spreadsheets/pdf_directory/2015.11.15.a-Engelman.pdf\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/2015.11.15.a-Engelman.pdf\n",
      "\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/http://sharkattackfile.net/spreadsheets/pdf_directory/2015.12.21.a-Brazil.pdf\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/2015.12.21.a-Brazil.pdf\n",
      "\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/http://sharkattackfile.net/spreadsheets/pdf_directory/2014.00.00.b-OceanicWhitetip.pdf\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/2014.00.00.b-OceanicWhitetip.pdf\n",
      "\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/http://sharkattackfile.net/spreadsheets/pdf_directory/2014.04.03-Armstrong.pdf\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/2014.04.03-Armstrong.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examples of the corrupted link versus their working counterpart\n",
    "print(df.iloc[332]['href']), print(df.iloc[332]['href formula'])\n",
    "print()\n",
    "print(df.iloc[324]['href']), print(df.iloc[324]['href formula'])\n",
    "print()\n",
    "print(df.iloc[588]['href']), print(df.iloc[588]['href formula'])\n",
    "print()\n",
    "print(df.iloc[569]['href']), print(df.iloc[569]['href formula'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the sake of simplicity, we will drop the `href` column, and replace it with the `href formula`\n",
    "df = df.drop(columns='href')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèäÔ∏è IDEAS:\n",
    "- The pdfs presented on the links seem quite structured\n",
    " \n",
    " - It could be possible to parse them later down the road and use a **REGEX** to find more data\n",
    " \n",
    " - Like, adding a column that lists the **'Moon Phase'** described on some of the pdfs\n",
    "\n",
    "- I also have ran query a few times to notice that all pdfs have actually been uploaded to the same website and have the same naming structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è\n",
    "\n",
    "Some column names can be simplified, and some have unnecesary white spaces.\n",
    " \n",
    " Let's fix that right away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Name', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time',\n",
       "       'Species ', 'Investigator or Source', 'href formula'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The column with the name of the victims does not bring much relevant information to our study\n",
    "df = df.drop(columns='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CaseNum', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Sex', 'Age', 'Injury', 'Fatal', 'Time', 'Species',\n",
       "       'Source', 'href'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df\n",
    "df.columns = ['CaseNum', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
    "       'Activity', 'Sex', 'Age', 'Injury', 'Fatal', 'Time',\n",
    "       'Species', 'Source', 'href']\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèäÔ∏è SPECIES IDEAS: \n",
    "- create a standardized column for species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è\n",
    "Many of the values from the Species column are `nulls`. We'll fill them with the same `Invalid` value that other cells already have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "White shark                                           163\n",
       "Shark involvement prior to death was not confirmed    105\n",
       "Invalid                                               102\n",
       "Shark involvement not confirmed                        88\n",
       "Tiger shark                                            73\n",
       "                                                     ... \n",
       "Shark involvement not confirmed & highly unlikely       1\n",
       "Port Jackson shark, 1m                                  1\n",
       "Tiger shark, 4 m [13'] female                           1\n",
       "1.5' to 2' shark                                        1\n",
       "White shark, 5m to 6m                                   1\n",
       "Name: Species, Length: 1549, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BEFORE\n",
    "df.Species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Invalid                                               2940\n",
       "White shark                                            163\n",
       "Shark involvement prior to death was not confirmed     105\n",
       "Shark involvement not confirmed                         88\n",
       "Tiger shark                                             73\n",
       "                                                      ... \n",
       "Shark involvement not confirmed & highly unlikely        1\n",
       "Port Jackson shark, 1m                                   1\n",
       "Tiger shark, 4 m [13'] female                            1\n",
       "1.5' to 2' shark                                         1\n",
       "White shark, 5m to 6m                                    1\n",
       "Name: Species, Length: 1549, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Species = df.Species.fillna('Invalid')\n",
    "\n",
    "#AFTER\n",
    "df.Species.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        6302\n",
       "unique       1549\n",
       "top       Invalid\n",
       "freq         2940\n",
       "Name: Species, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With the .describe() method, we can see that there are 1549 unique values in this column\n",
    "# It would be interesting to create a new column which narrows this down to less unique values.\n",
    "df.Species.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è \n",
    "\n",
    "[Can you guess the Pok√©mon?](https://i.ytimg.com/vi/mg1A94zBWBw/hqdefault.jpg)\n",
    "\n",
    "There are more than 400 species of sharks, and while lurking around the `Species` column you can find all sort of weird animals. Did you know there's even one species of shark known as the *'Cookie Cutter shark'* ?\n",
    "\n",
    "I certainly had no clue. \n",
    "\n",
    "Here I tried to sort a bit of the data, by creating a secondary column which *mapped* the different species, while also taking out possible confusions. \n",
    "\n",
    "- *note: the scrutiny for this categorization is quite laxed, as this project is more an exercise with data and less a research paper. The data, however, can be processed even further by forking this github repo.*\n",
    "\n",
    "Below is the process of creating such a secondary table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Invalid                                               2940\n",
       "White shark                                            163\n",
       "Shark involvement prior to death was not confirmed     105\n",
       "Shark involvement not confirmed                         88\n",
       "Tiger shark                                             73\n",
       "                                                      ... \n",
       "Shark involvement not confirmed & highly unlikely        1\n",
       "Port Jackson shark, 1m                                   1\n",
       "Tiger shark, 4 m [13'] female                            1\n",
       "1.5' to 2' shark                                         1\n",
       "White shark, 5m to 6m                                    1\n",
       "Name: Species2, Length: 1549, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping the Species column to decrease the amount of unique values\n",
    "df['Species2'] = df['Species']  # .map(lambda x: 'White shark' if 'White shark' in x else x)\n",
    "df.Species2.value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèäÔ∏è "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shark_identifier(x):\n",
    "    \n",
    "    #THERE ARE SO MANY ERRORS IN THIS COLUMN, let's filter them\n",
    "    # NOT CONFIRMED\n",
    "    if 'not confirmed' in x.lower():\n",
    "        return \"NOT CONFIRMED\"\n",
    "    if 'unidentified' in x.lower():\n",
    "        return 'NOT CONFIRMED'\n",
    "    if ' or ' in x.lower():\n",
    "        return 'NOT CONFIRMED'\n",
    "    #INVALIDS\n",
    "    if 'no shark involvement' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    if 'invalid' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    if 'questionable' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    if 'doubtful' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    #OTHER INVALIDS\n",
    "    if 'hoax' in x.lower():\n",
    "        return 'HOAX'\n",
    "    if 'drown' in x.lower():\n",
    "        return 'DROWNED'\n",
    "    if 'stingray' in x.lower():\n",
    "        return 'STINGRAY'\n",
    "    \n",
    "    \n",
    "    #  --- WHO'S THAT POKEMON?---\n",
    "    \n",
    "    if 'white shark' in x.lower():\n",
    "        return \"White shark\"\n",
    "    if 'tiger shark' in x.lower():\n",
    "        return \"Tiger shark\"\n",
    "    if 'bull shark' in x.lower():\n",
    "        return \"Bull shark\"\n",
    "    if 'nurse shark' in x.lower():\n",
    "        return 'Nurse shark'\n",
    "    if 'brown shark' in x.lower():\n",
    "        return 'Brown shark'\n",
    "    if 'mako shark' in x.lower():\n",
    "        return 'Mako Shark'\n",
    "    if 'blue shark' in x.lower():\n",
    "        return 'Blue shark'\n",
    "    if 'bronze whaler shark' in x.lower():\n",
    "        return 'Bronze whaler shark'\n",
    "    if 'blacktip shark' in x.lower():\n",
    "        return 'Blacktip shark'\n",
    "    if 'whitetip shark' in x.lower():\n",
    "        return 'Whitetip shark'\n",
    "    if 'sandbar shark' in x.lower():\n",
    "        return 'Sandbar shark'\n",
    "    if 'lemon shark' in x.lower():\n",
    "        return 'Lemon shark'\n",
    "    if 'hammerhead shark' in x.lower():\n",
    "        return 'Hammerhead shark'\n",
    "    if 'raggedtooth shark' in x.lower():\n",
    "        return 'Raggedtooth shark'\n",
    "    if 'thresher shark' in x.lower():\n",
    "        return 'Thresher shark'\n",
    "    if 'dusky shark' in x.lower():\n",
    "        return 'Dusky shark'\n",
    "    if 'wobbegong shark' in x.lower():\n",
    "        return 'Wobbegong shark'\n",
    "    if 'dusky shark' in x.lower():\n",
    "        return 'Dusky shark'\n",
    "    if 'spinner shark' in x.lower():\n",
    "        return 'Spinner shark'\n",
    "    if 'blue nose shark' in x.lower():\n",
    "        return 'Blue nose shark'\n",
    "    if 'leopard shark' in x.lower():\n",
    "        return 'Leopard shark'\n",
    "    if 'silvertip shark' in x.lower():\n",
    "        return 'Silvertip shark'\n",
    "    if 'gray shark' in x.lower():\n",
    "        return 'Gray shark'\n",
    "    if 'grey shark' in x.lower():\n",
    "        return 'Gray shark'\n",
    "    if 'reef shark' in x.lower():\n",
    "        return 'Reef shark'\n",
    "    if 'carpet shark' in x.lower():\n",
    "        return 'Carpet shark'\n",
    "    if 'whaler shark' in x.lower():\n",
    "        return 'Whaler shark'\n",
    "    \n",
    "    # -- trying to filter sizes --\n",
    "    \n",
    "    if \"\"\"10'\"\"\" in x.lower():\n",
    "        return \"\"\"10' shark\"\"\"\n",
    "    if \"\"\"11'\"\"\" in x.lower():\n",
    "        return \"\"\"11' shark\"\"\"\n",
    "    if \"\"\"12'\"\"\" in x.lower():\n",
    "        return \"\"\"12' shark\"\"\"\n",
    "    if \"\"\"13'\"\"\" in x.lower():\n",
    "        return \"\"\"13' shark\"\"\"\n",
    "    if \"\"\"14'\"\"\" in x.lower():\n",
    "        return \"\"\"14' shark\"\"\"\n",
    "    if \"\"\"15'\"\"\" in x.lower():\n",
    "        return \"\"\"15' shark\"\"\"\n",
    "    if \"\"\"16'\"\"\" in x.lower():\n",
    "        return \"\"\"16' shark\"\"\"\n",
    "    if \"\"\"17'\"\"\" in x.lower():\n",
    "        return \"\"\"17' shark\"\"\"\n",
    "    if \"\"\"18'\"\"\" in x.lower():\n",
    "        return \"\"\"18' shark\"\"\"\n",
    "    if \"\"\"19'\"\"\" in x.lower():\n",
    "        return \"\"\"19' shark\"\"\"\n",
    "    if \"\"\"20'\"\"\" in x.lower():\n",
    "        return \"\"\"20' shark\"\"\"\n",
    "    if \"\"\"21'\"\"\" in x.lower():\n",
    "        return \"\"\"21' shark\"\"\"\n",
    "    \n",
    "    if \"\"\"1'\"\"\" in x.lower():\n",
    "        return \"\"\"1' shark\"\"\"\n",
    "    if \"\"\"2'\"\"\" in x.lower():\n",
    "        return \"\"\"2' shark\"\"\"\n",
    "    if \"\"\"3'\"\"\" in x.lower():\n",
    "        return \"\"\"3' shark\"\"\"\n",
    "    if \"\"\"4'\"\"\" in x.lower():\n",
    "        return \"\"\"4' shark\"\"\"\n",
    "    if \"\"\"5'\"\"\" in x.lower():\n",
    "        return \"\"\"5' shark\"\"\"\n",
    "    if \"\"\"6'\"\"\" in x.lower():\n",
    "        return \"\"\"6' shark\"\"\"\n",
    "    if \"\"\"7'\"\"\" in x.lower():\n",
    "        return \"\"\"7' shark\"\"\"    \n",
    "    if \"\"\"8'\"\"\" in x.lower():\n",
    "        return \"\"\"8' shark\"\"\"\n",
    "    if \"\"\"9'\"\"\" in x.lower():\n",
    "        return \"\"\"9' shark\"\"\"\n",
    "\n",
    "    if 'small shark' in x.lower():\n",
    "        return 'Small shark'\n",
    "    \n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "# df['Species2'] = df['Species'].map(shark_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shark_identifier2(x):\n",
    "    \n",
    "    #THERE ARE SO MANY ERRORS IN THIS COLUMN, let's filter them\n",
    "    # NOT CONFIRMED\n",
    "    if 'not confirmed' in x.lower():\n",
    "        return \"OTHER / NOT KNOWN\"\n",
    "    if 'unidentified' in x.lower():\n",
    "        return 'OTHER / NOT KNOWN'\n",
    "    if ' or ' in x.lower():\n",
    "        return 'OTHER / NOT KNOWN'\n",
    "    #INVALIDS\n",
    "    if 'no shark involvement' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    if 'invalid' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    if 'questionable' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    if 'doubtful' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    #OTHER INVALIDS\n",
    "    if 'hoax' in x.lower():\n",
    "        return 'HOAX'\n",
    "    if 'drown' in x.lower():\n",
    "        return 'DROWNED'\n",
    "    if 'stingray' in x.lower():\n",
    "        return 'STINGRAY'\n",
    "    \n",
    "    \n",
    "    #  --- WHO'S THAT POKEMON?---\n",
    "    \n",
    "    if 'white shark' in x.lower():\n",
    "        return \"White shark\"\n",
    "    if 'tiger shark' in x.lower():\n",
    "        return \"Tiger shark\"\n",
    "    if 'bull shark' in x.lower():\n",
    "        return \"Bull shark\"\n",
    "    if 'nurse shark' in x.lower():\n",
    "        return 'Nurse shark'\n",
    "    if 'brown shark' in x.lower():\n",
    "        return 'Brown shark'\n",
    "    if 'mako shark' in x.lower():\n",
    "        return 'Mako Shark'\n",
    "    if 'blue shark' in x.lower():\n",
    "        return 'Blue shark'\n",
    "    if 'bronze whaler shark' in x.lower():\n",
    "        return 'Bronze whaler shark'\n",
    "    if 'blacktip shark' in x.lower():\n",
    "        return 'Blacktip shark'\n",
    "    if 'whitetip shark' in x.lower():\n",
    "        return 'Whitetip shark'\n",
    "    if 'sandbar shark' in x.lower():\n",
    "        return 'Sandbar shark'\n",
    "    if 'lemon shark' in x.lower():\n",
    "        return 'Lemon shark'\n",
    "    if 'hammerhead shark' in x.lower():\n",
    "        return 'Hammerhead shark'\n",
    "    if 'raggedtooth shark' in x.lower():\n",
    "        return 'Raggedtooth shark'\n",
    "    if 'thresher shark' in x.lower():\n",
    "        return 'Thresher shark'\n",
    "    if 'dusky shark' in x.lower():\n",
    "        return 'Dusky shark'\n",
    "    if 'wobbegong shark' in x.lower():\n",
    "        return 'Wobbegong shark'\n",
    "    if 'dusky shark' in x.lower():\n",
    "        return 'Dusky shark'\n",
    "    if 'spinner shark' in x.lower():\n",
    "        return 'Spinner shark'\n",
    "    if 'blue nose shark' in x.lower():\n",
    "        return 'Blue nose shark'\n",
    "    if 'leopard shark' in x.lower():\n",
    "        return 'Leopard shark'\n",
    "    if 'silvertip shark' in x.lower():\n",
    "        return 'Silvertip shark'\n",
    "    if 'gray shark' in x.lower():\n",
    "        return 'Gray shark'\n",
    "    if 'grey shark' in x.lower():\n",
    "        return 'Gray shark'\n",
    "    if 'reef shark' in x.lower():\n",
    "        return 'Reef shark'\n",
    "    if 'carpet shark' in x.lower():\n",
    "        return 'Carpet shark'\n",
    "    if 'whaler shark' in x.lower():\n",
    "        return 'Whaler shark'\n",
    "    if 'zambesi shark' in x.lower():\n",
    "        return 'Zambesi shark'\n",
    "    \n",
    "    # -- trying to filter sizes --\n",
    "\n",
    "    if 'small shark' in x.lower():\n",
    "        return 'Small shark'\n",
    "    \n",
    "    else:\n",
    "        return 'OTHER / NOT KNOWN'\n",
    "    \n",
    "df['Species2'] = df['Species'].map(shark_identifier2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INVALID ENTRY          3052\n",
      "OTHER / NOT KNOWN      1467\n",
      "White shark             625\n",
      "Tiger shark             275\n",
      "Bull shark              171\n",
      "Nurse shark              94\n",
      "Reef shark               65\n",
      "Bronze whaler shark      60\n",
      "Blacktip shark           56\n",
      "Small shark              55\n",
      "Mako Shark               53\n",
      "Wobbegong shark          46\n",
      "Hammerhead shark         44\n",
      "Raggedtooth shark        43\n",
      "Blue shark               38\n",
      "Lemon shark              34\n",
      "Zambesi shark            29\n",
      "Whitetip shark           23\n",
      "Spinner shark            20\n",
      "Dusky shark              12\n",
      "Carpet shark              8\n",
      "Whaler shark              6\n",
      "Sandbar shark             5\n",
      "Thresher shark            4\n",
      "Gray shark                3\n",
      "Brown shark               3\n",
      "Leopard shark             2\n",
      "DROWNED                   2\n",
      "Silvertip shark           2\n",
      "HOAX                      2\n",
      "Blue nose shark           2\n",
      "STINGRAY                  1\n",
      "Name: Species2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.Species2.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which species generate the most fatalities\n",
    "# df2.groupby('Species2', 'Fatal').filter(lambda x : x > 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèäÔ∏è TYPE OF ATTACK\n",
    "- On the Type column, dont count sea disasters, questionable and boatomg\n",
    "- Stardarize\n",
    "- Size of the shark according to Species column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Type.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unprovoked      4595\n",
       "Provoked         574\n",
       "Invalid          551\n",
       "Sea Disaster     239\n",
       "Boating          203\n",
       "Boat             137\n",
       "Questionable       2\n",
       "Boatomg            1\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Type = df.Type.fillna('Invalid')\n",
    "df.Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unprovoked      4595\n",
       "Provoked         574\n",
       "Invalid          553\n",
       "Boat             341\n",
       "Sea Disaster     239\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boat, Boating and Boatomg to 1 category\n",
    "filt = lambda x: 'Boat' if 'Boat' in x else x\n",
    "df.Type = df.Type.map(filt)\n",
    "\n",
    "# Questionable to Invalid\n",
    "filt = lambda x : 'Invalid' if 'Questionable' in x else x\n",
    "df.Type = df.Type.map(filt)\n",
    "\n",
    "df.Type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Surfing                                                                 971\n",
       "Swimming                                                                869\n",
       "Fishing                                                                 431\n",
       "Spearfishing                                                            333\n",
       "Bathing                                                                 162\n",
       "                                                                       ... \n",
       "Collecting crayfish                                                       1\n",
       "Swimming between  anchored  pearling luggers                              1\n",
       "Anti-sabotage night dive exercise alongside destroyer (Scuba diving)      1\n",
       "Diving / Kissing the shark                                                1\n",
       "Fishing for red fish                                                      1\n",
       "Name: Activity, Length: 1532, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Activity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Swimming                                                    1274\n",
       "Surfing                                                     1203\n",
       "Fishing                                                     1119\n",
       "Diving                                                       600\n",
       "Wading                                                       163\n",
       "                                                            ... \n",
       "Overturned skiff                                               1\n",
       "Catching sardines                                              1\n",
       "Boeing 757 enroute from Porta Plata plunged into the sea       1\n",
       "Washing sand off a speared fish                                1\n",
       "Harpooned shark                                                1\n",
       "Name: Activity2, Length: 370, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filt(x):\n",
    "    if type(x) is str:\n",
    "        if 'floating' in x.lower():\n",
    "            return 'Floating'\n",
    "        if 'diving' in x.lower():\n",
    "            return 'Diving'\n",
    "        if 'dive' in x.lower():\n",
    "            return 'Diving'\n",
    "        if 'skiing' in x.lower():\n",
    "            return 'Skiing'\n",
    "        if 'ski ' in x.lower():\n",
    "            return 'Skiing'\n",
    "        if 'surf' in x.lower():\n",
    "            return 'Surfing'\n",
    "        if 'snorkel' in x.lower():\n",
    "            return 'Snorkeling'\n",
    "        if 'fishing' in x.lower():\n",
    "            return 'Fishing'\n",
    "        if 'drift' in x.lower():\n",
    "            return 'Drifting'\n",
    "        if 'swim' in x.lower():\n",
    "            return 'Swimming'\n",
    "        if 'bathing' in x.lower():\n",
    "            return 'Swimming'\n",
    "        if 'paddle' in x.lower():\n",
    "            return 'Paddleboarding'\n",
    "        \n",
    "        if 'raft' in x.lower():\n",
    "            return 'Rafting'\n",
    "        if 'playing' in x.lower():\n",
    "            return 'Playing'\n",
    "        \n",
    "        if 'wading' in x.lower():\n",
    "            return 'Wading'\n",
    "        if 'research' in x.lower():\n",
    "            return 'Research'\n",
    "        if 'rescue' in x.lower():\n",
    "            return 'Rescuing someone / somthing'\n",
    "        if 'rescuing' in x.lower():\n",
    "            return 'Rescuing someone / somthing'\n",
    "        if 'overboard' in x.lower():\n",
    "            return 'Fell from boat into water'        \n",
    "        if 'fell' in x.lower():\n",
    "            return 'Fell to the water'\n",
    "        \n",
    "        if 'boat' in x.lower():\n",
    "            return 'Boating'\n",
    "        if 'yatch' in x.lower():\n",
    "            return 'Boating'\n",
    "        if 'disaster' in x.lower():\n",
    "            return 'Sea Disaster'\n",
    "        if 'wreck' in x.lower():\n",
    "            return 'Shipwreck'\n",
    "        if 'capsize' in x.lower():\n",
    "            return 'Shipwreck'\n",
    "        if 'sank' in x.lower():\n",
    "            return 'Shipwreck'\n",
    "        if 'torpedo' in x.lower():\n",
    "            return 'War (Torpedo)'\n",
    "        if 'warship' in x.lower():\n",
    "            return 'War (Warship)'\n",
    "        if ('plane' and 'crash') in x.lower():\n",
    "            return 'Airplane crash'\n",
    "        if 'airliner' in x.lower():\n",
    "            return 'Airplane crash'\n",
    "        \n",
    "        \n",
    "        if 'filming' in x.lower():\n",
    "            return 'Filming / Photoshoot'\n",
    "        if 'sailing' in x.lower():\n",
    "            return 'Sailing'\n",
    "        if 'net ' in x.lower():\n",
    "            return 'Fishing'\n",
    "        if ' net' in x.lower():\n",
    "            \n",
    "            return 'Fishing'\n",
    "        if 'photo' in x.lower():\n",
    "            return 'Filming / Photoshoot'\n",
    "        if 'sinking' in x.lower():\n",
    "            return 'Sea Disaster'\n",
    "        \n",
    "        if 'board' in x.lower():\n",
    "            return 'Other types of Boarding sports'\n",
    "        else:\n",
    "            return x\n",
    "df['Activity2'] = df.Activity.map(filt)\n",
    "df.Activity2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill the empty values too\n",
    "df.Activity.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Activity2 = df.Activity2.fillna('NOT SPECIFIED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Activity2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fatalities\n",
    "Sort them out and map them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "539"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Fatal.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Fatal = df.Fatal.fillna('UNKNOWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N          4301\n",
       "Y          1389\n",
       "UNKNOWN     612\n",
       "Name: Fatal, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filt(x):\n",
    "    if 'UNKNOWN' in x.upper():\n",
    "        return x\n",
    "    if 'N' in x.upper():\n",
    "        return 'N'\n",
    "    if 'Y' in x.upper():\n",
    "        return 'Y'\n",
    "    else:\n",
    "        return 'UNKNOWN'\n",
    "\n",
    "df['Fatal'] = df.Fatal.map(filt)\n",
    "df.Fatal.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attacks.csv  clean.ipynb  exported.csv\tREADME.md  shark-attacks.png\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FATAL                                                                                          802\n",
       "Survived                                                                                        97\n",
       "Foot bitten                                                                                     87\n",
       "No injury                                                                                       82\n",
       "Leg bitten                                                                                      72\n",
       "                                                                                              ... \n",
       "Laceration to right hand and cuts on fingertips                                                  1\n",
       "FATAL, thigh bitten, hands lacerated                                                             1\n",
       "Right leg severed at knee, abrasion on left ankle                                                1\n",
       "No injury to occupants. Sharks continually followed the dinghy, and one smashed its rudder       1\n",
       "Shark attacked boat, shark killed & towed to shore                                               1\n",
       "Name: Injury, Length: 3737, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Injury.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CaseNum      False\n",
      "Date         False\n",
      "Year         False\n",
      "Type         False\n",
      "Country      False\n",
      "Area          True\n",
      "Location      True\n",
      "Activity      True\n",
      "Sex           True\n",
      "Injury       False\n",
      "Fatal        False\n",
      "Species      False\n",
      "Source       False\n",
      "href         False\n",
      "Species2     False\n",
      "Activity2    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(df.count() < 5000) # To know how much data are we missin on each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è\n",
    "The `Age` and `Time` column have many null values and is not going to be uses to test our hypothesis, so we will drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CaseNum', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Sex', 'Injury', 'Fatal', 'Species', 'Source', 'href',\n",
       "       'Species2', 'Activity2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['Age', 'Time'])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 'duped values')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop dupes and compare lengths\n",
    "df_pdf_nodupes = df.drop_duplicates()\n",
    "\n",
    "len(df) - len(df_pdf_nodupes), 'duped values'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÑÔ∏è Exporting the cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It cannot get any simpler than this:\n",
    "df.to_csv('exported.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Injuries and types of attack\n",
    "The GSAF categorizes scavenging bites on humans as \"questionable incidents.\"\n",
    "\n",
    "## PROVOKED\n",
    "Provoked attacks occur when a human touches, hooks, nets, or otherwise aggravates the animal. Incidents that occur outside of a shark's natural habitat, such as aquariums and research holding-pens, are considered provoked, as are all incidents involving captured sharks. Sometimes humans inadvertently provoke an attack, such as when a surfer accidentally hits a shark with a surf board.\n",
    "\n",
    "## UNPROVOKED\n",
    "- Hit-and-run attack\n",
    "- Sneak Attack\n",
    "- Bump-and-bite attack \n",
    "\n",
    "For more information on how to differentiate PROVOKED vs UNPROVOKED attacks :\n",
    "https://en.wikipedia.org/wiki/Shark_attack#Types_of_attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there is no column that states if the attack was provoked or not,\n",
    "# I want to analyze the injury column to distinguish between the cases that were provoked\n",
    "# and those that were unprovoked.\n",
    "\n",
    "random.sample(list(df_label.Injury.value_counts().items()),20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorizing  Provoked and  Unprovoked attacks\n",
    "#df_clean.loc[df_clean[\"trany\"].str.startswith(\"M\"),\"trany\"] = \"Manual\"\n",
    "\n",
    "provoked = ['PROVOKED', 'hook', 'shot']\n",
    "#map(lambda words, x : words in x, provoked, df_nodupes.loc[df_nodupes['Injury'].str])\n",
    "df_nodupes.loc[df_nodupes['Injury'].str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodupes.loc[df_nodupes['Injury'].str]\n",
    "\n",
    "# df_provoked = np.where(df_nodupes.Injury.isin(provoked), True, False) \n",
    "\n",
    "# Passing that categorization to a new PROVOKED COLUMN\n",
    "df_nodupes['Provoked'] = df_provoked\n",
    "df_nodupes['Provoked'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CaseNum', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Sex', 'Age', 'Injury', 'Fatal', 'Time', 'Species',\n",
       "       'Source', 'href', 'Species2', 'Activity2'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CaseNum      False\n",
       "Date         False\n",
       "Year         False\n",
       "Type         False\n",
       "Country      False\n",
       "Area         False\n",
       "Location     False\n",
       "Activity     False\n",
       "Sex          False\n",
       "Age           True\n",
       "Injury       False\n",
       "Fatal        False\n",
       "Time          True\n",
       "Species      False\n",
       "Source       False\n",
       "href         False\n",
       "Species2     False\n",
       "Activity2    False\n",
       "dtype: bool"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CaseNum       object\n",
       "Date          object\n",
       "Year         float64\n",
       "Type          object\n",
       "Country       object\n",
       "Area          object\n",
       "Location      object\n",
       "Activity      object\n",
       "Sex           object\n",
       "Age           object\n",
       "Injury        object\n",
       "Fatal         object\n",
       "Time          object\n",
       "Species       object\n",
       "Source        object\n",
       "href          object\n",
       "Species2      object\n",
       "Activity2     object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.columns) # To know which are the columns in the DF\n",
    "display(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label[['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
    "       'Activity', 'Name', 'Sex', 'Age', 'Injury', 'Fatal', 'Time', 'Species',\n",
    "       'Investigator or Source', 'pdf', 'href',\n",
    "       'Case Number.1', 'Case Number.2']].head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
