{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# TO-DO: \n",
    "- how to add the dataset to gitignore?\n",
    "- how can i create a separate module that holds my functions?\n",
    "- change the functions so that they use dictionaries and not huge if/elif/else loop.\n",
    "\n",
    "- Why column labels now begin with a `u`?! \n",
    "    ```\n",
    "  Index([u'CaseNum', u'Date', u'Year', u'Type', u'Country', u'Area', u'Location',\n",
    "       u'Activity', u'Sex', u'Age', u'Injury', u'Fatal', u'Time', u'Species',\n",
    "       u'Source', u'href'],\n",
    "      dtype='object')\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Shark attacks, a project by Roberto Henr√≠quez Perozo. Data Analytics Bootcamp at IronHack](INPUT/shark-attacks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<center>\n",
    "    <h1> PART I: Data cleaning and exploration</h1>\n",
    "</center>\n",
    "\n",
    "## üé£Ô∏è Step 0 - Basic knowledge\n",
    "To begin the development of this project, it would be good to hold a minimum understanding of `Shark Attacks`.\n",
    "\n",
    "As I did not know much about this topic at the day the project started, I have recurred to the shark-attack wiki: https://en.wikipedia.org/wiki/Shark_attack\n",
    "\n",
    "With this information in mind, below is the process of data exploration, cleaning, and wrangling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start also by importing the modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "pd.compat.PY3 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé£Ô∏è Step 1 - Defining the dataset path, and importing it to begin basic dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To follow along and access the DataSet, download it from KAGGLE using this link\n",
    "# https://www.kaggle.com/teajay/global-shark-attacks\n",
    "\n",
    "# Once you have downloaded the DataSet, change the following `dataset` variable to match the \n",
    "# path where you have saved the 'attacks.csv' file.\n",
    "dataset = 'INPUT/attacks.csv' \n",
    "\n",
    "\n",
    "df = pd.read_csv(dataset, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will check some basic information about the dataset, in order to formulate a more educated hypothesis which we could actually put to test with the data available.\n",
    "\n",
    "Here, I notice that the shape of the `df` with no duplicates is very small when compared to the whole `df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåäÔ∏è  FUNCT\n",
    "This comparison could be turned into its own function, as it will be executed quite often"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('before', (25723, 24))\n",
      "('after', (6312, 24))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index([           'Case Number',                   'Date',\n",
       "                         'Year',                   'Type',\n",
       "                      'Country',                   'Area',\n",
       "                     'Location',               'Activity',\n",
       "                         'Name',                   'Sex ',\n",
       "                          'Age',                 'Injury',\n",
       "                  'Fatal (Y/N)',                   'Time',\n",
       "                     'Species ', 'Investigator or Source',\n",
       "                          'pdf',           'href formula',\n",
       "                         'href',          'Case Number.1',\n",
       "                'Case Number.2',         'original order',\n",
       "                  'Unnamed: 22',            'Unnamed: 23'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'll delete de duplicated rows\n",
    "print('before', df.shape)\n",
    "df = df.drop_duplicates()\n",
    "print('after', df.shape)\n",
    "\n",
    "# And also take a look at the columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25-Jun-2018\n",
       "1    18-Jun-2018\n",
       "2    09-Jun-2018\n",
       "3    08-Jun-2018\n",
       "4    04-Jun-2018\n",
       "Name: Date, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I want to take a look at the time structures\n",
    "df.Date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>6303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>6302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>6299.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case Number.1 Case Number.2  original order Unnamed: 22 Unnamed: 23\n",
       "0    2018.06.25    2018.06.25          6303.0         NaN         NaN\n",
       "1    2018.06.18    2018.06.18          6302.0         NaN         NaN\n",
       "2    2018.06.09    2018.06.09          6301.0         NaN         NaN\n",
       "3    2018.06.08    2018.06.08          6300.0         NaN         NaN\n",
       "4    2018.06.04    2018.06.04          6299.0         NaN         NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I want to see what is the data on the last couple\n",
    "# of columns which have unexplicit labels\n",
    "df[['Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22', 'Unnamed: 23']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6312, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Case Number.1       10\n",
       "Case Number.2       10\n",
       "original order       3\n",
       "Unnamed: 22       6311\n",
       "Unnamed: 23       6310\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Too many null values on the last two columns... let's count them\n",
    "print(df.shape)\n",
    "df[['Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22', 'Unnamed: 23']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there is only 1 value in the 'Unnamed: 22' column, and 2 values in the\n",
    "# 'Unnamed: 22' column, I'll not consider this data for my analysis.\n",
    "df = df.drop(columns=['Unnamed: 22', 'Unnamed: 23'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ND.0016         1\n",
       "1902.08.08      1\n",
       "2006.02.12.a    1\n",
       "2010.10.02.b    1\n",
       "1924.01.25      1\n",
       "1928.01.00      1\n",
       "1968.04.15      1\n",
       "1845.11.04      1\n",
       "2010.05.18.a    1\n",
       "2010.05.18.b    1\n",
       "Name: Case Number.1, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following columns seemed a little bit rare, so i do a value count to find out what they are about\n",
    "df['Case Number.1'].value_counts().sort_values().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ND.0015         1\n",
       "1902.08.08      1\n",
       "2006.02.12.a    1\n",
       "2010.10.02.b    1\n",
       "1924.01.25      1\n",
       "1928.01.00      1\n",
       "1968.04.15      1\n",
       "1845.11.04      1\n",
       "2010.05.18.a    1\n",
       "2010.05.18.b    1\n",
       "Name: Case Number.2, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Case Number.2'].value_counts().sort_values().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåäÔ∏è Creating a 'sampler' function\n",
    "\n",
    "After some thought and googling, it seems like these are some sort of notation used to categorize and order the shark attacks. They also use the a notation that includes dates. \n",
    "\n",
    "**Is it the same as the Date on the Date column?**\n",
    "\n",
    "To find out, I wanted to pick random samples of the dataframe, but python's built-in `random` module kept giving me trouble when I tried to use it alongside pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object sampler at 0x7f72e9c45fa0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VER 03\n",
    "def sampler(df, column, sample_size):\n",
    "# This function generates an iterator out of random rows from a pandas dataframe's specific column\n",
    "    \n",
    "    # Defining how many samples to fetch from the df\n",
    "    for i in range(sample_size):\n",
    "        \n",
    "        # Now a random index is generated out of the total length of the column...\n",
    "        i = random.choice(range(len(df[column])))\n",
    "        # ... to return the data values in that index as an iterator:\n",
    "        yield df.iloc[i][column]\n",
    "        \n",
    "        # For future versions, it would be good to look at how I can return the\n",
    "        # data as a tupple with just the data, and not have it return a formatted string\n",
    "        # or even better, a pandas dataframe with the results\n",
    "\n",
    "\n",
    "# Now let's try it out\n",
    "sampler(df, ['Date', 'Case Number.1', 'Case Number.2'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Date              15-Sep-2016\n",
       " Case Number.1    2016.09.15.R\n",
       " Case Number.2    2016.09.15.R\n",
       " Name: 218, dtype: object, Date             21-Feb-2000\n",
       " Case Number.1     2000.02.21\n",
       " Case Number.2     2000.02.21\n",
       " Name: 2071, dtype: object, Date              08-Mar-1998\n",
       " Case Number.1    1998.03.08.a\n",
       " Case Number.2    1998.03.08.a\n",
       " Name: 2199, dtype: object, Date             11-Aug--2011\n",
       " Case Number.1      2011.08.11\n",
       " Case Number.2      2011.08.11\n",
       " Name: 888, dtype: object, Date             29-Oct-1992\n",
       " Case Number.1     1992.10.29\n",
       " Case Number.2     1992.10.29\n",
       " Name: 2527, dtype: object]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since sampler generates iterators, list() must be used to see its contents\n",
    "list(sampler(df, ['Date', 'Case Number.1', 'Case Number.2'], 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è\n",
    "From this output, we can see that the `Case Number` Columnns are actually replicating the info that we already have on the `Date` column. Therefore, we will drop both `Case Number` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Case Number.1', 'Case Number.2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ü¶àÔ∏è\n",
    " Taking a closer look at the tail of the df, we notice that the last couple of rows are still holding many null values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode character u'\\xba' in position 1037: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/home/rh/.local/lib/python2.7/site-packages/IPython/core/formatters.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rh/.local/lib/python2.7/site-packages/IPython/lib/pretty.pyc\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    401\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                                 \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                             \u001b[0;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rh/.local/lib/python2.7/site-packages/IPython/lib/pretty.pyc\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rh/.local/lib/python2.7/site-packages/pandas/core/base.pyc\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mYields\u001b[0m \u001b[0mBytestring\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPy2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnicode\u001b[0m \u001b[0mString\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpy3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \"\"\"\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character u'\\xba' in position 1037: ordinal not in range(128)"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>original order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6300</th>\n",
       "      <td>ND.0002</td>\n",
       "      <td>1883-1889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>PANAMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Panama Bay 8¬∫N, 79¬∫W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jules Patterson</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Sun, 10/20/1938</td>\n",
       "      <td>ND-0002-JulesPatterson.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6301</th>\n",
       "      <td>ND.0001</td>\n",
       "      <td>1845-1853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>CEYLON (SRI LANKA)</td>\n",
       "      <td>Eastern Province</td>\n",
       "      <td>Below the English fort, Trincomalee</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>FATAL. \"Shark bit him in half, carrying away t...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S.W. Baker</td>\n",
       "      <td>ND-0001-Ceylon.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6302</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6303</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6305.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6304</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6305</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6306</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6308.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8702</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25722</th>\n",
       "      <td>xx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it's only the last 10 columns which have the nulls.\n",
    "df.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#since they are only 10 instances, we can drop them manually using their index:\n",
    "df = df.drop([6302, 6303,6304,6305,6306,6307,6308,6309,8702,25722])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode character u'\\xba' in position 791: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/home/rh/.local/lib/python2.7/site-packages/IPython/core/formatters.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rh/.local/lib/python2.7/site-packages/IPython/lib/pretty.pyc\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    401\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                                 \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                             \u001b[0;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rh/.local/lib/python2.7/site-packages/IPython/lib/pretty.pyc\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rh/.local/lib/python2.7/site-packages/pandas/core/base.pyc\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mYields\u001b[0m \u001b[0mBytestring\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPy2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnicode\u001b[0m \u001b[0mString\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpy3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \"\"\"\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character u'\\xba' in position 791: ordinal not in range(128)"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>original order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6297</th>\n",
       "      <td>ND.0005</td>\n",
       "      <td>Before 1903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>Roebuck Bay</td>\n",
       "      <td>Diving</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H. Taunton; N. Bartlett,  p. 234</td>\n",
       "      <td>ND-0005-RoebuckBay.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6298</th>\n",
       "      <td>ND.0004</td>\n",
       "      <td>Before 1903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl diving</td>\n",
       "      <td>Ahmun</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H. Taunton; N. Bartlett,  pp. 233-234</td>\n",
       "      <td>ND-0004-Ahmun.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6299</th>\n",
       "      <td>ND.0003</td>\n",
       "      <td>1900-1905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Ocracoke Inlet</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Coast Guard personnel</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F. Schwartz, p.23; C. Creswell, GSAF</td>\n",
       "      <td>ND-0003-Ocracoke_1900-1905.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6300</th>\n",
       "      <td>ND.0002</td>\n",
       "      <td>1883-1889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>PANAMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Panama Bay 8¬∫N, 79¬∫W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jules Patterson</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Sun, 10/20/1938</td>\n",
       "      <td>ND-0002-JulesPatterson.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6301</th>\n",
       "      <td>ND.0001</td>\n",
       "      <td>1845-1853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>CEYLON (SRI LANKA)</td>\n",
       "      <td>Eastern Province</td>\n",
       "      <td>Below the English fort, Trincomalee</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>FATAL. \"Shark bit him in half, carrying away t...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S.W. Baker</td>\n",
       "      <td>ND-0001-Ceylon.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü¶àÔ∏è\n",
    "With this cleaned dataframe, we can look deeper into the actual data.\n",
    "\n",
    "Notice that we still have additional columns that are not giving us any **'meaty information'** !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are just old indexes\n",
    "# df['original order'].value_counts()\n",
    "\n",
    "# And these are only the titles of the pdfs\n",
    "# df['pdf'].value_counts()\n",
    "\n",
    "# let's get rid of them\n",
    "df = df.drop(columns = ['pdf', 'original order'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü¶àÔ∏è\n",
    "The `href` and `href formula` columns look very similar, but since they can't be read on the DataFrame that pandas provides, we'll try to use our `sampler()` function again to compare them both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[href            http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " href formula    http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " Name: 86, dtype: object,\n",
       " href            http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " href formula    http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " Name: 1417, dtype: object]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sampler(df, ['href', 'href formula'],2))\n",
    "# This however, returns invalid links which are not accurately represented.\n",
    "# example: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü¶àÔ∏è\n",
    "Well.. Oops?\n",
    "To actually see the contents, I've resorted to two separate methods, `random.sample` and a `for` loop.\n",
    "\n",
    "These cells can be re-run a couple of times to make sure the data in the columns is homogeneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'http://sharkattackfile.net/spreadsheets/pdf_directory/1931.08.23-Rodriguez.pdf',\n",
       " u'http://sharkattackfile.net/spreadsheets/pdf_directory/1966.00.00-Derry.pdf',\n",
       " u'http://sharkattackfile.net/spreadsheets/pdf_directory/1894.11.28-Hewison.pdf',\n",
       " u'http://sharkattackfile.net/spreadsheets/pdf_directory/2000.10.29-Kelly.pdf',\n",
       " u'http://sharkattackfile.net/spreadsheets/pdf_directory/1970.07.05-NV-male.pdf']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[u'http://sharkattackfile.net/spreadsheets/pdf_directory/1948.09.17.R-Kaymaz.pdf',\n",
       " u'http://sharkattackfile.net/spreadsheets/pdf_directory/1947.10.10-Serafim.pdf',\n",
       " u'http://sharkattackfile.net/spreadsheets/pdf_directory/1902.12.22.R-Wiseman.pdf',\n",
       " u'http://sharkattackfile.net/spreadsheets/pdf_directory/1961.05.21-Orr_Collier.pdf',\n",
       " u'http://sharkattackfile.net/spreadsheets/pdf_directory/1956.01.16.R-Conedo.pdf']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# With Random sample\n",
    "display(random.sample(list(df['href']), 5))\n",
    "display(random.sample(list(df['href formula']), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(5):\\n   e = random.choice(range(1000))\\n   print(f\"index: {e} href:         {df.iloc[e][\\'href\\']})\\n   print(f\"index: {e} href formula: {df.iloc[e][\\'href formula\\']}\")\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # üî•Ô∏è FIX SYNTAX ERROR\n",
    " #With a FOR loop \n",
    "\"\"\"\n",
    "for i in range(5):\n",
    "    e = random.choice(range(1000))\n",
    "    print(f\"index: {e} href:         {df.iloc[e]['href']})\n",
    "    print(f\"index: {e} href formula: {df.iloc[e]['href formula']}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è\n",
    "The links on both columns seem to match, most of the times anyways.\n",
    "\n",
    "In some cases, the `href` seems to have an duplication on its links which corrupted them and made them innaccessible.\n",
    "\n",
    "However, the `href formula` actually saved the correct URL format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://sharkattackfile.net/spreadsheets/pdf_directory/http://sharkattackfile.net/spreadsheets/pdf_directory/2015.11.15.a-Engelman.pdf\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/2015.11.15.a-Engelman.pdf\n",
      "()\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/http://sharkattackfile.net/spreadsheets/pdf_directory/2015.12.21.a-Brazil.pdf\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/2015.12.21.a-Brazil.pdf\n",
      "()\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/http://sharkattackfile.net/spreadsheets/pdf_directory/2014.00.00.b-OceanicWhitetip.pdf\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/2014.00.00.b-OceanicWhitetip.pdf\n",
      "()\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/http://sharkattackfile.net/spreadsheets/pdf_directory/2014.04.03-Armstrong.pdf\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/2014.04.03-Armstrong.pdf\n"
     ]
    }
   ],
   "source": [
    "# üî•Ô∏è FIX SYNTAX ERRORS\n",
    "\n",
    "# Examples of the corrupted link versus their working counterpart\n",
    "print(df.iloc[332]['href'])\n",
    "print(df.iloc[332]['href formula'])\n",
    "print()\n",
    "print(df.iloc[324]['href'])\n",
    "print(df.iloc[324]['href formula'])\n",
    "print()\n",
    "print(df.iloc[588]['href'])\n",
    "print(df.iloc[588]['href formula'])\n",
    "print()\n",
    "print(df.iloc[569]['href'])\n",
    "print(df.iloc[569]['href formula'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è\n",
    "\n",
    "For the sake of simplicity, we will drop the `href` column, and replace it with the `href formula`. Also, some column names can be simplified, and some have unnecesary white spaces. Let's fix that right away:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Name', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time',\n",
       "       'Species ', 'Investigator or Source', 'href formula'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The column with the name of the victims does not bring much relevant information to our study\n",
    "df = df.drop(columns='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CaseNum', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Sex', 'Age', 'Injury', 'Fatal', 'Time', 'Species',\n",
       "       'Source', 'href'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['CaseNum', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
    "       'Activity', 'Sex', 'Age', 'Injury', 'Fatal', 'Time',\n",
    "       'Species', 'Source', 'href']\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è\n",
    "Many of the values from the **Species** column are `nulls`. We'll fill them with the same `Invalid` value that other cells already have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "White shark                                                                         163\n",
       "Shark involvement prior to death was not confirmed                                  105\n",
       "Invalid                                                                             102\n",
       "Shark involvement not confirmed                                                      88\n",
       "Tiger shark                                                                          73\n",
       "Shark involvement prior to death unconfirmed                                         68\n",
       "Bull shark                                                                           52\n",
       "6' shark                                                                             40\n",
       "4' shark                                                                             40\n",
       "1.8 m [6'] shark                                                                     35\n",
       "Questionable incident                                                                35\n",
       "Questionable                                                                         34\n",
       "1.5 m [5'] shark                                                                     32\n",
       "1.2 m [4'] shark                                                                     27\n",
       "5' shark                                                                             26\n",
       "3' shark                                                                             26\n",
       "2 m shark                                                                            25\n",
       "4' to 5' shark                                                                       24\n",
       "3 m [10'] shark                                                                      22\n",
       "Wobbegong shark                                                                      21\n",
       "No shark involvement                                                                 21\n",
       "3' to 4' shark                                                                       18\n",
       "3 m shark                                                                            17\n",
       "2.4 m [8'] shark                                                                     16\n",
       "3.7 m [12'] shark                                                                    15\n",
       "12' shark                                                                            15\n",
       "Blacktip shark                                                                       15\n",
       "Blue shark                                                                           14\n",
       "1.2 m to 1.5 m [4' to 5'] shark                                                      14\n",
       "Shark involvement prior to death not confirmed                                       13\n",
       "                                                                                   ... \n",
       "Blue shark, 70-kg blue shark                                                          1\n",
       "Grey nurse shark, 1.5 m [5']                                                          1\n",
       "Tiger shark, <2 m TL                                                                  1\n",
       "3m shark                                                                              1\n",
       "Bull shark, 2.3 m [7.5']                                                              1\n",
       " 6' to 8' shark                                                                       1\n",
       "Bronze whaler shark,4 m [13']                                                         1\n",
       "1.8 m silky shark                                                                     1\n",
       "Tiger shark 3 m  [10']                                                                1\n",
       "7' female shark                                                                       1\n",
       "Mako shark, 5'                                                                        1\n",
       "Wobbegong shark                                                                       1\n",
       "Said to involve a 6 m to 7.3 m [20' to 24'] shark                                     1\n",
       "White shark, 3.7 m [12']                                                              1\n",
       "2.4 m [8'] white shark                                                                1\n",
       " Sevengill  shark, 1.2 m [4']                                                         1\n",
       "1 m  shark                                                                            1\n",
       "Bull shark, 400-lb                                                                    1\n",
       "Bronze whaler shark, 2 m                                                              1\n",
       "possibly a bull shark                                                                 1\n",
       "1.8 m [6'] Zambezi shark                                                              1\n",
       "80 kg shark                                                                           1\n",
       "16' white shark                                                                       1\n",
       "White shark, 2 m to 4 m [6'9\" to 13']                                                 1\n",
       "Bronze whaler shark, 3.7 m [12'] identified by G.P. Whitley based on description      1\n",
       "Sevengill shark, 2.4 m                                                                1\n",
       "Zambezi shark (tooth fragments recovered)                                             1\n",
       "Bonita sharkk, 200-lb                                                                 1\n",
       "3.7 m [12'] tiger shark                                                               1\n",
       "Blacktip reef shark, 1.5 m [5']                                                       1\n",
       "Name: Species, Length: 1549, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BEFORE\n",
    "df.Species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Invalid                                                                             2940\n",
       "White shark                                                                          163\n",
       "Shark involvement prior to death was not confirmed                                   105\n",
       "Shark involvement not confirmed                                                       88\n",
       "Tiger shark                                                                           73\n",
       "Shark involvement prior to death unconfirmed                                          68\n",
       "Bull shark                                                                            52\n",
       "6' shark                                                                              40\n",
       "4' shark                                                                              40\n",
       "1.8 m [6'] shark                                                                      35\n",
       "Questionable incident                                                                 35\n",
       "Questionable                                                                          34\n",
       "1.5 m [5'] shark                                                                      32\n",
       "1.2 m [4'] shark                                                                      27\n",
       "5' shark                                                                              26\n",
       "3' shark                                                                              26\n",
       "2 m shark                                                                             25\n",
       "4' to 5' shark                                                                        24\n",
       "3 m [10'] shark                                                                       22\n",
       "Wobbegong shark                                                                       21\n",
       "No shark involvement                                                                  21\n",
       "3' to 4' shark                                                                        18\n",
       "3 m shark                                                                             17\n",
       "2.4 m [8'] shark                                                                      16\n",
       "3.7 m [12'] shark                                                                     15\n",
       "12' shark                                                                             15\n",
       "Blacktip shark                                                                        15\n",
       "Blue shark                                                                            14\n",
       "1.2 m to 1.5 m [4' to 5'] shark                                                       14\n",
       "Shark involvement prior to death not confirmed                                        13\n",
       "                                                                                    ... \n",
       "Blue shark, 70-kg blue shark                                                           1\n",
       "Grey nurse shark, 1.5 m [5']                                                           1\n",
       "Tiger shark, <2 m TL                                                                   1\n",
       "3m shark                                                                               1\n",
       "Bull shark, 2.3 m [7.5']                                                               1\n",
       " 6' to 8' shark                                                                        1\n",
       "Bronze whaler shark,4 m [13']                                                          1\n",
       "1.8 m silky shark                                                                      1\n",
       "Tiger shark 3 m  [10']                                                                 1\n",
       "7' female shark                                                                        1\n",
       "Mako shark, 5'                                                                         1\n",
       "Wobbegong shark                                                                        1\n",
       "Said to involve a 6 m to 7.3 m [20' to 24'] shark                                      1\n",
       "White shark, 3.7 m [12']                                                               1\n",
       "2.4 m [8'] white shark                                                                 1\n",
       " Sevengill  shark, 1.2 m [4']                                                          1\n",
       "1 m  shark                                                                             1\n",
       "Bull shark, 400-lb                                                                     1\n",
       "Bronze whaler shark, 2 m                                                               1\n",
       "possibly a bull shark                                                                  1\n",
       "1.8 m [6'] Zambezi shark                                                               1\n",
       "80 kg shark                                                                            1\n",
       "16' white shark                                                                        1\n",
       "White shark, 2 m to 4 m [6'9\" to 13']                                                  1\n",
       "Bronze whaler shark, 3.7 m [12'] identified by G.P. Whitley based on description       1\n",
       "Sevengill shark, 2.4 m                                                                 1\n",
       "Zambezi shark (tooth fragments recovered)                                              1\n",
       "Bonita sharkk, 200-lb                                                                  1\n",
       "3.7 m [12'] tiger shark                                                                1\n",
       "Blacktip reef shark, 1.5 m [5']                                                        1\n",
       "Name: Species, Length: 1549, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Species = df.Species.fillna('Invalid')\n",
    "\n",
    "#AFTER\n",
    "df.Species.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        6302\n",
       "unique       1549\n",
       "top       Invalid\n",
       "freq         2940\n",
       "Name: Species, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With the .describe() method, we can see that there are 1549 unique values in this column\n",
    "# It would be interesting to create a new column which narrows this down to less unique values.\n",
    "df.Species.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è    [Can you guess the Pok√©mon?](https://i.ytimg.com/vi/mg1A94zBWBw/hqdefault.jpg)\n",
    "\n",
    "There are more than 400 species of sharks, and while lurking around the `Species` column you can find all sort of weird animals. Did you know there's even one species of shark known as the *'Cookie Cutter shark'* ?\n",
    "\n",
    "I certainly had no clue. \n",
    "\n",
    "Here I tried to sort a bit of the data, by creating a secondary column which *mapped* the different species, while also taking out possible confusions. \n",
    "\n",
    "- *note: the scrutiny for this categorization is quite laxed, as this project is more an exercise with data and less a research paper. The data, however, can be processed even further by forking this github repo.*\n",
    "\n",
    "Below is the process of creating such a secondary table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Invalid                                                                             2940\n",
       "White shark                                                                          163\n",
       "Shark involvement prior to death was not confirmed                                   105\n",
       "Shark involvement not confirmed                                                       88\n",
       "Tiger shark                                                                           73\n",
       "Shark involvement prior to death unconfirmed                                          68\n",
       "Bull shark                                                                            52\n",
       "6' shark                                                                              40\n",
       "4' shark                                                                              40\n",
       "1.8 m [6'] shark                                                                      35\n",
       "Questionable incident                                                                 35\n",
       "Questionable                                                                          34\n",
       "1.5 m [5'] shark                                                                      32\n",
       "1.2 m [4'] shark                                                                      27\n",
       "5' shark                                                                              26\n",
       "3' shark                                                                              26\n",
       "2 m shark                                                                             25\n",
       "4' to 5' shark                                                                        24\n",
       "3 m [10'] shark                                                                       22\n",
       "Wobbegong shark                                                                       21\n",
       "No shark involvement                                                                  21\n",
       "3' to 4' shark                                                                        18\n",
       "3 m shark                                                                             17\n",
       "2.4 m [8'] shark                                                                      16\n",
       "3.7 m [12'] shark                                                                     15\n",
       "12' shark                                                                             15\n",
       "Blacktip shark                                                                        15\n",
       "Blue shark                                                                            14\n",
       "1.2 m to 1.5 m [4' to 5'] shark                                                       14\n",
       "Shark involvement prior to death not confirmed                                        13\n",
       "                                                                                    ... \n",
       "Blue shark, 70-kg blue shark                                                           1\n",
       "Grey nurse shark, 1.5 m [5']                                                           1\n",
       "Tiger shark, <2 m TL                                                                   1\n",
       "3m shark                                                                               1\n",
       "Bull shark, 2.3 m [7.5']                                                               1\n",
       " 6' to 8' shark                                                                        1\n",
       "Bronze whaler shark,4 m [13']                                                          1\n",
       "1.8 m silky shark                                                                      1\n",
       "Tiger shark 3 m  [10']                                                                 1\n",
       "7' female shark                                                                        1\n",
       "Mako shark, 5'                                                                         1\n",
       "Wobbegong shark                                                                        1\n",
       "Said to involve a 6 m to 7.3 m [20' to 24'] shark                                      1\n",
       "White shark, 3.7 m [12']                                                               1\n",
       "2.4 m [8'] white shark                                                                 1\n",
       " Sevengill  shark, 1.2 m [4']                                                          1\n",
       "1 m  shark                                                                             1\n",
       "Bull shark, 400-lb                                                                     1\n",
       "Bronze whaler shark, 2 m                                                               1\n",
       "possibly a bull shark                                                                  1\n",
       "1.8 m [6'] Zambezi shark                                                               1\n",
       "80 kg shark                                                                            1\n",
       "16' white shark                                                                        1\n",
       "White shark, 2 m to 4 m [6'9\" to 13']                                                  1\n",
       "Bronze whaler shark, 3.7 m [12'] identified by G.P. Whitley based on description       1\n",
       "Sevengill shark, 2.4 m                                                                 1\n",
       "Zambezi shark (tooth fragments recovered)                                              1\n",
       "Bonita sharkk, 200-lb                                                                  1\n",
       "3.7 m [12'] tiger shark                                                                1\n",
       "Blacktip reef shark, 1.5 m [5']                                                        1\n",
       "Name: Species2, Length: 1549, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping the Species column to decrease the amount of unique values\n",
    "df['Species2'] = df['Species']\n",
    "df.Species2.value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåäÔ∏è Shark Identifier function\n",
    "\n",
    "This can be turned into key:value pairs for easier reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shark_identifier2(x):\n",
    "    \n",
    "    #THERE ARE SO MANY ERRORS IN THIS COLUMN, let's filter them\n",
    "    \n",
    "    # NOT CONFIRMED\n",
    "    if 'not confirmed' in x.lower():\n",
    "        return \"OTHER / NOT KNOWN\"\n",
    "    if 'unidentified' in x.lower():\n",
    "        return 'OTHER / NOT KNOWN'\n",
    "    if ' or ' in x.lower():\n",
    "        return 'OTHER / NOT KNOWN'\n",
    "    \n",
    "    # INVALIDS\n",
    "    if 'no shark involvement' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    if 'invalid' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    if 'questionable' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    if 'doubtful' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    \n",
    "    # OTHER INVALIDS\n",
    "    if 'hoax' in x.lower():\n",
    "        return 'HOAX'\n",
    "    if 'drown' in x.lower():\n",
    "        return 'DROWNED'\n",
    "    if 'stingray' in x.lower():\n",
    "        return 'STINGRAY'\n",
    "    \n",
    "    \n",
    "    #  --- WHO'S THAT POKEMON?---\n",
    "    \n",
    "    if 'white shark' in x.lower():\n",
    "        return \"White shark\"\n",
    "    if 'tiger shark' in x.lower():\n",
    "        return \"Tiger shark\"\n",
    "    if 'bull shark' in x.lower():\n",
    "        return \"Bull shark\"\n",
    "    if 'nurse shark' in x.lower():\n",
    "        return 'Nurse shark'\n",
    "    if 'brown shark' in x.lower():\n",
    "        return 'Brown shark'\n",
    "    if 'mako shark' in x.lower():\n",
    "        return 'Mako Shark'\n",
    "    if 'blue shark' in x.lower():\n",
    "        return 'Blue shark'\n",
    "    if 'bronze whaler shark' in x.lower():\n",
    "        return 'Bronze whaler shark'\n",
    "    if 'blacktip shark' in x.lower():\n",
    "        return 'Blacktip shark'\n",
    "    if 'whitetip shark' in x.lower():\n",
    "        return 'Whitetip shark'\n",
    "    if 'sandbar shark' in x.lower():\n",
    "        return 'Sandbar shark'\n",
    "    if 'lemon shark' in x.lower():\n",
    "        return 'Lemon shark'\n",
    "    if 'hammerhead shark' in x.lower():\n",
    "        return 'Hammerhead shark'\n",
    "    if 'raggedtooth shark' in x.lower():\n",
    "        return 'Raggedtooth shark'\n",
    "    if 'thresher shark' in x.lower():\n",
    "        return 'Thresher shark'\n",
    "    if 'dusky shark' in x.lower():\n",
    "        return 'Dusky shark'\n",
    "    if 'wobbegong shark' in x.lower():\n",
    "        return 'Wobbegong shark'\n",
    "    if 'dusky shark' in x.lower():\n",
    "        return 'Dusky shark'\n",
    "    if 'spinner shark' in x.lower():\n",
    "        return 'Spinner shark'\n",
    "    if 'blue nose shark' in x.lower():\n",
    "        return 'Blue nose shark'\n",
    "    if 'leopard shark' in x.lower():\n",
    "        return 'Leopard shark'\n",
    "    if 'silvertip shark' in x.lower():\n",
    "        return 'Silvertip shark'\n",
    "    if 'gray shark' in x.lower():\n",
    "        return 'Gray shark'\n",
    "    if 'grey shark' in x.lower():\n",
    "        return 'Gray shark'\n",
    "    if 'reef shark' in x.lower():\n",
    "        return 'Reef shark'\n",
    "    if 'carpet shark' in x.lower():\n",
    "        return 'Carpet shark'\n",
    "    if 'whaler shark' in x.lower():\n",
    "        return 'Whaler shark'\n",
    "    if 'zambesi shark' in x.lower():\n",
    "        return 'Zambesi shark'\n",
    "    \n",
    "    # -- trying to filter sizes --\n",
    "\n",
    "    if 'small shark' in x.lower():\n",
    "        return 'Other small shark'\n",
    "    \n",
    "    else:\n",
    "        return 'OTHER / NOT KNOWN'\n",
    "    \n",
    "df['Species2'] = df['Species'].map(shark_identifier2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INVALID ENTRY          3052\n",
      "OTHER / NOT KNOWN      1467\n",
      "White shark             625\n",
      "Tiger shark             275\n",
      "Bull shark              171\n",
      "Nurse shark              94\n",
      "Reef shark               65\n",
      "Bronze whaler shark      60\n",
      "Blacktip shark           56\n",
      "Other small shark        55\n",
      "Mako Shark               53\n",
      "Wobbegong shark          46\n",
      "Hammerhead shark         44\n",
      "Raggedtooth shark        43\n",
      "Blue shark               38\n",
      "Lemon shark              34\n",
      "Zambesi shark            29\n",
      "Whitetip shark           23\n",
      "Spinner shark            20\n",
      "Dusky shark              12\n",
      "Carpet shark              8\n",
      "Whaler shark              6\n",
      "Sandbar shark             5\n",
      "Thresher shark            4\n",
      "Brown shark               3\n",
      "Gray shark                3\n",
      "Blue nose shark           2\n",
      "Leopard shark             2\n",
      "Silvertip shark           2\n",
      "DROWNED                   2\n",
      "HOAX                      2\n",
      "STINGRAY                  1\n",
      "Name: Species2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.Species2.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü¶àÔ∏è Injuries and types of attack\n",
    "The GSAF categorizes scavenging bites on humans as \"questionable incidents.\"\n",
    "\n",
    "## PROVOKED\n",
    "Provoked attacks occur when a human touches, hooks, nets, or otherwise aggravates the animal. Incidents that occur outside of a shark's natural habitat, such as aquariums and research holding-pens, are considered provoked, as are all incidents involving captured sharks. Sometimes humans inadvertently provoke an attack, such as when a surfer accidentally hits a shark with a surf board.\n",
    "\n",
    "## UNPROVOKED\n",
    "- Hit-and-run attack\n",
    "- Sneak Attack\n",
    "- Bump-and-bite attack \n",
    "\n",
    "For more information on how to differentiate PROVOKED vs UNPROVOKED attacks :\n",
    "https://en.wikipedia.org/wiki/Shark_attack#Types_of_attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî•Ô∏è\n",
    "## üèäÔ∏è TYPE OF ATTACK / IDEAS\n",
    "- On the Type column, don't count `sea disasters`, `questionable`, and `boatomg` values\n",
    "- **Use the information on the 'Injury' column to define if the human hooked, shot, or provoked the shark**\n",
    "- Stardarize\n",
    "- Size of the shark according to Species column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Type.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unprovoked      4595\n",
       "Provoked         574\n",
       "Invalid          551\n",
       "Sea Disaster     239\n",
       "Boating          203\n",
       "Boat             137\n",
       "Questionable       2\n",
       "Boatomg            1\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Type = df.Type.fillna('Invalid')\n",
    "df.Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unprovoked      4595\n",
       "Provoked         574\n",
       "Invalid          553\n",
       "Boat             341\n",
       "Sea Disaster     239\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boat, Boating and Boatomg to 1 category\n",
    "filt = lambda x: 'Boat' if 'Boat' in x else x\n",
    "df.Type = df.Type.map(filt)\n",
    "\n",
    "# Questionable to Invalid\n",
    "filt = lambda x : 'Invalid' if 'Questionable' in x else x\n",
    "df.Type = df.Type.map(filt)\n",
    "\n",
    "df.Type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è Activities\n",
    "Now we will clean the `activities` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Surfing                                                      971\n",
       "Swimming                                                     869\n",
       "Fishing                                                      431\n",
       "Spearfishing                                                 333\n",
       "Bathing                                                      162\n",
       "Wading                                                       149\n",
       "Diving                                                       127\n",
       "Standing                                                      99\n",
       "Snorkeling                                                    89\n",
       "Scuba diving                                                  76\n",
       "Body boarding                                                 61\n",
       "Body surfing                                                  49\n",
       "Swimming                                                      47\n",
       "Kayaking                                                      33\n",
       "Pearl diving                                                  32\n",
       "Fell overboard                                                32\n",
       "Treading water                                                32\n",
       "Free diving                                                   29\n",
       "Boogie boarding                                               29\n",
       "Windsurfing                                                   19\n",
       "Walking                                                       17\n",
       "Boogie Boarding                                               16\n",
       "Shark fishing                                                 15\n",
       "Floating                                                      14\n",
       "Canoeing                                                      13\n",
       "Fishing                                                       13\n",
       "Surf skiing                                                   12\n",
       "Rowing                                                        12\n",
       "Surf fishing                                                  12\n",
       "Surf-skiing                                                   12\n",
       "                                                            ... \n",
       "Swimming, wearing black wetsuit & swim fins                    1\n",
       "Fell overboard                                                 1\n",
       "Swimming, using bundles of sticks as raft                      1\n",
       "Fishing, holding fish                                          1\n",
       "Wading with surfboard                                          1\n",
       "Night bathing                                                  1\n",
       "Fisherman                                                      1\n",
       "Spearfishing, holding mesh bag with speared fish               1\n",
       "Kakaying                                                       1\n",
       "S2F-1 airplane crashed immediately after carrier take-off      1\n",
       "Sitting                                                        1\n",
       "Italian liner Principessa Mafalda sank                         1\n",
       "Fishing for tarpon                                             1\n",
       "Hardhat diving from Japanese pearling lugger, Reiyo Maru       1\n",
       "Jumped overboard from Norwegian steamship Venator              1\n",
       "Escaping from blackbirding vessel                              1\n",
       "Boeing 757 enroute from Porta Plata plunged into the sea       1\n",
       "Fishing boat capsized                                          1\n",
       "Surfing, paddling shorewards                                   1\n",
       "ship M.V. Rizal sank during typhoon                            1\n",
       "Fishing, caught a 15' shark & took it onboard                  1\n",
       "Crawling                                                       1\n",
       "Swimming with pod of dolphins                                  1\n",
       "Bathing in 3' to 4' of water                                   1\n",
       "Removing fish from a trap                                      1\n",
       "Fishing, hauling in a 5-lb snapper                             1\n",
       "Murdered                                                       1\n",
       "Spent 8 days in dinghy                                         1\n",
       "Wakeboarding                                                   1\n",
       "Attacked shark with fists                                      1\n",
       "Name: Activity, Length: 1532, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Activity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåäÔ∏è Turn this filter into a key:value pairs \n",
    "üî•Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Swimming                                                               1274\n",
       "Surfing                                                                1203\n",
       "Fishing                                                                1119\n",
       "Diving                                                                  600\n",
       "CORRUPTED DATA POINT                                                    544\n",
       "Wading                                                                  163\n",
       "Other types of Boarding sports                                          138\n",
       "Snorkeling                                                              100\n",
       "Standing                                                                 99\n",
       "Boating                                                                  81\n",
       "Fell from boat into water                                                80\n",
       "Shipwreck                                                                68\n",
       "Floating                                                                 52\n",
       "Skiing                                                                   43\n",
       "Sea Disaster                                                             36\n",
       "Kayaking                                                                 33\n",
       "Treading water                                                           32\n",
       "Rafting                                                                  28\n",
       "Fell to the water                                                        25\n",
       "Drifting                                                                 24\n",
       "Playing                                                                  20\n",
       "Walking                                                                  17\n",
       "War (Torpedo)                                                            17\n",
       "Rescuing someone / somthing                                              17\n",
       "Paddleboarding                                                           16\n",
       "Canoeing                                                                 13\n",
       "Rowing                                                                   12\n",
       "Sailing                                                                  12\n",
       "Filming / Photoshoot                                                     11\n",
       "Murder                                                                    6\n",
       "                                                                       ... \n",
       "Collecting aquarium specimens                                             1\n",
       "British ship Macedon was thrown on her beam ends by a sudden squall       1\n",
       "Stamding                                                                  1\n",
       "Murdered by Thai pirates                                                  1\n",
       "Touching sharks                                                           1\n",
       "Standing, washing rear wheels of his ambulance in ankle-deep water        1\n",
       "Jumping in swells                                                         1\n",
       "Cleaning a tank                                                           1\n",
       "Walking in chest-deep water                                               1\n",
       "Treading water, waiting for a wave                                        1\n",
       "Attempted to return injured shark to the sea                              1\n",
       "Dynamiting fish                                                           1\n",
       "Treading for clams                                                        1\n",
       "In deep water about 100 yards from his ship                               1\n",
       "Fleet of canoes caught by a squall and charged by sharks.                 1\n",
       "Dismantling cable buoys of the cable ship All America                     1\n",
       "Standing, holding shark pup                                               1\n",
       "Pulling shark from the water                                              1\n",
       "Restraining a beached shark                                               1\n",
       "Helping men land a shark                                                  1\n",
       "Painting a ship                                                           1\n",
       "Touching the mouth of a supposedly dead shark                             1\n",
       "Washing sand off a speared fish                                           1\n",
       "Dragging banana seeds through the shallows                                1\n",
       "Standing in water with child in her arms                                  1\n",
       "Walking on reef                                                           1\n",
       "Attempting to illegally enter the USA                                     1\n",
       "Overturned skiff                                                          1\n",
       "Sittting in water with his child                                          1\n",
       "Attacked shark with fists                                                 1\n",
       "Name: Activity2, Length: 371, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filt(x):\n",
    "    if type(x) is unicode:\n",
    "        if 'floating' in x.lower():\n",
    "            return 'Floating'\n",
    "        if 'diving' in x.lower():\n",
    "            return 'Diving'\n",
    "        if 'dive' in x.lower():\n",
    "            return 'Diving'\n",
    "        if 'skiing' in x.lower():\n",
    "            return 'Skiing'\n",
    "        if 'ski ' in x.lower():\n",
    "            return 'Skiing'\n",
    "        if 'surf' in x.lower():\n",
    "            return 'Surfing'\n",
    "        if 'snorkel' in x.lower():\n",
    "            return 'Snorkeling'\n",
    "        if 'fishing' in x.lower():\n",
    "            return 'Fishing'\n",
    "        if 'drift' in x.lower():\n",
    "            return 'Drifting'\n",
    "        if 'swim' in x.lower():\n",
    "            return 'Swimming'\n",
    "        if 'bathing' in x.lower():\n",
    "            return 'Swimming'\n",
    "        if 'paddle' in x.lower():\n",
    "            return 'Paddleboarding'\n",
    "        \n",
    "        if 'raft' in x.lower():\n",
    "            return 'Rafting'\n",
    "        if 'playing' in x.lower():\n",
    "            return 'Playing'\n",
    "        \n",
    "        if 'wading' in x.lower():\n",
    "            return 'Wading'\n",
    "        if 'research' in x.lower():\n",
    "            return 'Research'\n",
    "        if 'rescue' in x.lower():\n",
    "            return 'Rescuing someone / somthing'\n",
    "        if 'rescuing' in x.lower():\n",
    "            return 'Rescuing someone / somthing'\n",
    "        if 'overboard' in x.lower():\n",
    "            return 'Fell from boat into water'        \n",
    "        if 'fell' in x.lower():\n",
    "            return 'Fell to the water'\n",
    "        \n",
    "        if 'boat' in x.lower():\n",
    "            return 'Boating'\n",
    "        if 'yatch' in x.lower():\n",
    "            return 'Boating'\n",
    "        if 'disaster' in x.lower():\n",
    "            return 'Sea Disaster'\n",
    "        if 'wreck' in x.lower():\n",
    "            return 'Shipwreck'\n",
    "        if 'capsize' in x.lower():\n",
    "            return 'Shipwreck'\n",
    "        if 'sank' in x.lower():\n",
    "            return 'Shipwreck'\n",
    "        if 'torpedo' in x.lower():\n",
    "            return 'War (Torpedo)'\n",
    "        if 'warship' in x.lower():\n",
    "            return 'War (Warship)'\n",
    "        if ('plane' and 'crash') in x.lower():\n",
    "            return 'Airplane crash'\n",
    "        if 'airliner' in x.lower():\n",
    "            return 'Airplane crash'\n",
    "        \n",
    "        \n",
    "        if 'filming' in x.lower():\n",
    "            return 'Filming / Photoshoot'\n",
    "        if 'sailing' in x.lower():\n",
    "            return 'Sailing'\n",
    "        if 'net ' in x.lower():\n",
    "            return 'Fishing'\n",
    "        if ' net' in x.lower():\n",
    "            \n",
    "            return 'Fishing'\n",
    "        if 'photo' in x.lower():\n",
    "            return 'Filming / Photoshoot'\n",
    "        if 'sinking' in x.lower():\n",
    "            return 'Sea Disaster'\n",
    "        \n",
    "        if 'board' in x.lower():\n",
    "            return 'Other types of Boarding sports'\n",
    "        else:\n",
    "            return x\n",
    "    elif x == 'nan':\n",
    "        return 'NOT SPECIFIED'\n",
    "   #     print(type(x), x) #for debugging  üî•Ô∏è\n",
    "    else:\n",
    "        return 'CORRUPTED DATA POINT'\n",
    "\n",
    "# Fill the empty values first\n",
    "df.Activity = df.Activity.fillna('NOT SPECIFIED')\n",
    "\n",
    "# Create the categorized column and count the values\n",
    "df['Activity2'] = df.Activity.map(filt)\n",
    "df.Activity2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Activity2 = df.Activity2.fillna('NOT SPECIFIED')\n",
    "df.Activity2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü¶àÔ∏è Fatalities\n",
    "Sort them out and map them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "539"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Fatal.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Fatal = df.Fatal.fillna('UNKNOWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N          4301\n",
       "Y          1389\n",
       "UNKNOWN     612\n",
       "Name: Fatal, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filt(x):\n",
    "    if 'UNKNOWN' in x.upper():\n",
    "        return x\n",
    "    if 'N' in x.upper():\n",
    "        return 'N'\n",
    "    if 'Y' in x.upper():\n",
    "        return 'Y'\n",
    "    else:\n",
    "        return 'UNKNOWN'\n",
    "\n",
    "df['Fatal'] = df.Fatal.map(filt)\n",
    "df.Fatal.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü¶àÔ∏è Injuries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FATAL                                                                                                               802\n",
       "Survived                                                                                                             97\n",
       "Foot bitten                                                                                                          87\n",
       "No injury                                                                                                            82\n",
       "Leg bitten                                                                                                           72\n",
       "Left foot bitten                                                                                                     50\n",
       "No details                                                                                                           43\n",
       "Right foot bitten                                                                                                    39\n",
       "No injury, board bitten                                                                                              31\n",
       "Hand bitten                                                                                                          29\n",
       "Thigh bitten                                                                                                         27\n",
       "FATAL, body not recovered                                                                                            24\n",
       "Calf bitten                                                                                                          22\n",
       "Minor injury                                                                                                         22\n",
       "Foot lacerated                                                                                                       21\n",
       "Arm bitten                                                                                                           20\n",
       "Lacerations to foot                                                                                                  20\n",
       "Right leg bitten                                                                                                     20\n",
       "Lacerations to left foot                                                                                             18\n",
       "Lacerations to right foot                                                                                            18\n",
       "Ankle bitten                                                                                                         17\n",
       "Right calf bitten                                                                                                    16\n",
       "Minor injuries                                                                                                       14\n",
       "No injury to occupants                                                                                               14\n",
       "Heel bitten                                                                                                          14\n",
       "Left arm bitten                                                                                                      13\n",
       "Left leg bitten                                                                                                      13\n",
       "Foot severed                                                                                                         13\n",
       "Leg injured                                                                                                          13\n",
       "No injury, surfboard bitten                                                                                          13\n",
       "                                                                                                                   ... \n",
       "Presumed FATAL Disappeared, his shark-bitten swim trunks were found on the seafloor                                   1\n",
       "4 scratches on left hand                                                                                              1\n",
       "Minor injury to foot & shin                                                                                           1\n",
       "FATAL, injuries to lower back                                                                                         1\n",
       "Cuts on left foot                                                                                                     1\n",
       "Left elbow and forearm bitten                                                                                         1\n",
       "No injury. Copper breastplate & harness bitten                                                                        1\n",
       "Single puncture wound on the foot                                                                                     1\n",
       "Right thigh injured by hooked pregnant female shark PROVOKED INCIDENT                                                 1\n",
       "Minor injury                                                                                                          1\n",
       "One was bitten on the leg, the other on the arm                                                                       1\n",
       "No injury to occupants; oar bitten                                                                                    1\n",
       "Left ankle & foot lacerated                                                                                           1\n",
       "Puncture wounds on left foot                                                                                          1\n",
       "Severe lacerations to thigh                                                                                           1\n",
       "Next day 2 bodies recovered from sharks                                                                               1\n",
       "5.5-inch laceration on calf                                                                                           1\n",
       "Left hand severely lacerated                                                                                          1\n",
       "A \"dead\" shark grabbed by the tail bit his right torso PROVOKED INCIDENT                                              1\n",
       "FATAL Foot & leg bitten                                                                                               1\n",
       "Wrist lacerated PROVOKED INCIDENT                                                                                     1\n",
       "Feet bitten, surgically amputated FATAL                                                                               1\n",
       "FATAL, bitten five times. Other survivors fought off sharks for 10 hours. One survivor's arm severed by a shark.      1\n",
       "Minor laceration to leg                                                                                               1\n",
       "Recuers fought sharks for the bodies                                                                                  1\n",
       "Lacerations to left thigh and calf                                                                                    1\n",
       "Shark bit his arm, nearly severing it PROVOKED INCIDENT                                                               1\n",
       "FATAL, left leg & calf bitten, leg surgically amputated                                                               1\n",
       "Leg pinched                                                                                                           1\n",
       "Of 1256 on board, 295 perished, some were taken by sharks                                                             1\n",
       "Name: Injury, Length: 3737, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Injury.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CaseNum      False\n",
      "Date         False\n",
      "Year         False\n",
      "Type         False\n",
      "Country      False\n",
      "Area         False\n",
      "Location     False\n",
      "Activity     False\n",
      "Sex          False\n",
      "Age           True\n",
      "Injury       False\n",
      "Fatal        False\n",
      "Time          True\n",
      "Species      False\n",
      "Source       False\n",
      "href         False\n",
      "Species2     False\n",
      "Activity2    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(df.count() < 5000) # To know how much data are we missing on each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶àÔ∏è Age and Time\n",
    "The `Age` and `Time` column have many null values and is not going to be uses to test our hypothesis, so we will drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CaseNum       object\n",
       "Date          object\n",
       "Year         float64\n",
       "Type          object\n",
       "Country       object\n",
       "Area          object\n",
       "Location      object\n",
       "Activity      object\n",
       "Sex           object\n",
       "Injury        object\n",
       "Fatal         object\n",
       "Species       object\n",
       "Source        object\n",
       "href          object\n",
       "Species2      object\n",
       "Activity2     object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.drop(columns=['Age', 'Time'])\n",
    "df.columns\n",
    "display(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 'duped values')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop dupes and compare lengths\n",
    "df_pdf_nodupes = df.drop_duplicates()\n",
    "\n",
    "len(df) - len(df_pdf_nodupes), 'duped values'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "<br><br><br>\n",
    "\n",
    "<h1><center> üèÑÔ∏è Exporting the cleaned Dataset </center></h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phew... \n",
    "#\n",
    "# That was a long haul right there.\n",
    "# It might not be perfect, but we have\n",
    "# some cleaner data with which we can \n",
    "# make a more educated guess abour \n",
    "# this topic.\n",
    "#\n",
    "# Now, we can take this dataframe and\n",
    "# export it. This will be one of the\n",
    "# products of this project and \n",
    "# hopefully benefit the future of\n",
    "# sharing the planet with sharks.\n",
    "#\n",
    "#\n",
    "#\n",
    "# Oh, I almos forgot... \n",
    "#\n",
    "# Exporting as '.csv':\n",
    "#\n",
    "# It cannot get any simpler than this:\n",
    "df.to_csv('OUTPUT/exported.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_measurments(x):\n",
    "    \n",
    "    #THERE ARE SO MANY ERRORS IN THIS COLUMN, let's filter them\n",
    "    # NOT CONFIRMED\n",
    "    \n",
    "    # -- trying to filter sizes --\n",
    "    \n",
    "    if \"\"\"10'\"\"\" in x.lower():\n",
    "        return \"\"\"10' shark\"\"\"\n",
    "    if \"\"\"11'\"\"\" in x.lower():\n",
    "        return \"\"\"11' shark\"\"\"\n",
    "    if \"\"\"12'\"\"\" in x.lower():\n",
    "        return \"\"\"12' shark\"\"\"\n",
    "    if \"\"\"13'\"\"\" in x.lower():\n",
    "        return \"\"\"13' shark\"\"\"\n",
    "    if \"\"\"14'\"\"\" in x.lower():\n",
    "        return \"\"\"14' shark\"\"\"\n",
    "    if \"\"\"15'\"\"\" in x.lower():\n",
    "        return \"\"\"15' shark\"\"\"\n",
    "    if \"\"\"16'\"\"\" in x.lower():\n",
    "        return \"\"\"16' shark\"\"\"\n",
    "    if \"\"\"17'\"\"\" in x.lower():\n",
    "        return \"\"\"17' shark\"\"\"\n",
    "    if \"\"\"18'\"\"\" in x.lower():\n",
    "        return \"\"\"18' shark\"\"\"\n",
    "    if \"\"\"19'\"\"\" in x.lower():\n",
    "        return \"\"\"19' shark\"\"\"\n",
    "    if \"\"\"20'\"\"\" in x.lower():\n",
    "        return \"\"\"20' shark\"\"\"\n",
    "    if \"\"\"21'\"\"\" in x.lower():\n",
    "        return \"\"\"21' shark\"\"\"\n",
    "    \n",
    "    if \"\"\"1'\"\"\" in x.lower():\n",
    "        return \"\"\"1' shark\"\"\"\n",
    "    if \"\"\"2'\"\"\" in x.lower():\n",
    "        return \"\"\"2' shark\"\"\"\n",
    "    if \"\"\"3'\"\"\" in x.lower():\n",
    "        return \"\"\"3' shark\"\"\"\n",
    "    if \"\"\"4'\"\"\" in x.lower():\n",
    "        return \"\"\"4' shark\"\"\"\n",
    "    if \"\"\"5'\"\"\" in x.lower():\n",
    "        return \"\"\"5' shark\"\"\"\n",
    "    if \"\"\"6'\"\"\" in x.lower():\n",
    "        return \"\"\"6' shark\"\"\"\n",
    "    if \"\"\"7'\"\"\" in x.lower():\n",
    "        return \"\"\"7' shark\"\"\"    \n",
    "    if \"\"\"8'\"\"\" in x.lower():\n",
    "        return \"\"\"8' shark\"\"\"\n",
    "    if \"\"\"9'\"\"\" in x.lower():\n",
    "        return \"\"\"9' shark\"\"\"\n",
    "\n",
    "    if 'small shark' in x.lower():\n",
    "        return 'Small shark'\n",
    "    \n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "# df['Species2'] = df['Species'].map(shark_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'No injury to occupants, shark released from net holed boat', 1),\n",
       " (u'Minor laceration to shoulder from captive shark PROVOKED INCIDENT', 1),\n",
       " (u'FATAL, coroner\\'s Verdict: \"Death presumably through shark attack & drowning\"',\n",
       "  1),\n",
       " (u'Probable drowning and scavenging', 1),\n",
       " (u' The shark & man simply collided; neither were injured', 1),\n",
       " (u'Extensive injuries to left leg', 1),\n",
       " (u'Shark leapt into boat, hitting Fanie Schoeman on his back before sliding into the sea',\n",
       "  1),\n",
       " (u'Puncture wounds & laceration above knee', 1),\n",
       " (u'Shark rammed & overturned paddleboard, knocking him into water & bit his head, lacerating his face & neck',\n",
       "  1),\n",
       " (u\"Left arm injured by shark's tail as it swam beneath his board\", 1),\n",
       " (u'Legs bitten PROVOKED INCIDENT', 1),\n",
       " (u'20 punctures in right foot', 1),\n",
       " (u'No injury, paddleboard bitten', 2),\n",
       " (u'No injury, fell off ski after possibly colliding with  a shark', 1),\n",
       " (u'Legs bitten  FATAL', 1),\n",
       " (u'Left calf injured', 2),\n",
       " (u'Lacerations to left elbow', 1),\n",
       " (u'Ankle & foot lacerated', 3),\n",
       " (u'Foot lacerated by netted shark PROVOKED INCIDENT', 1),\n",
       " (u'Survived, no details', 1)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since there is no column that states if the attack was provoked or not,\n",
    "# I want to analyze the injury column to distinguish between the cases that were provoked\n",
    "# and those that were unprovoked.\n",
    "\n",
    "random.sample(list(df.Injury.value_counts().items()),20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Provoked'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-16db0a42d648>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Provoked\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/rh/.local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rh/.local/lib/python2.7/site-packages/pandas/core/indexes/base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Provoked'"
     ]
    }
   ],
   "source": [
    "# Categorizing  Provoked and  Unprovoked attacks\n",
    "# df_provoked = np.where(df_nodupes.Injury.isin(provoked), True, False) \n",
    "\n",
    "# Passing that categorization to a new PROVOKED COLUMN\n",
    "def provoked_attacks(x):\n",
    "        \n",
    "    provoked = [\"provoked\", \"hook\", \"shot\", 'net']\n",
    "    \n",
    "    print(x, type(x))    \n",
    "    \n",
    "    if x is not unicode:\n",
    "        return x    \n",
    "    \n",
    "    for e in provoked:\n",
    "        if e in x.lower():\n",
    "            return \"PROVOKED\"\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "df[\"Provoked\"].value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_clean.loc[df_clean[\"trany\"].str.startswith(\"M\"),\"trany\"] = \"Manual\"\n",
    "\n",
    "provoked = ['PROVOKED', 'hook', 'shot']\n",
    "#map(lambda words, x : words in x, provoked, df_nodupes.loc[df_nodupes['Injury'].str])\n",
    "df.loc[df['Injury'].str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèäÔ∏è IDEAS FOR FUTURE PROJECTS:\n",
    "- The pdfs presented on the `href` seem quite structured\n",
    " \n",
    " - It could be possible to parse them later down the road and use a **REGEX** to find more data\n",
    " \n",
    " - Like, adding a column that lists the **'Moon Phase'** described on some of the pdfs\n",
    "\n",
    "- I also have ran query a few times to notice that all pdfs have actually been uploaded to the same website and have the same naming structure"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
