{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Shark attacks, a project by Roberto Henr√≠quez Perozo. Data Analytics Bootcamp at IronHack](INPUT/shark-attacks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<center>\n",
    "    <h1> PART I: Data cleaning and exploration</h1>\n",
    "</center>\n",
    "\n",
    "## üé£Ô∏è Step 0 - Basic knowledge\n",
    "To begin the development of this project, it would be good to hold a minimum understanding of `Shark Attacks`.\n",
    "\n",
    "As I did not know much about this topic at the day the project started, I recurred to the shark-attack wiki: https://en.wikipedia.org/wiki/Shark_attack\n",
    "\n",
    "With this information in mind, below is the process of data exploration, cleaning, and wrangling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing the modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "#pd.compat.PY3 = True #üî•Ô∏è  no longer needed ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé£Ô∏è Step 1 - Defining the dataset path, and importing it to begin basic dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To follow along, download the DataSet from KAGGLE using this link\n",
    "# https://www.kaggle.com/teajay/global-shark-attacks\n",
    "\n",
    "# Once you have downloaded the DataSet, change the following `dataset` variable to match the \n",
    "# path where you have saved the 'attacks.csv' file.\n",
    "dataset = 'INPUT/attacks.csv' \n",
    "\n",
    "\n",
    "df = pd.read_csv(dataset, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will check some basic information about the dataset, in order to formulate a more educated hypothesis which we could actually put to test with the data available.\n",
    "\n",
    "Here, I notice that the shape of the `df` with no duplicates is very small when compared to the whole `df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üåäÔ∏è  Declutter Function\n",
    "This comparison could be turned into its own function, as it will be executed quite often"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Data Frame shape before declutter:', (25723, 24))\n",
      "('Data Frame shape after declutter: ', (6312, 24))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index([           u'Case Number',                   u'Date',\n",
       "                         u'Year',                   u'Type',\n",
       "                      u'Country',                   u'Area',\n",
       "                     u'Location',               u'Activity',\n",
       "                         u'Name',                   u'Sex ',\n",
       "                          u'Age',                 u'Injury',\n",
       "                  u'Fatal (Y/N)',                   u'Time',\n",
       "                     u'Species ', u'Investigator or Source',\n",
       "                          u'pdf',           u'href formula',\n",
       "                         u'href',          u'Case Number.1',\n",
       "                u'Case Number.2',         u'original order',\n",
       "                  u'Unnamed: 22',            u'Unnamed: 23'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'll delete de duplicated rows\n",
    "def declutter(df):\n",
    "    print('Data Frame shape before declutter:', df.shape)\n",
    "    df = df.drop_duplicates()\n",
    "    print('Data Frame shape after declutter: ', df.shape)\n",
    "    return df\n",
    "\n",
    "#calling the function to drop dupes\n",
    "df = declutter(df)\n",
    "\n",
    "# And also take a look at the columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25-Jun-2018\n",
       "1    18-Jun-2018\n",
       "2    09-Jun-2018\n",
       "3    08-Jun-2018\n",
       "4    04-Jun-2018\n",
       "Name: Date, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I want to take a look at the time structures\n",
    "df.Date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>6303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>6302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>6299.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case Number.1 Case Number.2  original order Unnamed: 22 Unnamed: 23\n",
       "0    2018.06.25    2018.06.25          6303.0         NaN         NaN\n",
       "1    2018.06.18    2018.06.18          6302.0         NaN         NaN\n",
       "2    2018.06.09    2018.06.09          6301.0         NaN         NaN\n",
       "3    2018.06.08    2018.06.08          6300.0         NaN         NaN\n",
       "4    2018.06.04    2018.06.04          6299.0         NaN         NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I want to see what is the data on the last couple\n",
    "# of columns which have unexplicit labels\n",
    "df[['Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22', 'Unnamed: 23']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6312, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Case Number.1       10\n",
       "Case Number.2       10\n",
       "original order       3\n",
       "Unnamed: 22       6311\n",
       "Unnamed: 23       6310\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Too many null values on the last two columns... let's count them\n",
    "print(df.shape)\n",
    "df[['Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22', 'Unnamed: 23']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé£Ô∏è Step 2 - Dropping null values and unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there is only 1 value in the 'Unnamed: 22' column, and 2 values in the\n",
    "# 'Unnamed: 22' column, I'll not consider this data for my analysis.\n",
    "df = df.drop(columns=['Unnamed: 22', 'Unnamed: 23'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The column with the name of the victims does not bring much relevant information to our study\n",
    "df = df.drop(columns='Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Age` and `Time` column have many null values and is not going to be uses to test our hypothesis, so we will drop them both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Age', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ND.0016         1\n",
       "1902.08.08      1\n",
       "2006.02.12.a    1\n",
       "2010.10.02.b    1\n",
       "1924.01.25      1\n",
       "1928.01.00      1\n",
       "1968.04.15      1\n",
       "1845.11.04      1\n",
       "2010.05.18.a    1\n",
       "2010.05.18.b    1\n",
       "Name: Case Number.1, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following columns seemed a little bit rare, so i do a value count to find out what they are about\n",
    "df['Case Number.1'].value_counts().sort_values().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ND.0015         1\n",
       "1902.08.08      1\n",
       "2006.02.12.a    1\n",
       "2010.10.02.b    1\n",
       "1924.01.25      1\n",
       "1928.01.00      1\n",
       "1968.04.15      1\n",
       "1845.11.04      1\n",
       "2010.05.18.a    1\n",
       "2010.05.18.b    1\n",
       "Name: Case Number.2, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Case Number.2'].value_counts().sort_values().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üåäÔ∏è Creating a 'sampler' function\n",
    "\n",
    "After some thought and googling, it seems like these are some sort of notation used to categorize and order the shark attacks. They also use the a notation that includes dates. \n",
    "\n",
    "**Is it the same as the Date on the Date column?**\n",
    "\n",
    "To find out, I wanted to pick random samples of the dataframe, but python's built-in `random` module kept giving me trouble when I tried to use it alongside pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object sampler at 0x7f6800f03a50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VER 03\n",
    "def sampler(df, column, sample_size):\n",
    "# This function generates an iterator out of random rows from a pandas dataframe's specific column\n",
    "    \n",
    "    # Defining how many samples to fetch from the df\n",
    "    for i in range(sample_size):\n",
    "        \n",
    "        # Now a random index is generated out of the total length of the column...\n",
    "        i = random.choice(range(len(df[column])))\n",
    "        # ... to return the data values in that index as an iterator:\n",
    "        yield df.iloc[i][column]\n",
    "        \n",
    "        # For future versions, it would be good to look at how I can return the\n",
    "        # data as a tupple with just the data, and not have it return a formatted string\n",
    "        # or even better, a pandas dataframe with the results\n",
    "\n",
    "\n",
    "# Now let's try it out\n",
    "sampler(df, ['Date', 'Case Number.1', 'Case Number.2'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Date             11-Apr-2009\n",
       " Case Number.1     2009.04.11\n",
       " Case Number.2     2009.04.11\n",
       " Name: 1136, dtype: object, Date             11-Dec-2015\n",
       " Case Number.1     2015.12.11\n",
       " Case Number.2     2015.12.11\n",
       " Name: 327, dtype: object, Date                   1909\n",
       " Case Number.1    1909.00.00\n",
       " Case Number.2    1909.00.00\n",
       " Name: 5427, dtype: object, Date              31-Mar-2007\n",
       " Case Number.1    2007.03.31.b\n",
       " Case Number.2    2007.03.31.b\n",
       " Name: 1392, dtype: object, Date              11-Apr-2001\n",
       " Case Number.1    2001.04.11.d\n",
       " Case Number.2    2001.04.11.d\n",
       " Name: 1960, dtype: object]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since sampler generates iterators, list() must be used to see its contents\n",
    "list(sampler(df, ['Date', 'Case Number.1', 'Case Number.2'], 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü¶àÔ∏è \n",
    "From this output, we can see that the `Case Number` Columnns are actually replicating the info that we already have on the `Date` column. Therefore, we will drop both `Case Number` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Case Number.1', 'Case Number.2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### ü¶àÔ∏è  Taking a closer look at the tail of the df, we notice that the last couple of rows are still holding many null values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>original order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6300</th>\n",
       "      <td>ND.0002</td>\n",
       "      <td>1883-1889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>PANAMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Panama Bay 8¬∫N, 79¬∫W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Sun, 10/20/1938</td>\n",
       "      <td>ND-0002-JulesPatterson.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6301</th>\n",
       "      <td>ND.0001</td>\n",
       "      <td>1845-1853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>CEYLON (SRI LANKA)</td>\n",
       "      <td>Eastern Province</td>\n",
       "      <td>Below the English fort, Trincomalee</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>M</td>\n",
       "      <td>FATAL. \"Shark bit him in half, carrying away t...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S.W. Baker</td>\n",
       "      <td>ND-0001-Ceylon.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6302</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6303</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6305.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6304</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6305</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6306</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6308.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8702</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25722</th>\n",
       "      <td>xx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Case Number       Date  Year        Type             Country  \\\n",
       "6300      ND.0002  1883-1889   0.0  Unprovoked              PANAMA   \n",
       "6301      ND.0001  1845-1853   0.0  Unprovoked  CEYLON (SRI LANKA)   \n",
       "6302            0        NaN   NaN         NaN                 NaN   \n",
       "6303            0        NaN   NaN         NaN                 NaN   \n",
       "6304            0        NaN   NaN         NaN                 NaN   \n",
       "6305            0        NaN   NaN         NaN                 NaN   \n",
       "6306            0        NaN   NaN         NaN                 NaN   \n",
       "6307            0        NaN   NaN         NaN                 NaN   \n",
       "6308            0        NaN   NaN         NaN                 NaN   \n",
       "6309            0        NaN   NaN         NaN                 NaN   \n",
       "8702          NaN        NaN   NaN         NaN                 NaN   \n",
       "25722          xx        NaN   NaN         NaN                 NaN   \n",
       "\n",
       "                   Area                             Location  Activity Sex   \\\n",
       "6300                NaN                 Panama Bay 8¬∫N, 79¬∫W       NaN    M   \n",
       "6301   Eastern Province  Below the English fort, Trincomalee  Swimming    M   \n",
       "6302                NaN                                  NaN       NaN  NaN   \n",
       "6303                NaN                                  NaN       NaN  NaN   \n",
       "6304                NaN                                  NaN       NaN  NaN   \n",
       "6305                NaN                                  NaN       NaN  NaN   \n",
       "6306                NaN                                  NaN       NaN  NaN   \n",
       "6307                NaN                                  NaN       NaN  NaN   \n",
       "6308                NaN                                  NaN       NaN  NaN   \n",
       "6309                NaN                                  NaN       NaN  NaN   \n",
       "8702                NaN                                  NaN       NaN  NaN   \n",
       "25722               NaN                                  NaN       NaN  NaN   \n",
       "\n",
       "                                                  Injury Fatal (Y/N) Species   \\\n",
       "6300                                               FATAL           Y      NaN   \n",
       "6301   FATAL. \"Shark bit him in half, carrying away t...           Y      NaN   \n",
       "6302                                                 NaN         NaN      NaN   \n",
       "6303                                                 NaN         NaN      NaN   \n",
       "6304                                                 NaN         NaN      NaN   \n",
       "6305                                                 NaN         NaN      NaN   \n",
       "6306                                                 NaN         NaN      NaN   \n",
       "6307                                                 NaN         NaN      NaN   \n",
       "6308                                                 NaN         NaN      NaN   \n",
       "6309                                                 NaN         NaN      NaN   \n",
       "8702                                                 NaN         NaN      NaN   \n",
       "25722                                                NaN         NaN      NaN   \n",
       "\n",
       "      Investigator or Source                         pdf  \\\n",
       "6300     The Sun, 10/20/1938  ND-0002-JulesPatterson.pdf   \n",
       "6301              S.W. Baker          ND-0001-Ceylon.pdf   \n",
       "6302                     NaN                         NaN   \n",
       "6303                     NaN                         NaN   \n",
       "6304                     NaN                         NaN   \n",
       "6305                     NaN                         NaN   \n",
       "6306                     NaN                         NaN   \n",
       "6307                     NaN                         NaN   \n",
       "6308                     NaN                         NaN   \n",
       "6309                     NaN                         NaN   \n",
       "8702                     NaN                         NaN   \n",
       "25722                    NaN                         NaN   \n",
       "\n",
       "                                            href formula  \\\n",
       "6300   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6301   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6302                                                 NaN   \n",
       "6303                                                 NaN   \n",
       "6304                                                 NaN   \n",
       "6305                                                 NaN   \n",
       "6306                                                 NaN   \n",
       "6307                                                 NaN   \n",
       "6308                                                 NaN   \n",
       "6309                                                 NaN   \n",
       "8702                                                 NaN   \n",
       "25722                                                NaN   \n",
       "\n",
       "                                                    href  original order  \n",
       "6300   http://sharkattackfile.net/spreadsheets/pdf_di...             3.0  \n",
       "6301   http://sharkattackfile.net/spreadsheets/pdf_di...             2.0  \n",
       "6302                                                 NaN          6304.0  \n",
       "6303                                                 NaN          6305.0  \n",
       "6304                                                 NaN          6306.0  \n",
       "6305                                                 NaN          6307.0  \n",
       "6306                                                 NaN          6308.0  \n",
       "6307                                                 NaN          6309.0  \n",
       "6308                                                 NaN          6310.0  \n",
       "6309                                                 NaN             NaN  \n",
       "8702                                                 NaN             NaN  \n",
       "25722                                                NaN             NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it's only the last 10 columns which have the nulls.\n",
    "df.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Since they are only 10 instances, we can drop them manually using their index:\n",
    "df = df.drop([6302, 6303,6304,6305,6306,6307,6308,6309,8702,25722])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>original order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6297</th>\n",
       "      <td>ND.0005</td>\n",
       "      <td>Before 1903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>Roebuck Bay</td>\n",
       "      <td>Diving</td>\n",
       "      <td>M</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H. Taunton; N. Bartlett,  p. 234</td>\n",
       "      <td>ND-0005-RoebuckBay.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6298</th>\n",
       "      <td>ND.0004</td>\n",
       "      <td>Before 1903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pearl diving</td>\n",
       "      <td>M</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H. Taunton; N. Bartlett,  pp. 233-234</td>\n",
       "      <td>ND-0004-Ahmun.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6299</th>\n",
       "      <td>ND.0003</td>\n",
       "      <td>1900-1905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Ocracoke Inlet</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>M</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F. Schwartz, p.23; C. Creswell, GSAF</td>\n",
       "      <td>ND-0003-Ocracoke_1900-1905.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6300</th>\n",
       "      <td>ND.0002</td>\n",
       "      <td>1883-1889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>PANAMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Panama Bay 8¬∫N, 79¬∫W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Sun, 10/20/1938</td>\n",
       "      <td>ND-0002-JulesPatterson.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6301</th>\n",
       "      <td>ND.0001</td>\n",
       "      <td>1845-1853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>CEYLON (SRI LANKA)</td>\n",
       "      <td>Eastern Province</td>\n",
       "      <td>Below the English fort, Trincomalee</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>M</td>\n",
       "      <td>FATAL. \"Shark bit him in half, carrying away t...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S.W. Baker</td>\n",
       "      <td>ND-0001-Ceylon.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Case Number         Date  Year        Type             Country  \\\n",
       "6297     ND.0005  Before 1903   0.0  Unprovoked           AUSTRALIA   \n",
       "6298     ND.0004  Before 1903   0.0  Unprovoked           AUSTRALIA   \n",
       "6299     ND.0003    1900-1905   0.0  Unprovoked                 USA   \n",
       "6300     ND.0002    1883-1889   0.0  Unprovoked              PANAMA   \n",
       "6301     ND.0001    1845-1853   0.0  Unprovoked  CEYLON (SRI LANKA)   \n",
       "\n",
       "                   Area                             Location      Activity  \\\n",
       "6297  Western Australia                          Roebuck Bay        Diving   \n",
       "6298  Western Australia                                  NaN  Pearl diving   \n",
       "6299     North Carolina                       Ocracoke Inlet      Swimming   \n",
       "6300                NaN                 Panama Bay 8¬∫N, 79¬∫W           NaN   \n",
       "6301   Eastern Province  Below the English fort, Trincomalee      Swimming   \n",
       "\n",
       "     Sex                                              Injury Fatal (Y/N)  \\\n",
       "6297    M                                              FATAL           Y   \n",
       "6298    M                                              FATAL           Y   \n",
       "6299    M                                              FATAL           Y   \n",
       "6300    M                                              FATAL           Y   \n",
       "6301    M  FATAL. \"Shark bit him in half, carrying away t...           Y   \n",
       "\n",
       "     Species                  Investigator or Source  \\\n",
       "6297      NaN       H. Taunton; N. Bartlett,  p. 234   \n",
       "6298      NaN  H. Taunton; N. Bartlett,  pp. 233-234   \n",
       "6299      NaN   F. Schwartz, p.23; C. Creswell, GSAF   \n",
       "6300      NaN                    The Sun, 10/20/1938   \n",
       "6301      NaN                             S.W. Baker   \n",
       "\n",
       "                                 pdf  \\\n",
       "6297          ND-0005-RoebuckBay.pdf   \n",
       "6298               ND-0004-Ahmun.pdf   \n",
       "6299  ND-0003-Ocracoke_1900-1905.pdf   \n",
       "6300      ND-0002-JulesPatterson.pdf   \n",
       "6301              ND-0001-Ceylon.pdf   \n",
       "\n",
       "                                           href formula  \\\n",
       "6297  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6298  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6299  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6300  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "6301  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                   href  original order  \n",
       "6297  http://sharkattackfile.net/spreadsheets/pdf_di...             6.0  \n",
       "6298  http://sharkattackfile.net/spreadsheets/pdf_di...             5.0  \n",
       "6299  http://sharkattackfile.net/spreadsheets/pdf_di...             4.0  \n",
       "6300  http://sharkattackfile.net/spreadsheets/pdf_di...             3.0  \n",
       "6301  http://sharkattackfile.net/spreadsheets/pdf_di...             2.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü¶àÔ∏è We still have additional columns that are not giving us any *'MEATY' info* !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are just old indexes\n",
    "# df['original order'].value_counts()\n",
    "\n",
    "# And these are only the titles of the pdfs\n",
    "# df['pdf'].value_counts()\n",
    "\n",
    "# let's get rid of them\n",
    "df = df.drop(columns = ['pdf', 'original order'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé£Ô∏è Step 3 - Digging deeper into the data, and dropping more unnecesary data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `href` and `href formula` columns look very similar, but since they can't be read on the DataFrame that pandas provides, we'll try to use our `sampler()` function again to compare them both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[href            http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " href formula    http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " Name: 527, dtype: object,\n",
       " href            http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " href formula    http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " Name: 2167, dtype: object,\n",
       " href            http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " href formula    http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " Name: 5739, dtype: object,\n",
       " href            http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " href formula    http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " Name: 5201, dtype: object,\n",
       " href            http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " href formula    http://sharkattackfile.net/spreadsheets/pdf_di...\n",
       " Name: 6266, dtype: object]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sampler(df, ['href', 'href formula'],5))\n",
    "# This however, returns invalid links which are not accurately represented.\n",
    "# example: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü¶àÔ∏è Well, Oops? That didn't work as planned...\n",
    "\n",
    "The links are not clickable, and to actually see the contents, I've resorted to two separate methods, `random.sample` and a `for` loop.\n",
    "\n",
    "These cells can be re-run a couple of times to make sure the data in the columns is homogeneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'http://sharkattackfile.net/spreadsheets/pdf_directory/2016.07.28.R-Franz.pdf',\n",
       " u'http://sharkattackfile.net/spreadsheets/pdf_directory/1961.10.09-Haen.pdf',\n",
       " u'http://sharkattackfile.net/spreadsheets/pdf_directory/2016.07.15.a-MyrtleBeach.pdf',\n",
       " u'http://sharkattackfile.net/spreadsheets/pdf_directory/1933.02.15.R-Tumia.pdf',\n",
       " u'http://sharkattackfile.net/spreadsheets/pdf_directory/1944.09.03-PhilipStanton.pdf']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[u'http://sharkattackfile.net/spreadsheets/pdf_directory/1920.03.08-Burgess.pdf',\n",
       " u'http://sharkattackfile.net/spreadsheets/pdf_directory/2016.05.21.a-Girl.pdf',\n",
       " u'http://sharkattackfile.net/spreadsheets/pdf_directory/1996.02.26-Good.pdf',\n",
       " u'http://sharkattackfile.net/spreadsheets/pdf_directory/1977.03.13.c-Harrison.pdf',\n",
       " u'http://sharkattackfile.net/spreadsheets/pdf_directory/1991.07.30-Ivana-Iacaccia.pdf']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# With Random sample\n",
    "display(random.sample(list(df['href']), 5))\n",
    "display(random.sample(list(df['href formula']), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(5):\\n   e = random.choice(range(1000))\\n   print(f\"index: {e} href:         {df.iloc[e][\\'href\\']})\\n   print(f\"index: {e} href formula: {df.iloc[e][\\'href formula\\']}\")\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # üî•Ô∏è FIX SYNTAX ERROR with .format method\n",
    " #With a FOR loop \n",
    "\"\"\"\n",
    "for i in range(5):\n",
    "    e = random.choice(range(1000))\n",
    "    print(f\"index: {e} href:         {df.iloc[e]['href']})\n",
    "    print(f\"index: {e} href formula: {df.iloc[e]['href formula']}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü¶àÔ∏è The links on both columns seem to match, most of the times anyways.\n",
    "\n",
    "In some cases, the `href` seems to have an duplication on its links which corrupted them and made them innaccessible.\n",
    "\n",
    "However, the `href formula` actually saved the correct URL format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://sharkattackfile.net/spreadsheets/pdf_directory/http://sharkattackfile.net/spreadsheets/pdf_directory/2015.11.15.a-Engelman.pdf\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/2015.11.15.a-Engelman.pdf\n",
      "()\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/http://sharkattackfile.net/spreadsheets/pdf_directory/2015.12.21.a-Brazil.pdf\n",
      "http://sharkattackfile.net/spreadsheets/pdf_directory/2015.12.21.a-Brazil.pdf\n"
     ]
    }
   ],
   "source": [
    "# üî•Ô∏è FIX SYNTAX ERRORS\n",
    "\n",
    "# Examples of the corrupted link versus their working counterpart\n",
    "print(df.iloc[332]['href'])\n",
    "print(df.iloc[332]['href formula'])\n",
    "print()\n",
    "print(df.iloc[324]['href'])\n",
    "print(df.iloc[324]['href formula'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü¶àÔ∏è  For the sake of simplicity, we will drop the `href` column, and replace it with the `href formula`. Also, some column names can be simplified, and some have unnecesary white spaces. Let's fix that right away:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Case Number', u'Date', u'Year', u'Type', u'Country', u'Area',\n",
       "       u'Location', u'Activity', u'Sex ', u'Injury', u'Fatal (Y/N)',\n",
       "       u'Species ', u'Investigator or Source', u'href formula'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns='href')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'CaseNum', u'Date', u'Year', u'Type', u'Country', u'Area', u'Location',\n",
       "       u'Activity', u'Sex', u'Injury', u'Fatal', u'Species', u'Source',\n",
       "       u'href'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['CaseNum', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
    "       'Activity', 'Sex', 'Injury', 'Fatal', 'Species', 'Source', 'href']\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü¶àÔ∏è Many of the values from the **Species** column are `nulls`. We'll fill them with the same `Invalid` value that other cells already have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "White shark                                           163\n",
       "Shark involvement prior to death was not confirmed    105\n",
       "Invalid                                               102\n",
       "Shark involvement not confirmed                        88\n",
       "Tiger shark                                            73\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BEFORE\n",
    "df.Species.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Invalid                                               2940\n",
       "White shark                                            163\n",
       "Shark involvement prior to death was not confirmed     105\n",
       "Shark involvement not confirmed                         88\n",
       "Tiger shark                                             73\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Species = df.Species.fillna('Invalid')\n",
    "\n",
    "#AFTER\n",
    "df.Species.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        6302\n",
       "unique       1549\n",
       "top       Invalid\n",
       "freq         2940\n",
       "Name: Species, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With the .describe() method, we can see that there are 1549 unique values in this column\n",
    "# It would be interesting to create a new column which narrows this down to fewer unique values.\n",
    "df.Species.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé£Ô∏è Step 4 - Categorizing and beginning hypothesis formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü¶àÔ∏è    [Who's that Pok√©mon?!](https://i.ytimg.com/vi/mg1A94zBWBw/hqdefault.jpg) \n",
    "\n",
    "There are more than 400 species of sharks, and while lurking around the `Species` column you can find all sort of weird animals. Did you know there's even one species of shark known as the *'**Cookie Cutter shark**'* ?\n",
    "\n",
    "![cookie-cutter-shark](INPUT/cookie-cutter-shark.jpeg)\n",
    "\n",
    "I certainly had no clue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü¶àÔ∏è Mapping shark species üëÅÔ∏è\n",
    "Here I tried to sort the data by creating a secondary column which *mapped* the different species, while also classifying possible confusions as `\"OTHER / NOT KNOWN\" `. \n",
    "\n",
    "- *note: the scrutiny for this categorization is quite laxed, as this project is more an exercise with data and less a research paper. The data, however, can be processed even further by forking this github repo.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicating the Species column to decrease the amount of unique values\n",
    "df['Species2'] = df['Species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üåäÔ∏è Shark Identifier functionüëÅÔ∏è\n",
    "This can be turned into key:value pairs for easier reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shark_identifier2(x):\n",
    "    \n",
    "    #THERE ARE SO MANY ERRORS IN THIS COLUMN, let's filter them\n",
    "    \n",
    "    # NOT CONFIRMED\n",
    "    if 'not confirmed' in x.lower():\n",
    "        return \"OTHER / NOT KNOWN\"\n",
    "    if 'unidentified' in x.lower():\n",
    "        return 'OTHER / NOT KNOWN'\n",
    "    if ' or ' in x.lower():\n",
    "      #  print(x) \n",
    "        return 'OTHER / NOT KNOWN'\n",
    "    \n",
    "    # INVALIDS\n",
    "    if 'no shark involvement' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    if 'invalid' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    if 'questionable' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    if 'doubtful' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    \n",
    "    # OTHER INVALIDS\n",
    "    if 'hoax' in x.lower():\n",
    "        return 'INVALID ENTRY'\n",
    "    if 'drown' in x.lower():\n",
    "        return 'DROWNED'\n",
    "    if 'stingray' in x.lower():\n",
    "        return 'STINGRAY'\n",
    "    \n",
    "    \n",
    "    #  --- WHO'S THAT POKEMON?---\n",
    "    \n",
    "    if 'white shark' in x.lower():\n",
    "        return \"White shark\"\n",
    "    if 'tiger shark' in x.lower():\n",
    "        return \"Tiger shark\"\n",
    "    if 'bull shark' in x.lower():\n",
    "        return \"Bull shark\"\n",
    "    if 'nurse shark' in x.lower():\n",
    "        return 'Nurse shark'\n",
    "    if 'brown shark' in x.lower():\n",
    "        return 'Brown shark'\n",
    "    if 'mako shark' in x.lower():\n",
    "        return 'Mako Shark'\n",
    "    if 'blue shark' in x.lower():\n",
    "        return 'Blue shark'\n",
    "    if 'bronze whaler shark' in x.lower():\n",
    "        return 'Bronze whaler shark'\n",
    "    if 'blacktip shark' in x.lower():\n",
    "        return 'Blacktip shark'\n",
    "    if 'whitetip shark' in x.lower():\n",
    "        return 'Whitetip shark'\n",
    "    if 'sandbar shark' in x.lower():\n",
    "        return 'Sandbar shark'\n",
    "    if 'lemon shark' in x.lower():\n",
    "        return 'Lemon shark'\n",
    "    if 'hammerhead shark' in x.lower():\n",
    "        return 'Hammerhead shark'\n",
    "    if 'raggedtooth shark' in x.lower():\n",
    "        return 'Raggedtooth shark'\n",
    "    if 'thresher shark' in x.lower():\n",
    "        return 'Thresher shark'\n",
    "    if 'dusky shark' in x.lower():\n",
    "        return 'Dusky shark'\n",
    "    if 'wobbegong shark' in x.lower():\n",
    "        return 'Wobbegong shark'\n",
    "    if 'dusky shark' in x.lower():\n",
    "        return 'Dusky shark'\n",
    "    if 'spinner shark' in x.lower():\n",
    "        return 'Spinner shark'\n",
    "    if 'blue nose shark' in x.lower():\n",
    "        return 'Blue nose shark'\n",
    "    if 'leopard shark' in x.lower():\n",
    "        return 'Leopard shark'\n",
    "    if 'silvertip shark' in x.lower():\n",
    "        return 'Silvertip shark'\n",
    "    if 'gray shark' in x.lower():\n",
    "        return 'Gray shark'\n",
    "    if 'grey shark' in x.lower():\n",
    "        return 'Gray shark'\n",
    "    if 'reef shark' in x.lower():\n",
    "        return 'Reef shark'\n",
    "    if 'carpet shark' in x.lower():\n",
    "        return 'Carpet shark'\n",
    "    if 'whaler shark' in x.lower():\n",
    "        return 'Whaler shark'\n",
    "    if 'zambesi shark' in x.lower():\n",
    "        return 'Zambesi shark'\n",
    "    \n",
    "    # -- trying to filter sizes --\n",
    "\n",
    "    if 'small shark' in x.lower():\n",
    "        return 'Other small shark'\n",
    "    \n",
    "    else:\n",
    "        return 'OTHER / NOT KNOWN'\n",
    "    \n",
    "df['Species2'] = df['Species'].map(shark_identifier2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INVALID ENTRY          3054\n",
       "OTHER / NOT KNOWN      1467\n",
       "White shark             625\n",
       "Tiger shark             275\n",
       "Bull shark              171\n",
       "Nurse shark              94\n",
       "Reef shark               65\n",
       "Bronze whaler shark      60\n",
       "Blacktip shark           56\n",
       "Other small shark        55\n",
       "Mako Shark               53\n",
       "Wobbegong shark          46\n",
       "Hammerhead shark         44\n",
       "Raggedtooth shark        43\n",
       "Blue shark               38\n",
       "Lemon shark              34\n",
       "Zambesi shark            29\n",
       "Whitetip shark           23\n",
       "Spinner shark            20\n",
       "Dusky shark              12\n",
       "Carpet shark              8\n",
       "Whaler shark              6\n",
       "Sandbar shark             5\n",
       "Thresher shark            4\n",
       "Brown shark               3\n",
       "Gray shark                3\n",
       "Silvertip shark           2\n",
       "Blue nose shark           2\n",
       "DROWNED                   2\n",
       "Leopard shark             2\n",
       "STINGRAY                  1\n",
       "Name: Species2, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Species2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü¶àÔ∏è Types of attack üëÅÔ∏è\n",
    "The GSAF categorizes *scavenging bites* on humans as \"questionable incidents.\"\n",
    "\n",
    "### - PROVOKED\n",
    "Provoked attacks occur when a human touches, hooks, nets, or otherwise aggravates the animal. Incidents that occur outside of a shark's natural habitat, such as aquariums and research holding-pens, are considered provoked, as are all incidents involving captured sharks. Sometimes humans inadvertently provoke an attack, such as when a surfer accidentally hits a shark with a surf board.\n",
    "\n",
    "### - UNPROVOKED\n",
    " - Hit-and-run attack\n",
    " - Sneak Attack\n",
    " - Bump-and-bite attack \n",
    "\n",
    "For more information on how to differentiate PROVOKED vs UNPROVOKED attacks :\n",
    "https://en.wikipedia.org/wiki/Shark_attack#Types_of_attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü¶àÔ∏è TYPE OF ATTACK (Considering Injuries)\n",
    "- I wanted to use the information on the `Injury` column to define if the human hooked, shot, or provoked the shark. However, after mapping the `Injury` column, I noticed that the ammount of Provoked attacks count from this mapping technique varied very slightly from the number of provoked attacks on the `Type` column. **A decission was made to disregard these two additional cases.**\n",
    "- Size of the shark according to Species column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Type.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unprovoked      4595\n",
       "Provoked         574\n",
       "Invalid          551\n",
       "Sea Disaster     239\n",
       "Boating          203\n",
       "Boat             137\n",
       "Questionable       2\n",
       "Boatomg            1\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Type = df.Type.fillna('Invalid')\n",
    "df.Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unprovoked      4595\n",
       "Provoked         574\n",
       "Invalid          553\n",
       "Boat             341\n",
       "Sea Disaster     239\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boat, Boating and Boatomg to 1 category\n",
    "filt = lambda x: 'Boat' if 'Boat' in x else x\n",
    "df.Type = df.Type.map(filt)\n",
    "\n",
    "# Questionable to Invalid\n",
    "filt = lambda x : 'Invalid' if 'Questionable' in x else x\n",
    "df.Type = df.Type.map(filt)\n",
    "\n",
    "df.Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rh/.local/lib/python2.7/site-packages/ipykernel_launcher.py:8: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FATAL          802\n",
       "Survived        97\n",
       "Foot bitten     87\n",
       "No injury       82\n",
       "Leg bitten      72\n",
       "Name: Injury, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  üî•Ô∏è this cell generates an error code related to column creation\n",
    "\n",
    "# making a copy of the original DF\n",
    "DFX = df.copy()\n",
    "\n",
    "# removing those pesky floats that keep giving me trouble\n",
    "float_to_unicode = lambda x : 'ERROR' if type(x) == float else x\n",
    "DFX.TypeX = df.Injury.map(float_to_unicode).copy()\n",
    "\n",
    "# Filter list and function to identify provoked attacks üëÅÔ∏è\n",
    "provoked = ['provoked', 'hook', 'shot']\n",
    "\n",
    "def filt_reloaded(string):\n",
    "    for word in string.split():\n",
    "        if word.lower() in provoked:\n",
    "            return 'PROVOKED'\n",
    "    return string \n",
    "\n",
    "DFX['TypeX'] = DFX.TypeX.map(filt_reloaded).copy()\n",
    "DFX.TypeX.value_counts().head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü¶àÔ∏è Activities\n",
    "Now we will clean the `activities` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Surfing          971\n",
       "Swimming         869\n",
       "Fishing          431\n",
       "Spearfishing     333\n",
       "Bathing          162\n",
       "Wading           149\n",
       "Diving           127\n",
       "Standing          99\n",
       "Snorkeling        89\n",
       "Scuba diving      76\n",
       "Body boarding     61\n",
       "Body surfing      49\n",
       "Swimming          47\n",
       "Kayaking          33\n",
       "Pearl diving      32\n",
       "Name: Activity, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Activity.value_counts().head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üåäÔ∏è Turn this filter into a key:value pairs  üëÅÔ∏è\n",
    "This column could also be used to identify if the attacks were `PROVOKED` or `UNPROVOKED`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Swimming                                                               1274\n",
       "Surfing                                                                1203\n",
       "Fishing                                                                1119\n",
       "Diving                                                                  600\n",
       "INVALID                                                                 544\n",
       "Wading                                                                  163\n",
       "Other types of Boarding sports                                          138\n",
       "Snorkeling                                                              100\n",
       "Standing                                                                 99\n",
       "Boating                                                                  81\n",
       "Fell from boat into water                                                80\n",
       "Shipwreck                                                                68\n",
       "Floating                                                                 52\n",
       "Skiing                                                                   43\n",
       "Sea Disaster                                                             36\n",
       "Kayaking                                                                 33\n",
       "Treading water                                                           32\n",
       "Rafting                                                                  28\n",
       "Fell to the water                                                        25\n",
       "Drifting                                                                 24\n",
       "Playing                                                                  20\n",
       "Walking                                                                  17\n",
       "Rescuing someone / something                                             17\n",
       "War (Torpedo)                                                            17\n",
       "Paddleboarding                                                           16\n",
       "Canoeing                                                                 13\n",
       "Sailing                                                                  12\n",
       "Rowing                                                                   12\n",
       "Filming / Photoshoot                                                     11\n",
       "Airplane crash                                                            6\n",
       "                                                                       ... \n",
       "British ship Macedon was thrown on her beam ends by a sudden squall       1\n",
       "Stamding                                                                  1\n",
       "Murdered by Thai pirates                                                  1\n",
       "Touching sharks                                                           1\n",
       "Standing, washing rear wheels of his ambulance in ankle-deep water        1\n",
       "Jumping in swells                                                         1\n",
       "Cleaning a tank                                                           1\n",
       "Walking in chest-deep water                                               1\n",
       "Jumped out of canoe                                                       1\n",
       "Collecting beche-de-mer                                                   1\n",
       "Treading water, waiting for a wave                                        1\n",
       "Attempted to return injured shark to the sea                              1\n",
       "Painting a ship                                                           1\n",
       "Fleet of canoes caught by a squall and charged by sharks.                 1\n",
       "Dismantling cable buoys of the cable ship All America                     1\n",
       "Standing, holding shark pup                                               1\n",
       "Pulling shark from the water                                              1\n",
       "Restraining a beached shark                                               1\n",
       "Helping men land a shark                                                  1\n",
       "Treading for clams                                                        1\n",
       "Washing sand off a speared fish                                           1\n",
       "Dynamiting fish                                                           1\n",
       "Dragging banana seeds through the shallows                                1\n",
       "Standing in water with child in her arms                                  1\n",
       "Walking on reef                                                           1\n",
       "Attempting to illegally enter the USA                                     1\n",
       "Overturned skiff                                                          1\n",
       "Sittting in water with his child                                          1\n",
       "Touching the mouth of a supposedly dead shark                             1\n",
       "Attacked shark with fists                                                 1\n",
       "Name: Activity2, Length: 371, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filt(x):\n",
    "    if type(x) is unicode:\n",
    "        if 'floating' in x.lower():\n",
    "            return 'Floating'\n",
    "        if 'diving' in x.lower():\n",
    "            return 'Diving'\n",
    "        if 'dive' in x.lower():\n",
    "            return 'Diving'\n",
    "        if 'skiing' in x.lower():\n",
    "            return 'Skiing'\n",
    "        if 'ski ' in x.lower():\n",
    "            return 'Skiing'\n",
    "        if 'surf' in x.lower():\n",
    "            return 'Surfing'\n",
    "        if 'snorkel' in x.lower():\n",
    "            return 'Snorkeling'\n",
    "        if 'fishing' in x.lower():\n",
    "            return 'Fishing'\n",
    "        if 'drift' in x.lower():\n",
    "            return 'Drifting'\n",
    "        if 'swim' in x.lower():\n",
    "            return 'Swimming'\n",
    "        if 'bathing' in x.lower():\n",
    "            return 'Swimming'\n",
    "        if 'paddle' in x.lower():\n",
    "            return 'Paddleboarding'\n",
    "        \n",
    "        if 'raft' in x.lower():\n",
    "            return 'Rafting'\n",
    "        if 'playing' in x.lower():\n",
    "            return 'Playing'\n",
    "        \n",
    "        if 'wading' in x.lower():\n",
    "            return 'Wading'\n",
    "        if 'research' in x.lower():\n",
    "            return 'Research'\n",
    "        if 'rescue' in x.lower():\n",
    "            return 'Rescuing someone / something'\n",
    "        if 'rescuing' in x.lower():\n",
    "            return 'Rescuing someone / something'\n",
    "        if 'overboard' in x.lower():\n",
    "            return 'Fell from boat into water'        \n",
    "        if 'fell' in x.lower():\n",
    "            return 'Fell to the water'\n",
    "        \n",
    "        if 'boat' in x.lower():\n",
    "            return 'Boating'\n",
    "        if 'yatch' in x.lower():\n",
    "            return 'Boating'\n",
    "        if 'disaster' in x.lower():\n",
    "            return 'Sea Disaster'\n",
    "        if 'wreck' in x.lower():\n",
    "            return 'Shipwreck'\n",
    "        if 'capsize' in x.lower():\n",
    "            return 'Shipwreck'\n",
    "        if 'sank' in x.lower():\n",
    "            return 'Shipwreck'\n",
    "        if 'torpedo' in x.lower():\n",
    "            return 'War (Torpedo)'\n",
    "        if 'warship' in x.lower():\n",
    "            return 'War (Warship)'\n",
    "        if ('plane' and 'crash') in x.lower():\n",
    "            return 'Airplane crash'\n",
    "        if 'airliner' in x.lower():\n",
    "            return 'Airplane crash'\n",
    "        \n",
    "        \n",
    "        if 'filming' in x.lower():\n",
    "            return 'Filming / Photoshoot'\n",
    "        if 'sailing' in x.lower():\n",
    "            return 'Sailing'\n",
    "        if 'net ' in x.lower():\n",
    "            return 'Fishing'\n",
    "        if ' net' in x.lower():\n",
    "            \n",
    "            return 'Fishing'\n",
    "        if 'photo' in x.lower():\n",
    "            return 'Filming / Photoshoot'\n",
    "        if 'sinking' in x.lower():\n",
    "            return 'Sea Disaster'\n",
    "        \n",
    "        if 'board' in x.lower():\n",
    "            return 'Other types of Boarding sports'\n",
    "        else:\n",
    "            return x\n",
    "    elif x == 'nan':\n",
    "        return 'NOT SPECIFIED'\n",
    "   #     print(type(x), x) #for debugging  üî•Ô∏è\n",
    "    elif type(x) == float:\n",
    "        return 'INVALID - FLOAT'\n",
    "    else:\n",
    "     #   print(type(x)) #for debugging  üî•Ô∏è\n",
    "        return 'INVALID'\n",
    "\n",
    "# Fill the empty values first\n",
    "df.Activity = df.Activity.fillna('NOT SPECIFIED')\n",
    "\n",
    "# Create the categorized column and count the values\n",
    "df['Activity2'] = df.Activity.map(filt)\n",
    "df.Activity2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Activity2 = df.Activity2.fillna('NOT SPECIFIED')\n",
    "df.Activity2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü¶àÔ∏è Fatalities\n",
    "Sort them out and map them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "539"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Fatal.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Fatal = df.Fatal.fillna('UNKNOWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N          4301\n",
       "Y          1389\n",
       "UNKNOWN     612\n",
       "Name: Fatal, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filt(x):\n",
    "    if 'UNKNOWN' in x.upper():\n",
    "        return x\n",
    "    if 'N' in x.upper():\n",
    "        return 'N'\n",
    "    if 'Y' in x.upper():\n",
    "        return 'Y'\n",
    "    else:\n",
    "        return 'UNKNOWN'\n",
    "\n",
    "df['Fatal'] = df.Fatal.map(filt)\n",
    "df.Fatal.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé£Ô∏è Step 5 - Review of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CaseNum      False\n",
      "Date         False\n",
      "Year         False\n",
      "Type         False\n",
      "Country      False\n",
      "Area         False\n",
      "Location     False\n",
      "Activity     False\n",
      "Sex          False\n",
      "Injury       False\n",
      "Fatal        False\n",
      "Species      False\n",
      "Source       False\n",
      "href         False\n",
      "Species2     False\n",
      "Activity2    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(df.count() < 5000) # To know how much data are we missing on each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 'duped values')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop dupes and compare lengths\n",
    "df_pdf_nodupes = df.drop_duplicates()\n",
    "\n",
    "len(df) - len(df_pdf_nodupes), 'duped values'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "<br><br><br>\n",
    "\n",
    "<h1><center> üèÑÔ∏è \n",
    "    <br> Step 6\n",
    "    <br> Exporting the cleaned Dataset \n",
    "    </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phew... \n",
    "#\n",
    "# That was a long haul right there.\n",
    "# It might not be perfect, but we have\n",
    "# some cleaner data with which we can \n",
    "# make a more educated guess abour \n",
    "# this topic.\n",
    "#\n",
    "# Now, we can take this dataframe and\n",
    "# export it. This will be one of the\n",
    "# products of this project and \n",
    "# hopefully benefit the future of\n",
    "# sharing the planet with sharks.\n",
    "#\n",
    "#\n",
    "#\n",
    "# Oh, I almos forgot... \n",
    "#\n",
    "# Exporting as '.csv':\n",
    "#\n",
    "# It cannot get any simpler than this:\n",
    "df.to_csv('OUTPUT/exported.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hammer head sharks swimming](INPUT/hammer-head-shark.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> üèÅÔ∏èüèÅÔ∏èüèÅÔ∏èüèÅÔ∏èüèÅÔ∏èüèÅÔ∏èüèÅÔ∏èüèÅÔ∏èüèÅÔ∏èüèÅÔ∏èüèÅÔ∏èüèÅÔ∏èüèÅÔ∏èüèÅÔ∏èüèÅÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-2e4669a6f6de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# I just don't want the code below to be ran.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;36m0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "# Have you ever tried to divide by zero ?\n",
    "# I just don't want the code below to be run.\n",
    "\n",
    "0/0\n",
    "################################################################\n",
    "################################################################\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèäÔ∏è IDEAS FOR FUTURE PROJECTS:\n",
    "- The pdfs presented on the `href` seem quite structured\n",
    " \n",
    " - It could be possible to parse them later down the road and use a **REGEX** to find more data\n",
    " \n",
    " - Like, adding a column that lists the **'Moon Phase'** described on some of the pdfs\n",
    "\n",
    "- I also have ran query a few times to notice that all pdfs have actually been uploaded to the same website and have the same naming structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some logic like the one described below could be used to get an idea of shark measurements\n",
    "# Another idea would be to use REGEX\n",
    "\n",
    "def distance_measurments(x):\n",
    "    \n",
    "    #THERE ARE SO MANY ERRORS IN THIS COLUMN, let's filter them\n",
    "    # NOT CONFIRMED\n",
    "    \n",
    "    # -- trying to filter sizes --\n",
    "    \n",
    "    if \"\"\"10'\"\"\" in x.lower():\n",
    "        return \"\"\"10' shark\"\"\"\n",
    "    if \"\"\"11'\"\"\" in x.lower():\n",
    "        return \"\"\"11' shark\"\"\"\n",
    "    if \"\"\"12'\"\"\" in x.lower():\n",
    "        return \"\"\"12' shark\"\"\"\n",
    "    if \"\"\"13'\"\"\" in x.lower():\n",
    "        return \"\"\"13' shark\"\"\"\n",
    "    if \"\"\"14'\"\"\" in x.lower():\n",
    "        return \"\"\"14' shark\"\"\"\n",
    "    if \"\"\"15'\"\"\" in x.lower():\n",
    "        return \"\"\"15' shark\"\"\"\n",
    "    if \"\"\"16'\"\"\" in x.lower():\n",
    "        return \"\"\"16' shark\"\"\"\n",
    "    if \"\"\"17'\"\"\" in x.lower():\n",
    "        return \"\"\"17' shark\"\"\"\n",
    "    if \"\"\"18'\"\"\" in x.lower():\n",
    "        return \"\"\"18' shark\"\"\"\n",
    "    if \"\"\"19'\"\"\" in x.lower():\n",
    "        return \"\"\"19' shark\"\"\"\n",
    "    if \"\"\"20'\"\"\" in x.lower():\n",
    "        return \"\"\"20' shark\"\"\"\n",
    "    if \"\"\"21'\"\"\" in x.lower():\n",
    "        return \"\"\"21' shark\"\"\"\n",
    "    \n",
    "    if \"\"\"1'\"\"\" in x.lower():\n",
    "        return \"\"\"1' shark\"\"\"\n",
    "    if \"\"\"2'\"\"\" in x.lower():\n",
    "        return \"\"\"2' shark\"\"\"\n",
    "    if \"\"\"3'\"\"\" in x.lower():\n",
    "        return \"\"\"3' shark\"\"\"\n",
    "    if \"\"\"4'\"\"\" in x.lower():\n",
    "        return \"\"\"4' shark\"\"\"\n",
    "    if \"\"\"5'\"\"\" in x.lower():\n",
    "        return \"\"\"5' shark\"\"\"\n",
    "    if \"\"\"6'\"\"\" in x.lower():\n",
    "        return \"\"\"6' shark\"\"\"\n",
    "    if \"\"\"7'\"\"\" in x.lower():\n",
    "        return \"\"\"7' shark\"\"\"    \n",
    "    if \"\"\"8'\"\"\" in x.lower():\n",
    "        return \"\"\"8' shark\"\"\"\n",
    "    if \"\"\"9'\"\"\" in x.lower():\n",
    "        return \"\"\"9' shark\"\"\"\n",
    "\n",
    "    if 'small shark' in x.lower():\n",
    "        return 'Small shark'\n",
    "    \n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "# df['Species2'] = df['Species'].map(shark_identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTHER PENDING TASKS TO-DO: \n",
    "- De-clutter ipynb and solve other errors >> Ctrl+F this emoji >> üî•Ô∏è\n",
    "- Optimize variables üëÅÔ∏è\n",
    " - Fatalities\n",
    " - Species classification\n",
    " - Type of attack (Provoked/Unprovoked)\n",
    "- Create a separate module that holds my functions\n",
    "- Change the functions so that they use dictionaries and not huge if/elif/else loop.\n",
    "- Add pictures of sharks to `analysis.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
